---
title: "DoubleML Package"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{package-replication}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Replication of DoubleML results with tiDML

I use the 401k data from Chernozhukov et al. (2018) to replicate results from their package under a few different specifications.

The goal is to show that `tiDML::dml_plr()` can produce comparable results with much less code.


# Get data and import packages

Note I use the same data (401k) and variables across both specifications. 

```{r setup, warning = FALSE, message = FALSE}
library(tiDML)
library(dplyr)
library(purrr)
library(tibble)
library(ggplot2)
library(DoubleML)
library(mlr3)
library(mlr3learners)

df401k <- DoubleML::fetch_401k(return_type = "data.frame", instrument = FALSE)

y_col  <- "net_tfa"   # or "tw" depending on the example
d_col  <- "e401"
x_cols <- c("age","inc","educ","fsize","marr","twoearn","db","pira","hown")

```

# `tiDML` approach as a function

Following Chernozhukov, I use random forest in both stages but the first is classification while the second is regression. 

```{r run-tidml, warning = FALSE, message = FALSE}
run_tidml <- function(seed, df, y, d, x, trees_grid = 1200L, n_folds = 5L) {
  set.seed(seed)

  
  df <- df |> mutate(!!d := as.factor(!!rlang::sym(d)))

  fit_tidml <- dml_rf(
    data = df,
    y = !!rlang::sym(y),
    d = !!rlang::sym(d),
    x = x,
  )

  return(tibble(
    method = "tiDML",
    seed = seed,
    theta = unname(fit_tidml$estimate),
    se    = unname(fit_tidml$se)
  ) |>
    mutate(
      lwr = theta - stats::qnorm(0.975) * se,
      upr = theta + stats::qnorm(0.975) * se
    ))
}

```

# DoubleML approach as a function

Next I use the `DoubleML` package to run the model.

```{r run-dml, warning = FALSE, message = FALSE}
run_dml <- function(seed, df, y, d, x, trees_grid = 1200L, n_folds = 5L) {
  ## DoubleML :: PLR with ranger
  ml_l <- lrn("regr.ranger",
              num.trees = trees_grid, 
              num.threads = 1,
              respect.unordered.factors = "order")
  
  ml_m <- lrn(
    "classif.ranger",
    num.trees = trees_grid,
    num.threads = 1,
    predict_type="prob"
  )

  dml_data <- DoubleMLData$new(
    data = df, 
    y_col = y, 
    d_cols = d, 
    x_cols = x
  )

  dml <- DoubleMLPLR$new(
    dml_data, 
    ml_l = ml_l, 
    ml_m = ml_m,
    n_folds = n_folds,
    score = "partialling out"
  )

  dml$fit()

  ci <- dml$confint(level = 0.95)
  return(tibble(
    method = "DoubleML",
    seed = seed,
    theta = as.numeric(dml$coef),
    se    = as.numeric(dml$se),
    lwr   = as.numeric(ci[1]),
    upr   = as.numeric(ci[2])
  )
  )
}
```

# Run both methods across many replications

This wrapper function runs both methods and returns a combined data frame.

```{r run-rep, warning = FALSE, message = FALSE}

replications <- 100L

run_both <- function(seed, df, y, d, x, trees_grid = 1200L, n_folds = 5L) {
  tidml_row <- run_tidml(seed, df, y, d, x, trees_grid, n_folds)
  dml_row   <- run_dml(seed, df, y, d, x, trees_grid, n_folds)
  bind_rows(tidml_row, dml_row)
}

seeds <- 401 + 0:replications-1  
res <- map_dfr(
  seeds,
  ~ run_both(.x, df = df401k, y = y_col, d = d_col, x = x_cols)
)
```

# Method-by-method densities

There is randomness in both methods so the estimates vary across seeds. Below I plot the densities of estimates across the replications to show that they overlap and have very similar means.

```{r plot-results, warning = FALSE, message = FALSE}
ggplot(res, aes(theta, fill = method)) +
  geom_density(alpha = 0.35) +
  geom_vline(
    data = res %>% group_by(method) %>% summarize(mean_theta = mean(theta)),
    aes(xintercept = mean_theta, color = method),
    linetype = "dashed", size = 1
  ) +
  labs(
    title = "DML-PLR estimates across seeds",
    x = expression(hat(theta)), y = "Density", fill = "Method", colour= "Method"
  ) +
  theme_minimal(base_size = 12)

```