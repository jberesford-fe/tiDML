---
title: "DoubleML Replication"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{DoubleML Replication}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  cache = TRUE,
  eval = identical(Sys.getenv("NOT_CRAN"), "true")
)
```
# Replication of DoubleML results with tiDML

I use 401k data to replicate results from <a href="hhttps://arxiv.org/abs/1608.00060">Chernozhukov et al. (2018)</a>. Note that this is the example given in their <a href="https://docs.doubleml.org/stable/examples/py_double_ml_pension.html">package documentation</a>. 

The goal is to show that `tiDML` produces identical results, with less code and a more interpretable output.

This code takes several hours to run. For ease, I have saved the results in the `inst/extdata` folder of the package. To generate the results yourself, set `run_long  <- TRUE`.

```{r run-long}
run_long <- FALSE
```

# Get data and import packages

To important the 401k data, load the DoubleML (and other required packages) and call:  

```{r load-packages, warning = FALSE, message = FALSE}
library(tiDML)
library(dplyr)
library(purrr)
library(tibble)
library(ggplot2)
library(DoubleML)
library(mlr3)
library(mlr3learners)
```
```{r import-data, warning = FALSE, message = FALSE, eval = run_long}
df401k <- DoubleML::fetch_401k(return_type = "data.frame", instrument = FALSE)
```

I define  the outcome, treatment, and control variables following Chernozhukov et al. (2018) exactly. 

```{r define-cols, warning = FALSE, message = FALSE, eval = run_long}
y_col  <- "net_tfa"
d_col  <- "e401"
x_cols <- c("age","inc","educ","fsize","marr","twoearn","db","pira","hown")
```

# `tiDML` approach as a function

Again following Chernozhukov, I use random forest in both stages. Since e401 is a dummy variable, the first stage is classification while the second is regression. 

```{r run-tidml, warning = FALSE, message = FALSE, eval = run_long}
run_tidml <- function(seed, df, y, d, x, trees_grid, n_folds, n_rep) {
  set.seed(seed)
  
  df <- df |> mutate(!!d := as.factor(!!rlang::sym(d)))

  fit_tidml <- dml_rf(
    data = df,
    y = !!rlang::sym(y),
    d = !!rlang::sym(d),
    x = x,
    trees_grid = trees_grid,
    n_folds = n_folds,
    n_rep = n_rep,
  )

  return(tibble(
    method = "tiDML",
    seed = seed,
    theta = unname(fit_tidml$estimate),
    se    = unname(fit_tidml$se)
  ) |>
    mutate(
      lwr = theta - stats::qnorm(0.975) * se,
      upr = theta + stats::qnorm(0.975) * se
    ))
}

```

# DoubleML approach as a function

Next I use the `DoubleML` package to run the model.

```{r run-dml, warning = FALSE, message = FALSE, eval = run_long}
run_dml <- function(seed, df, y, d, x, trees_grid, n_folds, n_rep) {
  set.seed(seed)
  ## DoubleML :: PLR with ranger
  ml_l <- lrn("regr.ranger",
              num.trees = trees_grid, 
              num.threads = 1,
              respect.unordered.factors = "order")
  
  ml_m <- lrn(
    "classif.ranger",
    num.trees = trees_grid,
    num.threads = 1,
    predict_type="prob"
  )

  dml_data <- DoubleMLData$new(
    data = df, 
    y_col = y, 
    d_cols = d, 
    x_cols = x
  )

  dml <- DoubleMLPLR$new(
    dml_data, 
    ml_l = ml_l, 
    ml_m = ml_m,
    n_folds = n_folds,
    n_rep = n_rep,
    score = "partialling out"
  )

  dml$fit()

  ci <- dml$confint(level = 0.95)
  return(tibble(
    method = "DoubleML",
    seed = seed,
    theta = as.numeric(dml$coef),
    se    = as.numeric(dml$se),
    lwr   = as.numeric(ci[1]),
    upr   = as.numeric(ci[2])
  )
  )
}
```

# Run both methods across many replications

This wrapper function runs both methods and returns a combined data frame.

```{r run-rep, warning = FALSE, message = FALSE, eval = run_long}

replications <- 100L

run_both <- function(seed, df, y, d, x, trees_grid = 1200, n_folds = 2L, n_rep = 2L) {
  tidml_row <- run_tidml(seed, df, y, d, x, trees_grid, n_folds, n_rep)
  dml_row   <- run_dml(seed, df, y, d, x, trees_grid, n_folds, n_rep)
  bind_rows(tidml_row, dml_row)
}

seeds <- 401 + 0:(replications-1L)  
res <- map_dfr(
  seeds,
  ~ run_both(.x, df = df401k, y = y_col, d = d_col, x = x_cols)
)
```

```{r quick-results, warning = FALSE, message = FALSE, eval = run_long, echo = FALSE}
if ~run_long {
  res <- read_rds(system.file("extdata", "dml_replication.rds", package = "tiDML"))
}
```


# Method-by-method densities

There is randomness in both methods so the estimates vary across seeds. Below I plot the densities of estimates across the replications to show that they overlap and have very similar means.

```{r plot-results, warning = FALSE, message = FALSE, fig.alt="DML estimates across packages"}
ggplot(res, aes(theta, fill = method)) +
  geom_density(alpha = 0.35) +
  geom_vline(
    data = res %>% group_by(method) %>% summarize(mean_theta = mean(theta)),
    aes(xintercept = mean_theta, color = method),
    linetype = "dashed", size = 1
  ) +
  labs(
    title = "DML-PLR estimates across seeds",
    x = expression(hat(theta)), y = "Density", fill = "Method", colour= "Method"
  ) +
  theme_minimal(base_size = 12)

```

# T-Test shows no differences between packages 

There is no statistically significant difference in mean, standard error, or confidence intervals. 

```{r t-test, warning = FALSE, message = FALSE}
# No difference in means
print(t.test(theta ~ method, data = res))

# No difference in standard errors
print(t.test(mean_se ~ method, data = res))

# No difference in confidence interval width
res <- res |> mutate(ci_width = upr - lwr)
print(t.test(ci_width ~ method, data = res))
```