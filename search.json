[{"path":"https://jberesford-fe.github.io/tiDML/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 Justin Beresford Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":[]},{"path":"https://jberesford-fe.github.io/tiDML/articles/examine-outputs.html","id":"tidy-glance-and-augment","dir":"Articles","previous_headings":"Describing the model output","what":"tidy(), glance() and augment()","title":"Examine model outputs","text":"functions generics return coefficients, models settings, fold predictions (hat) residuals (res). outcome model (g) treatment model (m). tidy() returns coefficients standard errors glance() returns model settings augment() returns original data, predicted values, residuals","code":"library(tiDML) library(generics)  df <- diamonds_sample(n=500)  fit_rf <- dml_rf(   data = df,   y = \"price\",   d = \"is_rated_ideal\",   x = c(\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"), ) tidy(fit_rf) #> # A tibble: 1 × 6 #>   term               estimate std.error conf.low conf.high vcov_type #>   <chr>                 <dbl>     <dbl>    <dbl>     <dbl> <chr>     #> 1 is_rated_idealTRUE     149.      165.    -174.      472. HC2 glance(fit_rf) #> # A tibble: 1 × 8 #>   n_obs n_folds vcov_type treatment_type estimate std_error conf_low conf_high #>   <int>   <int> <chr>     <chr>             <dbl>     <dbl>    <dbl>     <dbl> #> 1   500       5 HC2       binary_factor      149.      165.    -174.      472. augment(fit_rf) #> # A tibble: 500 × 7 #>     .row     y d      g_hat m_hat  y_res  d_res #>    <int> <int> <fct>  <dbl> <dbl>  <dbl>  <dbl> #>  1     1   638 FALSE   994. 0.139  -356. -0.139 #>  2     2  1402 FALSE  1579. 0.225  -177. -0.225 #>  3     3  3530 FALSE  5390. 0.092 -1860. -0.092 #>  4     4  5037 TRUE   5872. 0.871  -835.  0.129 #>  5     5 13757 FALSE  7996. 0.01   5761. -0.01  #>  6     6   457 TRUE    727. 0.859  -270.  0.141 #>  7     7  2321 FALSE  3621. 0.558 -1300. -0.558 #>  8     8  5657 FALSE  5135. 0.116   522. -0.116 #>  9     9  4372 FALSE  4941. 0.014  -569. -0.014 #> 10    10 13976 FALSE 13659. 0.072   317. -0.072 #> # ℹ 490 more rows"},{"path":"https://jberesford-fe.github.io/tiDML/articles/examine-outputs.html","id":"inspecting-the-workflow","dir":"Articles","previous_headings":"","what":"Inspecting the workflow","title":"Examine model outputs","text":"workflow defined using workflows package. combines pre-processing (recipes) model fitting (parsnip).","code":""},{"path":"https://jberesford-fe.github.io/tiDML/articles/examine-outputs.html","id":"get-the-recipepreprocessor","dir":"Articles","previous_headings":"Inspecting the workflow","what":"Get the recipe/preprocessor","title":"Examine model outputs","text":"","code":"recipe_g <- workflows::extract_preprocessor(fit_rf$g_workflow)  # See the recipe print(recipe_g) #>  #> ── Recipe ────────────────────────────────────────────────────────────────────── #>  #> ── Inputs #> Number of variables by role #> outcome:   1 #> predictor: 6 # See a summary of all steps summary(recipe_g) #> # A tibble: 7 × 4 #>   variable type      role      source   #>   <chr>    <list>    <chr>     <chr>    #> 1 carat    <chr [2]> predictor original #> 2 depth    <chr [2]> predictor original #> 3 table    <chr [2]> predictor original #> 4 x        <chr [2]> predictor original #> 5 y        <chr [2]> predictor original #> 6 z        <chr [2]> predictor original #> 7 price    <chr [2]> outcome   original  # See what variables are involved recipe_g$var_info #> # A tibble: 7 × 4 #>   variable type      role      source   #>   <chr>    <list>    <chr>     <chr>    #> 1 carat    <chr [2]> predictor original #> 2 depth    <chr [2]> predictor original #> 3 table    <chr [2]> predictor original #> 4 x        <chr [2]> predictor original #> 5 y        <chr [2]> predictor original #> 6 z        <chr [2]> predictor original #> 7 price    <chr [2]> outcome   original  # If you want to see what the recipe does to data: prepped <- recipes::prep(recipe_g, df) processed <- recipes::bake(prepped, df) processed |> head()  #> # A tibble: 6 × 7 #>   carat depth table     x     y     z price #>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <int> #> 1  0.41  62.3    61  4.72  4.75  2.95   638 #> 2  0.5   62.8    57  5.05  5.08  3.18  1402 #> 3  1.03  65.2    56  6.42  6.35  4.16  3530 #> 4  1.1   62.1    57  6.6   6.64  4.11  5037 #> 5  1.51  63.3    61  7.24  7.17  4.56 13757 #> 6  0.3   62.1    55  4.3   4.33  2.68   457"},{"path":"https://jberesford-fe.github.io/tiDML/articles/examine-outputs.html","id":"get-the-model-specifications","dir":"Articles","previous_headings":"Inspecting the workflow","what":"Get the model specifications","title":"Examine model outputs","text":"","code":"model_spec_g <- workflows::extract_spec_parsnip(fit_rf$g_workflow) model_spec_m <- workflows::extract_spec_parsnip(fit_rf$m_workflow)  print(model_spec_g) #> Random Forest Model Specification (regression) #>  #> Main Arguments: #>   mtry = mtry_g #>   trees = 500 #>  #> Engine-Specific Arguments: #>   respect.unordered.factors = order #>   num.threads = 1 #>   importance = if (store_models) \"impurity\" else \"none\" #>  #> Computational engine: ranger  # Key properties model_spec_g$engine    # \"ranger\" is used in the default random forest #> [1] \"ranger\" model_spec_g$mode      # \"regression\" for the outcome model #> [1] \"regression\" model_spec_m$mode      # \"classification\" for the treatment model, since it's binary   #> [1] \"classification\""},{"path":"https://jberesford-fe.github.io/tiDML/articles/examine-outputs.html","id":"what-are-the-hyperparameters","dir":"Articles","previous_headings":"Inspecting the workflow > Get the model specifications","what":"What are the hyperparameters?","title":"Examine model outputs","text":"","code":"model_spec_g$args #> $mtry #> <quosure> #> expr: ^mtry_g #> env:  0x563335a9a908 #>  #> $trees #> <quosure> #> expr: ^500 #> env:  empty #>  #> $min_n #> <quosure> #> expr: ^NULL #> env:  empty"},{"path":"https://jberesford-fe.github.io/tiDML/articles/examine-outputs.html","id":"evaluation-metrics","dir":"Articles","previous_headings":"","what":"Evaluation metrics","title":"Examine model outputs","text":"done fold predictions. Running augment() fitted model give : + actual values Y D + predicted (hat) values Y D + residuals Y D (.e. actual - predicted) consider plotting following: + scatter plot actual vs predicted Y D + histogram residuals Y D + QQ plot residuals Y D consider calculating following metrics: + Mean Squared Error (MSE) Y D + R-squared Y D + Correlation actual predicted Y D + Correlation residuals Y D can use yardstick package calculate metrics. example:","code":"library(yardstick) # Mean Squared Error mse_y <- mse(data, truth = Y, estimate = .pred_Y) mse_d <- mse(data, truth = D, estimate = .pred_D) # R-squared rsq_y <- rsq(data, truth = Y, estimate = .pred_Y) rsq_d <- rsq(data, truth = D, estimate = .pred_D) # Correlation cor_y <- cor(data$Y, data$.pred_Y) cor_d <- cor(data$D, data$.pred_D)"},{"path":"https://jberesford-fe.github.io/tiDML/articles/feature-importance.html","id":"storing-fitted-models","dir":"Articles","previous_headings":"","what":"Storing fitted models","title":"Extract feature importance","text":"either default dml_XX() functions, running custom run_dml(), option store fitted models (across folds reps) setting store_models = TRUE. allows extract feature importance measures underlying models. Warning: can use lot memory, especially using large number folds reps.","code":""},{"path":"https://jberesford-fe.github.io/tiDML/articles/feature-importance.html","id":"store_models-true","dir":"Articles","previous_headings":"Storing fitted models","what":"store_models = TRUE","title":"Extract feature importance","text":"","code":"library(tiDML)  df <- diamonds_sample(n=500, seed=42)  fit_rf <- dml_rf(   data = df,   y = \"price\",   d = \"is_rated_ideal\",   x = c(\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"),   n_folds = 5,   n_rep = 3,   store_models = TRUE )"},{"path":"https://jberesford-fe.github.io/tiDML/articles/feature-importance.html","id":"extracting-feature-importance","dir":"Articles","previous_headings":"","what":"Extracting feature importance","title":"Extract feature importance","text":"Feature importance can extracted tree based models (decision trees, random forests, gradient boosted trees). Lasso regression, coefficients can used assess variable importance. function get_feature_importance() extracts feature importance measures fitted models returns tidy data frame. can average importance across folds reps, plot feature importance distribution.","code":"print(\"not yet implemented\") #> [1] \"not yet implemented\" feature_importance <- get_feature_importance(fit_rf, model = \"outcome\")  print(feature_importance) #> # A tibble: 90 × 4 #>    rep     fold  variable  importance #>    <chr>   <chr> <chr>          <dbl> #>  1 Repeat1 Fold1 carat    1476530170. #>  2 Repeat1 Fold1 depth     129023204. #>  3 Repeat1 Fold1 table      97344033. #>  4 Repeat1 Fold1 x        1438006224. #>  5 Repeat1 Fold1 y        1385954655. #>  6 Repeat1 Fold1 z        1291377574. #>  7 Repeat1 Fold2 carat    1333627279. #>  8 Repeat1 Fold2 depth     130770570. #>  9 Repeat1 Fold2 table     110364172. #> 10 Repeat1 Fold2 x        1374728139. #> # ℹ 80 more rows library(ggplot2)  feature_importance |>   ggplot(aes(importance, reorder(variable, importance))) +   geom_violin(fill=\"#425a7f\", colour=\"#425a7f\") +   labs(x=\"Distribution of importance across folds\", y=\"Feature\")"},{"path":[]},{"path":"https://jberesford-fe.github.io/tiDML/articles/neural-network.html","id":"import-data-and-libraries","dir":"Articles","previous_headings":"Run a neural network with default settings","what":"Import data and libraries","title":"Neural Network","text":"","code":"library(tiDML) library(dplyr) library(recipes) library(parsnip)  # Import first 10k rows of diamonds data df <- diamonds_sample(n=500)"},{"path":"https://jberesford-fe.github.io/tiDML/articles/neural-network.html","id":"neural-network-with-default-settings","dir":"Articles","previous_headings":"","what":"Neural network with default settings","title":"Neural Network","text":"","code":"fit_nnet <- dml_nnet(   data = df,   y = \"price\",   d = \"is_rated_ideal\",   x = c(\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"), )  tidy(fit_nnet) #> # A tibble: 1 × 6 #>   term               estimate std.error conf.low conf.high vcov_type #>   <chr>                 <dbl>     <dbl>    <dbl>     <dbl> <chr>     #> 1 is_rated_idealTRUE     373.      259.    -135.      881. HC2"},{"path":"https://jberesford-fe.github.io/tiDML/articles/neural-network.html","id":"run-a-neural-network-with-custom-settings","dir":"Articles","previous_headings":"","what":"Run a neural network with custom settings","title":"Neural Network","text":"’s possible customise default dml_nnet() degree. set custom penalty rate, number epochs, maximum number weights. also choose number layers (yet true, currently ’s single layer) hidden units (nodes per layer) . Setting hidden units NULL let function choose number hidden units automatically.","code":"fit_nnet <- dml_nnet(   data = df,   y = \"price\",   d = \"is_rated_ideal\",   x = c(\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"),   n_folds = 5,   n_rep = 3,   vcov_type = \"HC2\",   hidden_units_m = 6,   hidden_units_g = 7,   penalty = 0.001,   epochs = 200,   max_weights = 5000,   trace = FALSE   )  fit_nnet |> tidy() #> # A tibble: 1 × 6 #>   term               estimate std.error conf.low conf.high vcov_type #>   <chr>                 <dbl>     <dbl>    <dbl>     <dbl> <chr>     #> 1 is_rated_idealTRUE     249.      179.    -102.      600. HC2"},{"path":"https://jberesford-fe.github.io/tiDML/articles/package-replication.html","id":"replication-of-doubleml-results-with-tidml","dir":"Articles","previous_headings":"","what":"Replication of DoubleML results with tiDML","title":"DoubleML Package","text":"use 401k data Chernozhukov et al. (2018) replicate results package different specifications. goal show tiDML::dml_plr() can produce comparable results much less code.","code":""},{"path":"https://jberesford-fe.github.io/tiDML/articles/package-replication.html","id":"get-data-and-import-packages","dir":"Articles","previous_headings":"","what":"Get data and import packages","title":"DoubleML Package","text":"Note use data (401k) variables across specifications.","code":"library(tiDML) library(dplyr) library(purrr) library(tibble) library(ggplot2) library(DoubleML) library(mlr3) library(mlr3learners)  df401k <- DoubleML::fetch_401k(return_type = \"data.frame\", instrument = FALSE) |>   sample_n(5000, replace = FALSE, seed = 123)  y_col  <- \"net_tfa\"   # or \"tw\" depending on the example d_col  <- \"e401\" x_cols <- c(\"age\",\"inc\",\"educ\",\"fsize\",\"marr\",\"twoearn\",\"db\",\"pira\",\"hown\")"},{"path":"https://jberesford-fe.github.io/tiDML/articles/package-replication.html","id":"tidml-approach-as-a-function","dir":"Articles","previous_headings":"","what":"tiDML approach as a function","title":"DoubleML Package","text":"Following Chernozhukov, use random forest stages first classification second regression.","code":"run_tidml <- function(seed, df, y, d, x, trees_grid, n_folds, n_rep) {   set.seed(seed)      df <- df |> mutate(!!d := as.factor(!!rlang::sym(d)))    fit_tidml <- dml_rf(     data = df,     y = !!rlang::sym(y),     d = !!rlang::sym(d),     x = x,     trees_grid = trees_grid,     n_folds = n_folds,     n_rep = n_rep,   )    return(tibble(     method = \"tiDML\",     seed = seed,     theta = unname(fit_tidml$estimate),     se    = unname(fit_tidml$se)   ) |>     mutate(       lwr = theta - stats::qnorm(0.975) * se,       upr = theta + stats::qnorm(0.975) * se     )) }"},{"path":"https://jberesford-fe.github.io/tiDML/articles/package-replication.html","id":"doubleml-approach-as-a-function","dir":"Articles","previous_headings":"","what":"DoubleML approach as a function","title":"DoubleML Package","text":"Next use DoubleML package run model.","code":"run_dml <- function(seed, df, y, d, x, trees_grid, n_folds, n_rep) {   set.seed(seed)   ## DoubleML :: PLR with ranger   ml_l <- lrn(\"regr.ranger\",               num.trees = trees_grid,                num.threads = 1,               respect.unordered.factors = \"order\")      ml_m <- lrn(     \"classif.ranger\",     num.trees = trees_grid,     num.threads = 1,     predict_type=\"prob\"   )    dml_data <- DoubleMLData$new(     data = df,      y_col = y,      d_cols = d,      x_cols = x   )    dml <- DoubleMLPLR$new(     dml_data,      ml_l = ml_l,      ml_m = ml_m,     n_folds = n_folds,     n_rep = n_rep,     score = \"partialling out\"   )    dml$fit()    ci <- dml$confint(level = 0.95)   return(tibble(     method = \"DoubleML\",     seed = seed,     theta = as.numeric(dml$coef),     se    = as.numeric(dml$se),     lwr   = as.numeric(ci[1]),     upr   = as.numeric(ci[2])   )   ) }"},{"path":"https://jberesford-fe.github.io/tiDML/articles/package-replication.html","id":"run-both-methods-across-many-replications","dir":"Articles","previous_headings":"","what":"Run both methods across many replications","title":"DoubleML Package","text":"wrapper function runs methods returns combined data frame.","code":"replications <- 1L  run_both <- function(seed, df, y, d, x, trees_grid = 1200, n_folds = 5L, n_rep = 3L) {   tidml_row <- run_tidml(seed, df, y, d, x, trees_grid, n_folds, n_rep)   dml_row   <- run_dml(seed, df, y, d, x, trees_grid, n_folds, n_rep)   bind_rows(tidml_row, dml_row) }  seeds <- 401 + 0:(replications-1L)   res <- map_dfr(   seeds,   ~ run_both(.x, df = df401k, y = y_col, d = d_col, x = x_cols) )  print(res %>%   group_by(method) %>%   summarize(     mean_theta = mean(theta),     mean_se = mean(se),     mean_lwr = mean(lwr),     mean_upr = mean(upr)   )) #> # A tibble: 2 × 5 #>   method   mean_theta mean_se mean_lwr mean_upr #>   <chr>         <dbl>   <dbl>    <dbl>    <dbl> #> 1 DoubleML     10059.   2063.    6015.   14103. #> 2 tiDML        10088.   2055.    6060.   14117.  # T-Test for difference in means #print(t.test(theta ~ method, data = res)) # this doesn't work"},{"path":"https://jberesford-fe.github.io/tiDML/articles/package-replication.html","id":"method-by-method-densities","dir":"Articles","previous_headings":"","what":"Method-by-method densities","title":"DoubleML Package","text":"randomness methods estimates vary across seeds. plot densities estimates across replications show overlap similar means.","code":"ggplot(res, aes(theta, fill = method)) +   geom_density(alpha = 0.35) +   geom_vline(     data = res %>% group_by(method) %>% summarize(mean_theta = mean(theta)),     aes(xintercept = mean_theta, color = method),     linetype = \"dashed\", size = 1   ) +   labs(     title = \"DML-PLR estimates across seeds\",     x = expression(hat(theta)), y = \"Density\", fill = \"Method\", colour= \"Method\"   ) +   theme_minimal(base_size = 12)"},{"path":"https://jberesford-fe.github.io/tiDML/articles/random-forest.html","id":"load-packages-and-data","dir":"Articles","previous_headings":"","what":"Load packages and data","title":"Random Forest","text":"","code":"library(tiDML) library(tiDML) library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(recipes) #>  #> Attaching package: 'recipes' #> The following object is masked from 'package:stats': #>  #>     step library(parsnip)"},{"path":"https://jberesford-fe.github.io/tiDML/articles/random-forest.html","id":"random-forest-with-default-settings","dir":"Articles","previous_headings":"","what":"Random forest with default settings","title":"Random Forest","text":"","code":"df <- diamonds_sample()  fit_rf <- dml_rf(   data = df,   y = \"price\",   d = \"is_rated_ideal\",   x = c(\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"), )  tidy(fit_rf) #> # A tibble: 1 × 6 #>   term               estimate std.error conf.low conf.high vcov_type #>   <chr>                 <dbl>     <dbl>    <dbl>     <dbl> <chr>     #> 1 is_rated_idealTRUE     224.      45.4     135.      313. HC2"},{"path":"https://jberesford-fe.github.io/tiDML/articles/random-forest.html","id":"random-forest-with-custom-settings","dir":"Articles","previous_headings":"","what":"Random Forest with custom settings","title":"Random Forest","text":"can also customise default dml_rf() degree. set custom grid number trees try hyperparameter tuning (NB tests 100 200, rather everything ). can also set number folds cross-fitting type robust standard errors use (choice “HC0”, “HC1”, “HC2”, “HC3”, “HC4”).","code":"fit_rf <- dml_rf(   data = df,   y = \"price\",   d = \"is_rated_ideal\",   x = c(\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"),   n_folds = 5,   n_rep = 3,   vcov_type = \"HC2\",   trees_grid = c(100, 200))  tidy(fit_rf) #> # A tibble: 1 × 6 #>   term               estimate std.error conf.low conf.high vcov_type #>   <chr>                 <dbl>     <dbl>    <dbl>     <dbl> <chr>     #> 1 is_rated_idealTRUE     200.      45.1     111.      288. HC2"},{"path":"https://jberesford-fe.github.io/tiDML/articles/tiDML.html","id":"first-pass-with-tidml","dir":"Articles","previous_headings":"","what":"First pass with tiDML","title":"Introduction to tiDML","text":"simplest case, can use package complete default settings. Pick model, specify data, outcome variable, treatment variable, covariates, hit go. Currently, default models available : dml_rf() random forest, dml_nnet() neural network. use diamonds data ggplot2 estimate effect rated “ideal” diamonds’ price, controlled caret, depth, size.","code":"library(tiDML)  df <- diamonds_sample(n=10000)  fit_rf <- dml_rf(   data = df,   y = \"price\",   d = \"is_rated_ideal\",   x = c(\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"), )  fit_rf$estimate #> [1] 224.2336"},{"path":"https://jberesford-fe.github.io/tiDML/articles/tiDML.html","id":"checking-model-outputs","dir":"Articles","previous_headings":"","what":"Checking model outputs","title":"Introduction to tiDML","text":"benefit using tiDML (tidymodels ecosystem generally) can rely packages like generics workflows examine inputs outputs model.","code":""},{"path":"https://jberesford-fe.github.io/tiDML/articles/tiDML.html","id":"tidy","dir":"Articles","previous_headings":"Checking model outputs","what":"tidy()","title":"Introduction to tiDML","text":"Tidy returns tibble point estimate, standard error, t-value, p-value, confidence interval.","code":"# Coefficients and standard errors generics::tidy(fit_rf) #> # A tibble: 1 × 6 #>   term               estimate std.error conf.low conf.high vcov_type #>   <chr>                 <dbl>     <dbl>    <dbl>     <dbl> <chr>     #> 1 is_rated_idealTRUE     224.      45.4     135.      313. HC2"},{"path":"https://jberesford-fe.github.io/tiDML/articles/tiDML.html","id":"glance","dir":"Articles","previous_headings":"Checking model outputs","what":"glance()","title":"Introduction to tiDML","text":"Glance returns tibble inputs settings used DML estimation.","code":"generics::glance(fit_rf) #> # A tibble: 1 × 8 #>   n_obs n_folds vcov_type treatment_type estimate std_error conf_low conf_high #>   <int>   <int> <chr>     <chr>             <dbl>     <dbl>    <dbl>     <dbl> #> 1 10000       5 HC2       binary_factor      224.      45.4     135.      313."},{"path":"https://jberesford-fe.github.io/tiDML/articles/tiDML.html","id":"augment","dir":"Articles","previous_headings":"Checking model outputs","what":"augment()","title":"Introduction to tiDML","text":"Augment returns tibble original data, predicted values, residuals outcome treatment variables. --fold predictions residuals, handy diagnostics.","code":"generics::augment(fit_rf) |> head() #> # A tibble: 6 × 7 #>    .row     y d     g_hat  m_hat   y_res    d_res #>   <int> <int> <fct> <dbl>  <dbl>   <dbl>    <dbl> #> 1     1   638 FALSE  829. 0.0052  -191.  -0.0052  #> 2     2  1402 FALSE 1497. 0.0821   -95.2 -0.0821  #> 3     3  3530 FALSE 4385. 0.004   -855.  -0.004   #> 4     4  5037 TRUE  6732. 0.875  -1695.   0.125   #> 5     5 13757 FALSE 9337. 0.008   4420.  -0.008   #> 6     6   457 TRUE   714. 0.996   -257.   0.00408"},{"path":"https://jberesford-fe.github.io/tiDML/articles/tiDML.html","id":"examine-the-workflow-recipe-and-model-specs","dir":"Articles","previous_headings":"Checking model outputs","what":"Examine the workflow (recipe and model specs)","title":"Introduction to tiDML","text":"workflows package used manage preprocessing model fitting steps. can extract (unfitted) workflow object examine . Note fitted workflow can extracted, isn’t useful since DML uses cross-fitting. Much detail given Articles section. See vignette(\"examine-outputs\").","code":"# Examine the treatment model workflow print(\"Treatment model workflow:\") #> [1] \"Treatment model workflow:\" fit_rf$m_workflow #> ══ Workflow ════════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: rand_forest() #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #> 0 Recipe Steps #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> Random Forest Model Specification (classification) #>  #> Main Arguments: #>   mtry = mtry_m #>   trees = 500 #>   min_n = min_n_val #>  #> Engine-Specific Arguments: #>   num.threads = 1 #>   probability = (treatment_type == \"binary_factor\") #>   importance = if (store_models) \"impurity\" else \"none\" #>  #> Computational engine: ranger  print(\"Outcome model workflow:\") #> [1] \"Outcome model workflow:\" fit_rf$g_workflow #> ══ Workflow ════════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: rand_forest() #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #> 0 Recipe Steps #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> Random Forest Model Specification (regression) #>  #> Main Arguments: #>   mtry = mtry_g #>   trees = 500 #>  #> Engine-Specific Arguments: #>   respect.unordered.factors = order #>   num.threads = 1 #>   importance = if (store_models) \"impurity\" else \"none\" #>  #> Computational engine: ranger"},{"path":"https://jberesford-fe.github.io/tiDML/articles/tiDML.html","id":"setting-your-own-models","dir":"Articles","previous_headings":"","what":"Setting your own models","title":"Introduction to tiDML","text":"can also set models using parsnip recipes. gives control model specifications preprocessing steps. See vignette(\"user-defined-recipies\") instructions.","code":""},{"path":[]},{"path":"https://jberesford-fe.github.io/tiDML/articles/user-defined-recipies.html","id":"define-your-model-specs","dir":"Articles","previous_headings":"Three steps to your own model","what":"1. Define your model specs","title":"Set your own model","text":"define using parsnip package. literally thousands available models, see parsnip documentation comprehensive list examples.","code":"library(tiDML)  # Test dml_rf df = diamonds_sample(n=100)  # parsnip model spec  g_spec = parsnip::rand_forest(trees = 100) |>   parsnip::set_engine(\"ranger\") |>   parsnip::set_mode(\"regression\")  m_spec = parsnip::rand_forest(trees = 100) |>   parsnip::set_engine(\"ranger\") |>   parsnip::set_mode(\"classification\")"},{"path":"https://jberesford-fe.github.io/tiDML/articles/user-defined-recipies.html","id":"define-your-own-recipes","dir":"Articles","previous_headings":"Three steps to your own model","what":"2. Define your own recipes","title":"Set your own model","text":"","code":"g_rec <- recipes::recipe(price ~ carat + depth + table + x + y + z, data = df) |>   recipes::step_log('carat') |> # Take log for a given column name   recipes::step_impute_knn(recipes::all_numeric_predictors()) |> # Impute missing values for all numeric columns   recipes::step_dummy(recipes::all_nominal(), -recipes::all_outcomes()) # Note the exclusion of outcome variables with -  m_rec <- recipes::recipe(is_rated_ideal ~ carat + depth + table + x + y + z, data = df) |>   recipes::step_ns(carat, deg_free = 3) |>   recipes::step_dummy(recipes::all_nominal(), -recipes::all_outcomes())"},{"path":"https://jberesford-fe.github.io/tiDML/articles/user-defined-recipies.html","id":"finally-run-the-dml-procedure","dir":"Articles","previous_headings":"Three steps to your own model","what":"Finally, run the DML procedure","title":"Set your own model","text":"Use model specs recipes defined inputs run_dml(). dataframe going run_dml() must one used define recipes. see examine outputs, see vignette(\"examine-outputs\").","code":"fit <- run_dml(   data = df,    outcome_recipe = g_rec,   treatment_recipe = m_rec,   outcome_model = g_spec,   treatment_model = m_spec,   n_folds = 5 )  library(generics) tidy(fit) #> # A tibble: 1 × 6 #>   term               estimate std.error conf.low conf.high vcov_type #>   <chr>                 <dbl>     <dbl>    <dbl>     <dbl> <chr>     #> 1 is_rated_idealTRUE    -37.7      330.    -685.      610. HC2"},{"path":"https://jberesford-fe.github.io/tiDML/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Justin Beresford. Author, maintainer.","code":""},{"path":"https://jberesford-fe.github.io/tiDML/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Beresford J (2025). tiDML: Double Machine Learning Tidymodels. R package version 0.1.0, https://github.com/justinberesford/tiDML.","code":"@Manual{,   title = {tiDML: Double Machine Learning with Tidymodels},   author = {Justin Beresford},   year = {2025},   note = {R package version 0.1.0},   url = {https://github.com/justinberesford/tiDML}, }"},{"path":"https://jberesford-fe.github.io/tiDML/index.html","id":"tidml","dir":"","previous_headings":"","what":"Double Machine Learning with Tidymodels","title":"Double Machine Learning with Tidymodels","text":"goal tiDML twofold: Simple first pass: provide straightforward way run Double Machine Learning (DML) R. Users need pick model, specify data formula. Defaults set sensible values, ’s quick first pass ask: “OLS results change materially DML?” Run DML tidymodels way: flexible framework lets define inspect stages DML process explicitly. Specify first- second-stage models, chosing thousands parsnip models, specify preprocessing steps recipes. backend, combined workflows, used first- second-stage models DML partially linear regression. short, tiDML simplifies default models, ’s main contribution letting define examine stages DML process explicitly, way tidymodels user expect.","code":""},{"path":"https://jberesford-fe.github.io/tiDML/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Double Machine Learning with Tidymodels","text":"can install development version tiDML GitHub via pak, pacman remotes:","code":"# Using pak (recommended) pak::pak(\"jberesford-fe/tiDML\")  # using remotes remotes::install_github(\"jberesford-fe/tiDML\")  # not currently working: pacman::p_load_gh(\"jberesford-fe/tiDML\")"},{"path":"https://jberesford-fe.github.io/tiDML/index.html","id":"default-model-example","dir":"","previous_headings":"","what":"Default model example","title":"Double Machine Learning with Tidymodels","text":"basic example shows run DML PLR model random forests nuisance models, taking parameters default.","code":"library(tiDML)  random_forest <- dml_rf(   data = df,   y = \"y_var\",   d = \"d_var\",   x = c(\"x1\", \"x2\", \"x3\"), )  print(random_forest)"},{"path":"https://jberesford-fe.github.io/tiDML/index.html","id":"user-defined-model-example","dir":"","previous_headings":"","what":"User defined model example","title":"Double Machine Learning with Tidymodels","text":"users requiring control (.e. moving past testing phase implementation), can Define first- second-stage models using parsnip. exmample, using random forests stages: Handle pre-processing steps, stages, using recipes. example, standardising numeric predictors, turning nominals dummies, log-transforming outcome variable etc Pass parsnip model specs recipes recipe run_dml() function get DML estimate. Noting data must passed run_dml() used define recipes. See getting started vignette detailed examples.","code":"outcome_model <- parsnip::rand_forest(trees = 500) |>   parsnip::set_engine(\"ranger\") |>   parsnip::set_mode(\"regression\")  treatment_model <- parsnip::rand_forest(trees = 500) |>   parsnip::set_engine(\"ranger\") |>   parsnip::set_mode(\"classification\") treatment_recipe <- recipes::recipe(d_var ~ x1 + x2 + x3, data = df)  outcome_recipe <- recipes::recipe(y_var ~ x1 + x2 + x3, data = df) run_dml(   data = df,   outcome_model = outcome_model,   treatment_model = treatment_model,   outcome_recipe = outcome_recipe,   treatment_recipe = treatment_recipe,   n_folds = 5,   n_rep = 2, )"},{"path":"https://jberesford-fe.github.io/tiDML/reference/diamonds_sample.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample ggplot2::diamonds with a treatment column — diamonds_sample","title":"Sample ggplot2::diamonds with a treatment column — diamonds_sample","text":"Sample ggplot2::diamonds treatment column","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/diamonds_sample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample ggplot2::diamonds with a treatment column — diamonds_sample","text":"","code":"diamonds_sample(n = 10000, seed = 1)"},{"path":"https://jberesford-fe.github.io/tiDML/reference/diamonds_sample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample ggplot2::diamonds with a treatment column — diamonds_sample","text":"n Number rows sample (default 10,000). seed RNG seed reproducibility.","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/diamonds_sample.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample ggplot2::diamonds with a treatment column — diamonds_sample","text":"tibble columns ggplot2::diamonds plus D (factor 0,1).","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_core_wf.html","id":null,"dir":"Reference","previous_headings":"","what":"Core DML-PLR using workflows — dml_core_wf","title":"Core DML-PLR using workflows — dml_core_wf","text":"Core DML-PLR using workflows","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_core_wf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Core DML-PLR using workflows — dml_core_wf","text":"","code":"dml_core_wf(   data,   m_wf,   g_wf,   folds_outer = NULL,   n_folds = 5,   n_rep = 1,   vcov_type = \"HC2\",   store_models = FALSE )"},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_nnet.html","id":null,"dir":"Reference","previous_headings":"","what":"DML-PLR with single-hidden-layer MLP (nnet engine) — dml_nnet","title":"DML-PLR with single-hidden-layer MLP (nnet engine) — dml_nnet","text":"Uses small MLP nuisances. Adds dummy encoding nominal X normalizes numeric predictors (recommended NNs).","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_nnet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"DML-PLR with single-hidden-layer MLP (nnet engine) — dml_nnet","text":"","code":"dml_nnet(   data,   y,   d,   x,   folds_outer = NULL,   n_folds = 5,   n_rep = 1,   vcov_type = \"HC2\",   hidden_units_m = NULL,   hidden_units_g = NULL,   penalty = 0.001,   epochs = 200,   max_weights = 5000,   trace = FALSE,   store_models = FALSE )"},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_nnet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"DML-PLR with single-hidden-layer MLP (nnet engine) — dml_nnet","text":"data, y, d, x dml_rf() folds_outer Optional rsample rset. NULL, folds made internally (stratified D). n_folds Number outer folds folds_outer NULL. n_rep Number repetitions folds_outer NULL. vcov_type Sandwich variance type (e.g., \"HC2\" \"HC3\"). hidden_units_m, hidden_units_g Hidden units m- g-models (NULL = heuristic). penalty L2 penalty (.k.. weight decay). epochs Max iterations (passed nnet::nnet() via parsnip). max_weights Max allowable weights nnet engine (MaxNWts) avoid overflow. trace Logical; print nnet training trace.","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_rf.html","id":null,"dir":"Reference","previous_headings":"","what":"DML-PLR with Random Forest — dml_rf","title":"DML-PLR with Random Forest — dml_rf","text":"DML-PLR Random Forest","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_rf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"DML-PLR with Random Forest — dml_rf","text":"","code":"dml_rf(   data,   y,   d,   x,   folds_outer = NULL,   n_folds = 5,   n_rep = 1,   mtry_m = NULL,   mtry_g = NULL,   vcov_type = \"HC2\",   trees_grid = NULL,   store_models = FALSE )"},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_rf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"DML-PLR with Random Forest — dml_rf","text":"data Data frame y Outcome column d Treatment column x Covariate columns folds_outer Optional rsample rset. NULL, folds made internally (stratified D). n_folds Number outer folds folds_outer NULL. n_rep Number repetitions folds_outer NULL. vcov_type Sandwich variance type (e.g., \"HC2\" \"HC3\"). trees_grid Optional grid number trees try (m- g-models).","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/make_folds.html","id":null,"dir":"Reference","previous_headings":"","what":"Make v-fold outer folds — make_folds","title":"Make v-fold outer folds — make_folds","text":"Make v-fold outer folds","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/make_folds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make v-fold outer folds — make_folds","text":"","code":"make_folds(data, n_folds = 5)"},{"path":"https://jberesford-fe.github.io/tiDML/reference/make_folds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make v-fold outer folds — make_folds","text":"data Data frame n_folds Number folds","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/make_folds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make v-fold outer folds — make_folds","text":"rsample rset","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/make_folds_stratified.html","id":null,"dir":"Reference","previous_headings":"","what":"Make stratified v-fold outer folds (recommended for binary D) — make_folds_stratified","title":"Make stratified v-fold outer folds (recommended for binary D) — make_folds_stratified","text":"Make stratified v-fold outer folds (recommended binary D)","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/make_folds_stratified.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make stratified v-fold outer folds (recommended for binary D) — make_folds_stratified","text":"","code":"make_folds_stratified(data, d, n_folds = 5, n_rep = 1)"},{"path":"https://jberesford-fe.github.io/tiDML/reference/make_folds_stratified.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make stratified v-fold outer folds (recommended for binary D) — make_folds_stratified","text":"data Data frame d Treatment column name (string) n_folds Number folds n_rep Number repeats","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/make_folds_stratified.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make stratified v-fold outer folds (recommended for binary D) — make_folds_stratified","text":"rsample rset","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/oob_error.html","id":null,"dir":"Reference","previous_headings":"","what":"Get out of bad error — oob_error","title":"Get out of bad error — oob_error","text":"Get bad error","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/oob_error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get out of bad error — oob_error","text":"","code":"oob_error(fitted_wf)"},{"path":"https://jberesford-fe.github.io/tiDML/reference/oob_error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get out of bad error — oob_error","text":"d_vec Treatment vector","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/oob_error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get out of bad error — oob_error","text":"Treatment type string","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/oof_crossfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Out-of-fold cross-fitting for DML — oof_crossfit","title":"Out-of-fold cross-fitting for DML — oof_crossfit","text":"--fold cross-fitting DML","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/oof_crossfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Out-of-fold cross-fitting for DML — oof_crossfit","text":"","code":"oof_crossfit(   data,   folds,   m_fit_fun,   g_fit_fun,   y_name,   d_name,   store_models = FALSE )"},{"path":"https://jberesford-fe.github.io/tiDML/reference/run_dml.html","id":null,"dir":"Reference","previous_headings":"","what":"Run DML-PLR with user-supplied recipes and parsnip models — run_dml","title":"Run DML-PLR with user-supplied recipes and parsnip models — run_dml","text":"Run DML-PLR user-supplied recipes parsnip models","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/run_dml.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run DML-PLR with user-supplied recipes and parsnip models — run_dml","text":"","code":"run_dml(   data,   outcome_recipe,   treatment_recipe,   outcome_model,   treatment_model,   folds_outer = NULL,   n_folds = 5,   n_rep = 1,   vcov_type = \"HC2\",   store_models = FALSE )"},{"path":"https://jberesford-fe.github.io/tiDML/reference/treated_level.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the ","title":"Get the ","text":"Get \"treated\" level binary factor","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/treated_level.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the ","text":"","code":"treated_level(d_vec)"},{"path":"https://jberesford-fe.github.io/tiDML/reference/treated_level.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the ","text":"d_vec Binary factor vector","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/treated_level.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the ","text":"\"treated\" level (second level)","code":""}]
