[{"path":"https://jberesford-fe.github.io/tiDML/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 Justin Beresford Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://jberesford-fe.github.io/tiDML/articles/elastic-net.html","id":"regularised-regression","dir":"Articles","previous_headings":"","what":"Regularised Regression","title":"Elastic Net (ridge/lasso)","text":"function dml_enet() defaults elastic net regression mixture = 0.5. Setting mixture = 1 gives lasso regression mixture = 0 gives ridge regression. penalty parameter (lambda) also required input parameter, can vary two nuisance models (yet chosen via cross-validation, #FIXME). Elastic Net linear model, can use get_feature_coefs(fit_lasso, model=\"treatment\") get_feature_coefs(fit_lasso, model=\"outcome\") inspect coefficients selected features.","code":"library(tiDML)  df <- diamonds_sample()  fit_lasso <- dml_enet(   data = df,   y = \"price\",   d = \"is_rated_ideal\",   x = c(\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"),   store_models = TRUE,   mixture = 1,   penalty_g = 0.1,   penalty_m = 0.1 )"},{"path":[]},{"path":"https://jberesford-fe.github.io/tiDML/articles/examine-outputs.html","id":"tidy-glance-and-augment","dir":"Articles","previous_headings":"Describing the model output","what":"tidy(), glance() and augment()","title":"Examine model outputs","text":"functions generics return coefficients, models settings, fold predictions (hat) residuals (res). outcome model (g) treatment model (m). tidy() returns coefficients standard errors glance() returns model settings augment() returns original data, predicted values, residuals","code":"library(tiDML) library(generics)  df <- diamonds_sample(n=500)  fit_rf <- dml_rf(   data = df,   y = \"price\",   d = \"is_rated_ideal\",   x = c(\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"), ) tidy(fit_rf) #> # A tibble: 1 × 6 #>   term               estimate std.error conf.low conf.high vcov_type #>   <chr>                 <dbl>     <dbl>    <dbl>     <dbl> <chr>     #> 1 is_rated_idealTRUE     149.      165.    -174.      472. HC2 glance(fit_rf) #> # A tibble: 1 × 8 #>   n_obs n_folds vcov_type treatment_type estimate std_error conf_low conf_high #>   <int>   <int> <chr>     <chr>             <dbl>     <dbl>    <dbl>     <dbl> #> 1   500       5 HC2       binary_factor      149.      165.    -174.      472. augment(fit_rf) #> # A tibble: 500 × 7 #>     .row     y d      g_hat m_hat  y_res  d_res #>    <int> <int> <fct>  <dbl> <dbl>  <dbl>  <dbl> #>  1     1   638 FALSE   994. 0.139  -356. -0.139 #>  2     2  1402 FALSE  1579. 0.225  -177. -0.225 #>  3     3  3530 FALSE  5390. 0.092 -1860. -0.092 #>  4     4  5037 TRUE   5872. 0.871  -835.  0.129 #>  5     5 13757 FALSE  7996. 0.01   5761. -0.01  #>  6     6   457 TRUE    727. 0.859  -270.  0.141 #>  7     7  2321 FALSE  3621. 0.558 -1300. -0.558 #>  8     8  5657 FALSE  5135. 0.116   522. -0.116 #>  9     9  4372 FALSE  4941. 0.014  -569. -0.014 #> 10    10 13976 FALSE 13659. 0.072   317. -0.072 #> # ℹ 490 more rows"},{"path":"https://jberesford-fe.github.io/tiDML/articles/examine-outputs.html","id":"inspecting-the-workflow","dir":"Articles","previous_headings":"","what":"Inspecting the workflow","title":"Examine model outputs","text":"workflow defined using workflows package. combines pre-processing (recipes) model fitting (parsnip).","code":""},{"path":"https://jberesford-fe.github.io/tiDML/articles/examine-outputs.html","id":"get-the-recipepreprocessor","dir":"Articles","previous_headings":"Inspecting the workflow","what":"Get the recipe/preprocessor","title":"Examine model outputs","text":"","code":"recipe_g <- workflows::extract_preprocessor(fit_rf$g_workflow)  # See the recipe print(recipe_g) #>  #> ── Recipe ────────────────────────────────────────────────────────────────────── #>  #> ── Inputs #> Number of variables by role #> outcome:   1 #> predictor: 6 # See a summary of all steps summary(recipe_g) #> # A tibble: 7 × 4 #>   variable type      role      source   #>   <chr>    <list>    <chr>     <chr>    #> 1 carat    <chr [2]> predictor original #> 2 depth    <chr [2]> predictor original #> 3 table    <chr [2]> predictor original #> 4 x        <chr [2]> predictor original #> 5 y        <chr [2]> predictor original #> 6 z        <chr [2]> predictor original #> 7 price    <chr [2]> outcome   original  # See what variables are involved recipe_g$var_info #> # A tibble: 7 × 4 #>   variable type      role      source   #>   <chr>    <list>    <chr>     <chr>    #> 1 carat    <chr [2]> predictor original #> 2 depth    <chr [2]> predictor original #> 3 table    <chr [2]> predictor original #> 4 x        <chr [2]> predictor original #> 5 y        <chr [2]> predictor original #> 6 z        <chr [2]> predictor original #> 7 price    <chr [2]> outcome   original  # If you want to see what the recipe does to data: prepped <- recipes::prep(recipe_g, df) processed <- recipes::bake(prepped, df) processed |> head()  #> # A tibble: 6 × 7 #>   carat depth table     x     y     z price #>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <int> #> 1  0.41  62.3    61  4.72  4.75  2.95   638 #> 2  0.5   62.8    57  5.05  5.08  3.18  1402 #> 3  1.03  65.2    56  6.42  6.35  4.16  3530 #> 4  1.1   62.1    57  6.6   6.64  4.11  5037 #> 5  1.51  63.3    61  7.24  7.17  4.56 13757 #> 6  0.3   62.1    55  4.3   4.33  2.68   457"},{"path":"https://jberesford-fe.github.io/tiDML/articles/examine-outputs.html","id":"get-the-model-specifications","dir":"Articles","previous_headings":"Inspecting the workflow","what":"Get the model specifications","title":"Examine model outputs","text":"","code":"model_spec_g <- workflows::extract_spec_parsnip(fit_rf$g_workflow) model_spec_m <- workflows::extract_spec_parsnip(fit_rf$m_workflow)  print(model_spec_g) #> Random Forest Model Specification (regression) #>  #> Main Arguments: #>   mtry = mtry_g #>   trees = 500 #>  #> Engine-Specific Arguments: #>   respect.unordered.factors = order #>   num.threads = 1 #>   importance = if (store_models) \"impurity\" else \"none\" #>  #> Computational engine: ranger  # Key properties model_spec_g$engine    # \"ranger\" is used in the default random forest #> [1] \"ranger\" model_spec_g$mode      # \"regression\" for the outcome model #> [1] \"regression\" model_spec_m$mode      # \"classification\" for the treatment model, since it's binary   #> [1] \"classification\""},{"path":"https://jberesford-fe.github.io/tiDML/articles/examine-outputs.html","id":"what-are-the-hyperparameters","dir":"Articles","previous_headings":"Inspecting the workflow > Get the model specifications","what":"What are the hyperparameters?","title":"Examine model outputs","text":"","code":"model_spec_g$args #> $mtry #> <quosure> #> expr: ^mtry_g #> env:  0x55693a9ae890 #>  #> $trees #> <quosure> #> expr: ^500 #> env:  empty #>  #> $min_n #> <quosure> #> expr: ^NULL #> env:  empty"},{"path":"https://jberesford-fe.github.io/tiDML/articles/examine-outputs.html","id":"evaluation-metrics","dir":"Articles","previous_headings":"","what":"Evaluation metrics","title":"Examine model outputs","text":"done fold predictions. Running augment() fitted model give : + actual values Y D + predicted (hat) values Y D + residuals Y D (.e. actual - predicted) consider plotting following: + scatter plot actual vs predicted Y D + histogram residuals Y D + QQ plot residuals Y D consider calculating following metrics: + Mean Squared Error (MSE) Y D + R-squared Y D + Correlation actual predicted Y D + Correlation residuals Y D can use yardstick package calculate metrics. example:","code":"library(yardstick) # Mean Squared Error mse_y <- mse(data, truth = Y, estimate = .pred_Y) mse_d <- mse(data, truth = D, estimate = .pred_D) # R-squared rsq_y <- rsq(data, truth = Y, estimate = .pred_Y) rsq_d <- rsq(data, truth = D, estimate = .pred_D) # Correlation cor_y <- cor(data$Y, data$.pred_Y) cor_d <- cor(data$D, data$.pred_D)"},{"path":"https://jberesford-fe.github.io/tiDML/articles/feature-importance.html","id":"storing-fitted-models","dir":"Articles","previous_headings":"","what":"Storing fitted models","title":"Extract feature importance","text":"either default dml_XX() functions, running custom run_dml(), option store fitted models (across folds reps) setting store_models = TRUE. allows extract feature importance measures underlying models. Warning: can use lot memory, especially using large number folds reps.","code":""},{"path":"https://jberesford-fe.github.io/tiDML/articles/feature-importance.html","id":"saving-with-store_models-true","dir":"Articles","previous_headings":"Storing fitted models","what":"Saving with store_models = TRUE","title":"Extract feature importance","text":"","code":"library(tiDML)  df <- diamonds_sample(n=500, seed=42)  fit_rf <- dml_rf(   data = df,   y = \"price\",   d = \"is_rated_ideal\",   x = c(\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"),   store_models = TRUE )"},{"path":"https://jberesford-fe.github.io/tiDML/articles/feature-importance.html","id":"extracting-coefficients-linear-models","dir":"Articles","previous_headings":"","what":"Extracting coefficients (linear models)","title":"Extract feature importance","text":"linear models (e.g. Lasso), can extract regression coefficients directly. default settings (5 cross folds, 1 rep) 10 sets regression coefficients: five treatment five outcome. access treatment model , say, third crossfold, save lasso regression fit <- dml_XX(...) use generics package extract coefficients: generics::tidy(fit$m_fit[[3]]). tiDML’s get_feature_coefs() function wrapper around maps across cross folds give single tibble coefficients folds reps.","code":"fit_lasso <- dml_enet(   data = df,   y = \"price\",   d = \"is_rated_ideal\",   x = c(\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"),   store_models = TRUE,   mixture = 1 )  get_feature_coefs(fit_lasso) #> # A tibble: 35 × 5 #>     fold model     term        estimate penalty #>    <int> <chr>     <chr>          <dbl>   <dbl> #>  1     1 treatment (Intercept)   72.0      0.01 #>  2     1 treatment carat         -0.112    0.01 #>  3     1 treatment depth         -0.479    0.01 #>  4     1 treatment table         -0.750    0.01 #>  5     1 treatment x              0        0.01 #>  6     1 treatment y              0        0.01 #>  7     1 treatment z              0        0.01 #>  8     2 treatment (Intercept)   79.2      0.01 #>  9     2 treatment carat         -0.293    0.01 #> 10     2 treatment depth         -0.572    0.01 #> # ℹ 25 more rows"},{"path":"https://jberesford-fe.github.io/tiDML/articles/feature-importance.html","id":"extracting-feature-importance-tree-based-models","dir":"Articles","previous_headings":"","what":"Extracting feature importance (tree based models)","title":"Extract feature importance","text":"Feature importance can extracted tree based models (decision trees, random forests, gradient boosted trees). function get_feature_importance() extracts feature importance measures fitted models returns tidy data frame. can average importance across folds reps, plot feature importance distribution.","code":"print(\"not yet implemented\") #> [1] \"not yet implemented\" feature_importance <- get_feature_importance(fit_rf, model = \"outcome\") #> Warning: Unknown or uninitialised column: `id2`. #> Unknown or uninitialised column: `id2`. #> Unknown or uninitialised column: `id2`. #> Unknown or uninitialised column: `id2`. #> Unknown or uninitialised column: `id2`.  print(feature_importance) #> # A tibble: 30 × 3 #>    rep   variable  importance #>    <chr> <chr>          <dbl> #>  1 Fold1 carat    1529049266. #>  2 Fold1 depth     129513335. #>  3 Fold1 table      88149066. #>  4 Fold1 x        1424920545. #>  5 Fold1 y        1313158954. #>  6 Fold1 z        1316812151. #>  7 Fold2 carat    1367497373. #>  8 Fold2 depth     124626621. #>  9 Fold2 table     102783836. #> 10 Fold2 x        1268479322. #> # ℹ 20 more rows library(ggplot2)  feature_importance |>   ggplot(aes(importance, reorder(variable, importance))) +   geom_violin(fill=\"#425a7f\", colour=\"#425a7f\") +   labs(x=\"Distribution of importance across folds\", y=\"Feature\")"},{"path":[]},{"path":"https://jberesford-fe.github.io/tiDML/articles/neural-network.html","id":"import-data-and-libraries","dir":"Articles","previous_headings":"Run a neural network with default settings","what":"Import data and libraries","title":"Neural Network","text":"","code":"library(tiDML) library(dplyr) library(recipes) library(parsnip)  # Import first 10k rows of diamonds data df <- diamonds_sample(n=500)"},{"path":"https://jberesford-fe.github.io/tiDML/articles/neural-network.html","id":"neural-network-with-default-settings","dir":"Articles","previous_headings":"","what":"Neural network with default settings","title":"Neural Network","text":"","code":"fit_nnet <- dml_nnet(   data = df,   y = \"price\",   d = \"is_rated_ideal\",   x = c(\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"), )  tidy(fit_nnet) #> # A tibble: 1 × 6 #>   term               estimate std.error conf.low conf.high vcov_type #>   <chr>                 <dbl>     <dbl>    <dbl>     <dbl> <chr>     #> 1 is_rated_idealTRUE     373.      259.    -135.      881. HC2"},{"path":"https://jberesford-fe.github.io/tiDML/articles/neural-network.html","id":"run-a-neural-network-with-custom-settings","dir":"Articles","previous_headings":"","what":"Run a neural network with custom settings","title":"Neural Network","text":"’s possible customise default dml_nnet() degree. set custom penalty rate, number epochs, maximum number weights. also choose number layers (yet true, currently ’s single layer) hidden units (nodes per layer) . Setting hidden units NULL let function choose number hidden units automatically.","code":"fit_nnet <- dml_nnet(   data = df,   y = \"price\",   d = \"is_rated_ideal\",   x = c(\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"),   n_folds = 5,   n_rep = 3,   vcov_type = \"HC2\",   hidden_units_m = 6,   hidden_units_g = 7,   penalty = 0.001,   epochs = 200,   max_weights = 5000,   trace = FALSE   )  fit_nnet |> tidy() #> # A tibble: 1 × 6 #>   term               estimate std.error conf.low conf.high vcov_type #>   <chr>                 <dbl>     <dbl>    <dbl>     <dbl> <chr>     #> 1 is_rated_idealTRUE     249.      179.    -102.      600. HC2"},{"path":"https://jberesford-fe.github.io/tiDML/articles/package-rep.html","id":"replication-of-doubleml-results-with-tidml","dir":"Articles","previous_headings":"","what":"Replication of DoubleML results with tiDML","title":"DoubleML Replication","text":"use 401k data Chernozhukov et al. (2018) replicate results [name paper]. Note ’m following example given package documenation [DoubleML Package] GET LINK. goal show tiDML produces comparable results, less code interpretable output.","code":""},{"path":"https://jberesford-fe.github.io/tiDML/articles/package-rep.html","id":"get-data-and-import-packages","dir":"Articles","previous_headings":"","what":"Get data and import packages","title":"DoubleML Replication","text":"important 401k data, load DoubleML (required packages) call: define outcome, treatment, control variables following Chernozhukov et al. (2018) exactly.","code":"library(tiDML) library(dplyr) library(purrr) library(tibble) library(ggplot2) library(DoubleML) library(mlr3) library(mlr3learners)  df401k <- DoubleML::fetch_401k(return_type = \"data.frame\", instrument = FALSE) y_col  <- \"net_tfa\" d_col  <- \"e401\" x_cols <- c(\"age\",\"inc\",\"educ\",\"fsize\",\"marr\",\"twoearn\",\"db\",\"pira\",\"hown\")"},{"path":"https://jberesford-fe.github.io/tiDML/articles/package-rep.html","id":"tidml-approach-as-a-function","dir":"Articles","previous_headings":"","what":"tiDML approach as a function","title":"DoubleML Replication","text":"following Chernozhukov, use random forest stages. Since e401 dummy variable, first stage classification second regression.","code":"run_tidml <- function(seed, df, y, d, x, trees_grid, n_folds, n_rep) {   set.seed(seed)      df <- df |> mutate(!!d := as.factor(!!rlang::sym(d)))    fit_tidml <- dml_rf(     data = df,     y = !!rlang::sym(y),     d = !!rlang::sym(d),     x = x,     trees_grid = trees_grid,     n_folds = n_folds,     n_rep = n_rep,   )    return(tibble(     method = \"tiDML\",     seed = seed,     theta = unname(fit_tidml$estimate),     se    = unname(fit_tidml$se)   ) |>     mutate(       lwr = theta - stats::qnorm(0.975) * se,       upr = theta + stats::qnorm(0.975) * se     )) }"},{"path":"https://jberesford-fe.github.io/tiDML/articles/package-rep.html","id":"doubleml-approach-as-a-function","dir":"Articles","previous_headings":"","what":"DoubleML approach as a function","title":"DoubleML Replication","text":"Next use DoubleML package run model.","code":"run_dml <- function(seed, df, y, d, x, trees_grid, n_folds, n_rep) {   set.seed(seed)   ## DoubleML :: PLR with ranger   ml_l <- lrn(\"regr.ranger\",               num.trees = trees_grid,                num.threads = 1,               respect.unordered.factors = \"order\")      ml_m <- lrn(     \"classif.ranger\",     num.trees = trees_grid,     num.threads = 1,     predict_type=\"prob\"   )    dml_data <- DoubleMLData$new(     data = df,      y_col = y,      d_cols = d,      x_cols = x   )    dml <- DoubleMLPLR$new(     dml_data,      ml_l = ml_l,      ml_m = ml_m,     n_folds = n_folds,     n_rep = n_rep,     score = \"partialling out\"   )    dml$fit()    ci <- dml$confint(level = 0.95)   return(tibble(     method = \"DoubleML\",     seed = seed,     theta = as.numeric(dml$coef),     se    = as.numeric(dml$se),     lwr   = as.numeric(ci[1]),     upr   = as.numeric(ci[2])   )   ) }"},{"path":"https://jberesford-fe.github.io/tiDML/articles/package-rep.html","id":"run-both-methods-across-many-replications","dir":"Articles","previous_headings":"","what":"Run both methods across many replications","title":"DoubleML Replication","text":"wrapper function runs methods returns combined data frame.","code":"replications <- 2L  run_both <- function(seed, df, y, d, x, trees_grid = 1200, n_folds = 2L, n_rep = 1L) {   tidml_row <- run_tidml(seed, df, y, d, x, trees_grid, n_folds, n_rep)   dml_row   <- run_dml(seed, df, y, d, x, trees_grid, n_folds, n_rep)   bind_rows(tidml_row, dml_row) }  seeds <- 401 + 0:(replications-1L)   res <- map_dfr(   seeds,   ~ run_both(.x, df = df401k, y = y_col, d = d_col, x = x_cols) )  print(res %>%   group_by(method) %>%   summarize(     mean_theta = mean(theta),     mean_se = mean(se),     mean_lwr = mean(lwr),     mean_upr = mean(upr)   )) #> # A tibble: 2 × 5 #>   method   mean_theta mean_se mean_lwr mean_upr #>   <chr>         <dbl>   <dbl>    <dbl>    <dbl> #> 1 DoubleML      9049.   1282.    6537.   11561. #> 2 tiDML         9274.   1335.    6659.   11890.  # T-Test for difference in means print(t.test(theta ~ method, data = res)) #>  #>  Welch Two Sample t-test #>  #> data:  theta by method #> t = -0.65198, df = 1.9704, p-value = 0.5822 #> alternative hypothesis: true difference in means between group DoubleML and group tiDML is not equal to 0 #> 95 percent confidence interval: #>  -1735.844  1284.700 #> sample estimates: #> mean in group DoubleML    mean in group tiDML  #>               9048.864               9274.436"},{"path":"https://jberesford-fe.github.io/tiDML/articles/package-rep.html","id":"method-by-method-densities","dir":"Articles","previous_headings":"","what":"Method-by-method densities","title":"DoubleML Replication","text":"randomness methods estimates vary across seeds. plot densities estimates across replications show overlap similar means.","code":"ggplot(res, aes(theta, fill = method)) +   geom_density(alpha = 0.35) +   geom_vline(     data = res %>% group_by(method) %>% summarize(mean_theta = mean(theta)),     aes(xintercept = mean_theta, color = method),     linetype = \"dashed\", size = 1   ) +   labs(     title = \"DML-PLR estimates across seeds\",     x = expression(hat(theta)), y = \"Density\", fill = \"Method\", colour= \"Method\"   ) +   theme_minimal(base_size = 12)"},{"path":"https://jberesford-fe.github.io/tiDML/articles/random-forest.html","id":"load-packages-and-data","dir":"Articles","previous_headings":"","what":"Load packages and data","title":"Random Forest","text":"","code":"library(tiDML) library(tiDML) library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(recipes) #>  #> Attaching package: 'recipes' #> The following object is masked from 'package:stats': #>  #>     step library(parsnip)"},{"path":"https://jberesford-fe.github.io/tiDML/articles/random-forest.html","id":"random-forest-with-default-settings","dir":"Articles","previous_headings":"","what":"Random forest with default settings","title":"Random Forest","text":"","code":"df <- diamonds_sample(n=500)  fit_rf <- dml_rf(   data = df,   y = \"price\",   d = \"is_rated_ideal\",   x = c(\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"), )  tidy(fit_rf) #> # A tibble: 1 × 6 #>   term               estimate std.error conf.low conf.high vcov_type #>   <chr>                 <dbl>     <dbl>    <dbl>     <dbl> <chr>     #> 1 is_rated_idealTRUE     149.      165.    -174.      472. HC2"},{"path":"https://jberesford-fe.github.io/tiDML/articles/random-forest.html","id":"random-forest-with-custom-settings","dir":"Articles","previous_headings":"","what":"Random Forest with custom settings","title":"Random Forest","text":"can also customise default dml_rf() degree. set custom grid number trees try hyperparameter tuning (NB tests 100 200, rather everything ). can also set number folds cross-fitting type robust standard errors use (choice “HC0”, “HC1”, “HC2”, “HC3”, “HC4”).","code":"fit_rf <- dml_rf(   data = df,   y = \"price\",   d = \"is_rated_ideal\",   x = c(\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"),   n_folds = 5,   n_rep = 3,   vcov_type = \"HC2\",   trees_grid = c(100, 200))  tidy(fit_rf) #> # A tibble: 1 × 6 #>   term               estimate std.error conf.low conf.high vcov_type #>   <chr>                 <dbl>     <dbl>    <dbl>     <dbl> <chr>     #> 1 is_rated_idealTRUE     187.      154.    -114.      487. HC2"},{"path":"https://jberesford-fe.github.io/tiDML/articles/tiDML.html","id":"first-pass-with-tidml","dir":"Articles","previous_headings":"","what":"First pass with tiDML","title":"Intro to tiDML","text":"simplest case, can use package complete default settings. Pick model, specify data, outcome variable, treatment variable, covariates, hit go. Currently, default models available : dml_rf() random forest, dml_nnet() neural network. use diamonds data ggplot2 estimate effect rated “ideal” diamonds’ price, controlled caret, depth, size.","code":"library(tiDML)  df <- diamonds_sample(n=500)  fit_rf <- dml_rf(   data = df,   y = \"price\",   d = \"is_rated_ideal\",   x = c(\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"), )  fit_rf$estimate #> [1] 148.6011"},{"path":"https://jberesford-fe.github.io/tiDML/articles/tiDML.html","id":"checking-model-outputs","dir":"Articles","previous_headings":"","what":"Checking model outputs","title":"Intro to tiDML","text":"benefit using tiDML (tidymodels ecosystem generally) can rely packages like generics workflows examine inputs outputs model.","code":""},{"path":"https://jberesford-fe.github.io/tiDML/articles/tiDML.html","id":"tidy","dir":"Articles","previous_headings":"Checking model outputs","what":"tidy()","title":"Intro to tiDML","text":"Tidy returns tibble point estimate, standard error, t-value, p-value, confidence interval.","code":"# Coefficients and standard errors generics::tidy(fit_rf) #> # A tibble: 1 × 6 #>   term               estimate std.error conf.low conf.high vcov_type #>   <chr>                 <dbl>     <dbl>    <dbl>     <dbl> <chr>     #> 1 is_rated_idealTRUE     149.      165.    -174.      472. HC2"},{"path":"https://jberesford-fe.github.io/tiDML/articles/tiDML.html","id":"glance","dir":"Articles","previous_headings":"Checking model outputs","what":"glance()","title":"Intro to tiDML","text":"Glance returns tibble inputs settings used DML estimation.","code":"generics::glance(fit_rf) #> # A tibble: 1 × 8 #>   n_obs n_folds vcov_type treatment_type estimate std_error conf_low conf_high #>   <int>   <int> <chr>     <chr>             <dbl>     <dbl>    <dbl>     <dbl> #> 1   500       5 HC2       binary_factor      149.      165.    -174.      472."},{"path":"https://jberesford-fe.github.io/tiDML/articles/tiDML.html","id":"augment","dir":"Articles","previous_headings":"Checking model outputs","what":"augment()","title":"Intro to tiDML","text":"Augment returns tibble original data, predicted values, residuals outcome treatment variables. --fold predictions residuals, handy diagnostics.","code":"generics::augment(fit_rf) |> head() #> # A tibble: 6 × 7 #>    .row     y d     g_hat m_hat  y_res  d_res #>   <int> <int> <fct> <dbl> <dbl>  <dbl>  <dbl> #> 1     1   638 FALSE  994. 0.139  -356. -0.139 #> 2     2  1402 FALSE 1579. 0.225  -177. -0.225 #> 3     3  3530 FALSE 5390. 0.092 -1860. -0.092 #> 4     4  5037 TRUE  5872. 0.871  -835.  0.129 #> 5     5 13757 FALSE 7996. 0.01   5761. -0.01  #> 6     6   457 TRUE   727. 0.859  -270.  0.141"},{"path":"https://jberesford-fe.github.io/tiDML/articles/tiDML.html","id":"examine-the-workflow-recipe-and-model-specs","dir":"Articles","previous_headings":"Checking model outputs","what":"Examine the workflow (recipe and model specs)","title":"Intro to tiDML","text":"workflows package used manage preprocessing model fitting steps. can extract (unfitted) workflow object examine . Note fitted workflow can extracted, isn’t useful since DML uses cross-fitting. Much detail given Articles section. See vignette(\"examine-outputs\").","code":"# Examine the treatment model workflow print(\"Treatment model workflow:\") #> [1] \"Treatment model workflow:\" fit_rf$m_workflow #> ══ Workflow ════════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: rand_forest() #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #> 0 Recipe Steps #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> Random Forest Model Specification (classification) #>  #> Main Arguments: #>   mtry = mtry_m #>   trees = 500 #>   min_n = min_n_val #>  #> Engine-Specific Arguments: #>   num.threads = 1 #>   probability = (treatment_type == \"binary_factor\") #>   importance = if (store_models) \"impurity\" else \"none\" #>  #> Computational engine: ranger  print(\"Outcome model workflow:\") #> [1] \"Outcome model workflow:\" fit_rf$g_workflow #> ══ Workflow ════════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: rand_forest() #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #> 0 Recipe Steps #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> Random Forest Model Specification (regression) #>  #> Main Arguments: #>   mtry = mtry_g #>   trees = 500 #>  #> Engine-Specific Arguments: #>   respect.unordered.factors = order #>   num.threads = 1 #>   importance = if (store_models) \"impurity\" else \"none\" #>  #> Computational engine: ranger"},{"path":"https://jberesford-fe.github.io/tiDML/articles/tiDML.html","id":"setting-your-own-models","dir":"Articles","previous_headings":"","what":"Setting your own models","title":"Intro to tiDML","text":"can also set models using parsnip recipes. gives control model specifications preprocessing steps. See vignette(\"user-defined-recipies\") instructions.","code":""},{"path":[]},{"path":"https://jberesford-fe.github.io/tiDML/articles/user-defined.html","id":"define-your-model-specs","dir":"Articles","previous_headings":"Three steps to your own model","what":"1. Define your model specs","title":"User Defined Models","text":"define using parsnip package. literally thousands available models, see parsnip documentation comprehensive list examples.","code":"library(tiDML)  # Test dml_rf df = diamonds_sample(n=500)  # parsnip model spec  g_spec = parsnip::rand_forest(trees = 100) |>   parsnip::set_engine(\"ranger\") |>   parsnip::set_mode(\"regression\")  m_spec = parsnip::rand_forest(trees = 100) |>   parsnip::set_engine(\"ranger\") |>   parsnip::set_mode(\"classification\")"},{"path":"https://jberesford-fe.github.io/tiDML/articles/user-defined.html","id":"define-your-own-recipes","dir":"Articles","previous_headings":"Three steps to your own model","what":"2. Define your own recipes","title":"User Defined Models","text":"","code":"g_rec <- recipes::recipe(price ~ carat + depth + table + x + y + z, data = df) |>   recipes::step_log('carat') |> # Take log for a given column name   recipes::step_impute_knn(recipes::all_numeric_predictors()) |> # Impute missing values for all numeric columns   recipes::step_dummy(recipes::all_nominal(), -recipes::all_outcomes()) # Note the exclusion of outcome variables with -  m_rec <- recipes::recipe(is_rated_ideal ~ carat + depth + table + x + y + z, data = df) |>   recipes::step_ns(carat, deg_free = 3) |>   recipes::step_dummy(recipes::all_nominal(), -recipes::all_outcomes())"},{"path":"https://jberesford-fe.github.io/tiDML/articles/user-defined.html","id":"finally-run-the-dml-procedure","dir":"Articles","previous_headings":"Three steps to your own model","what":"Finally, run the DML procedure","title":"User Defined Models","text":"Use model specs recipes defined inputs run_dml(). dataframe going run_dml() must one used define recipes.","code":"fit <- run_dml(   data = df,   outcome_recipe = g_rec,   treatment_recipe = m_rec,   outcome_model = g_spec,   treatment_model = m_spec, )   fit #> $estimate #> [1] 203.3381 #>  #> $se #> [1] 154.1014 #>  #> $ci_95 #> [1] -98.69514 505.37138 #>  #> $y_res #>   [1]  -378.0036667  -344.2133333 -1539.8415000  -793.2005000  5420.2816667 #>   [6]  -271.5190000 -1257.7900000   418.0310000  -528.3820000   596.2836667 #>  [11]  2150.6943333 -1637.0605000   -96.4996667 -2467.2060000  -246.9483333 #>  [16]  -223.8695000   756.3700000  -791.2303333   -17.0321667  -212.4460000 #>  [21]  -209.3620000   -24.5418333  -196.9988333  -554.3550000   -72.7806667 #>  [26]  2396.2690000  1601.5366667 -6076.7333333 -1391.1023333  -229.1071667 #>  [31]  2568.1715000 -2223.7496667   347.2386667  2066.7461667  -995.9066667 #>  [36] -2500.0275000   752.2908333   661.3476667  -275.1476667   321.6830000 #>  [41]     5.7176667 -2413.8563333 -1265.9325000  -130.3648333  -470.2553333 #>  [46]   141.1651667  -229.3785000 -2778.9061667  -330.2428333   -55.8235000 #>  [51]    27.4705000   349.7416667  -241.2423333  -499.6591667   172.3735000 #>  [56]  -102.9426667   194.7866667    78.7225000    82.2336667   171.9896429 #>  [61]    46.3721667 -1110.9415000  -112.8313333 -1288.7231667   212.0175000 #>  [66]    52.8603333 -1614.8923333  -200.9135000   249.4595000 -1645.7823333 #>  [71]  3842.5265000  2867.7105000  2759.1248333 -1727.1691667  -283.5330000 #>  [76]  -189.2281667     6.2861667 -1829.5456667   139.7380000   175.9033333 #>  [81]  3269.5548333   316.1556667  -143.3931667  -165.0095000  2163.2946667 #>  [86]   -90.9768333 -1117.5501667   389.7836667  -377.4185000  1522.2568333 #>  [91]   622.4360000  -616.5211667     1.8076905   105.7435000    14.3963333 #>  [96]   450.6380000  -660.3650000     6.5713333   170.2288333  -137.5321667 #> [101]    52.5943333 -3107.2695000   605.3041667  -770.5553333   296.6178333 #> [106]  -224.0553333   157.8606667  1455.0818333  -303.0555000   182.2096667 #> [111]   288.9153333 -1228.4566667 -1287.1463333  -512.1931667  -331.8530000 #> [116] -1436.0176667  -346.0851667   -44.0373333   695.3078333 -3311.8395000 #> [121] -1490.4916667 -2699.8521667   782.5315000 -1022.2026667  -398.2480000 #> [126]   600.8110000  -988.3180000   157.3350000   -27.4375000 13172.0910000 #> [131]  -296.6180000  -294.8503333  -116.1293333 -2469.6376667   -35.6420000 #> [136]  3381.9480000   499.5988333   289.5456667    12.6470000  1041.2760000 #> [141]  2173.2695000   214.4575000 -2076.5828333  3932.0690000 -4237.5393333 #> [146]   995.0461667    62.2373333   255.6250000  1059.2540000  1392.3208333 #> [151]  -138.9815000  -115.5853333  4318.4438333  2547.1468333   812.8570000 #> [156]    36.1450000   118.2226667 -1477.7268333  4073.7695000    -0.2048333 #> [161]   -62.0338333 -7584.3491667 -1198.4878333  -131.8531667  3860.7826667 #> [166]  2684.0873333  -933.8386667 -2981.1316667   392.6631667  -730.1576667 #> [171]  2237.1336667  -166.4606667  -145.1480000  -984.6691667    40.2580000 #> [176]  -141.8766667   793.5638333  -856.3320000   133.6818333    16.2811667 #> [181]  -143.8430000   941.6210000  -202.9665000  2749.3605000 -1958.0138333 #> [186]   -91.0720000 -1026.8885000  -131.6563333  1164.3048333  -298.1438333 #> [191]    98.6758333   448.2588333     5.8140000   -50.6360000   430.7315000 #> [196]    78.1570000  -912.5395000   134.2640000    85.1506667   394.9743333 #> [201] -2246.3136667 -2259.3165000  -141.5308333   163.9916667   335.9440000 #> [206]  -153.5875000  -401.1706667   113.1825000  -173.6603333   505.2946667 #> [211] -3047.2660000  -130.0883333  -325.2983333  -165.1225000   233.4700000 #> [216]  -260.7986667  -275.9100000 -3714.0318333   161.4551667   358.9033333 #> [221]   380.1305000  2866.6005000 -1548.9650000 -1759.7643333  -759.4793333 #> [226]  -716.5880000  7525.3493333   -36.7713333   -19.5141667    82.9765000 #> [231]  -126.0361667  -365.0323333  1005.6656667   229.5620000   226.3406667 #> [236]  -302.7925000   -11.5100000  -638.9416667  3609.6476667  -152.7555000 #> [241]   -11.8463333  1429.3828333   407.4556667  -543.7945000   -94.6821667 #> [246]  -197.2225000   151.7021667  -442.9448333  -153.5533333  -330.3607381 #> [251]   -80.0133333  2727.3963333  3037.6284167   113.1338333 -1017.8295000 #> [256] -1296.1271667   135.5603333  -337.1923333  -706.2260000    34.6621667 #> [261]  -816.7755000  -545.4216667  2292.5995000   -57.7335000   -44.6561667 #> [266] -1088.3661667   167.8050000   329.7845000   267.9275000   396.8865000 #> [271]   270.9428333 -2083.6250000  -196.6540000   -98.4998333   -53.5011667 #> [276]   862.9413333  -581.3158333 -4224.1186667   -82.6291667   222.4678333 #> [281]   129.8896667   -84.8280000   -50.5131667   122.8031667   250.8213333 #> [286] -2086.4413333    97.3873333   -10.0120000   273.8560000  -167.1726667 #> [291]   -55.9331667    26.5930000  -180.5296667  -174.7026667  -905.6813333 #> [296]  -155.1961667   304.5806667   -58.9660000    45.1045000  -313.1250000 #> [301]   -92.2246667  -404.7490000   666.4123333  -362.5481667  -345.9253333 #> [306]    -5.8023333   347.0213333   -58.5763333   184.6743333  2186.4516667 #> [311]  1174.2476667    93.7335000  -826.3250000   817.5658333 -2379.9113333 #> [316]  -255.1026667  -106.1981667  -391.0991667  -442.7106667   -24.8703333 #> [321]   -37.9466667  -407.8110000   719.5755000 -1679.6645000   956.8431667 #> [326]  3216.8908333   223.9703333    75.0151667   773.7908333     6.3710000 #> [331]   134.6133333   632.7381667   689.0785000    50.6203333    61.8661667 #> [336]    56.1760000   149.1805000   806.2080000  -186.9425000  -370.0281667 #> [341]  -728.6146667  -508.0843333    92.5521667  -354.3993333  -809.5765000 #> [346]    36.3008333   422.4593333   675.8510000   458.9101667  -222.9830000 #> [351]   161.1193333   289.7561667  -414.6980000 -1528.9815000  2158.3065000 #> [356]   391.4636667 -1727.3798333   660.1055000  -130.9011667  -134.7316667 #> [361]   -43.3246667    85.4555000 -4139.2751667  -537.6655000   420.1978333 #> [366] -1629.2631667  -617.4883333   946.4656667  -347.9578333   187.0958333 #> [371]  -218.2286667  -141.6178333   781.8008333    16.3848333   -51.9880000 #> [376]  -377.1138333  -700.3305000 -1142.5706667 -1048.2036667  -140.5070000 #> [381] -2212.0376667  -988.7240000  -180.2175000  1808.3388333  3341.7315000 #> [386]  1366.1125000  -269.3841667 -1414.5436667  1049.4633333  -235.9370000 #> [391]   421.8650000 -2404.9688333   287.7423333    56.6196667  -163.7115000 #> [396]   -78.6381667   418.6261667    55.6153333  -120.2906667   358.0695000 #> [401]  5617.5973333    26.6520000 -1213.7963333    84.1590000     1.2878333 #> [406]  -109.6073333   434.6793333  2251.4013333   411.2490000   -40.0986667 #> [411]  -290.1580000   -46.5445000  -120.2555000    18.2191667  3195.9865000 #> [416]  -754.0078333  -301.1865000 -2550.5165000   134.5910000   202.3278333 #> [421] -1509.3970000  -375.2523333  -724.7476667  -330.8000000   -92.8406667 #> [426]   -51.6773333  2378.0223333   124.1708333 -2607.3976667  -200.3820000 #> [431]  1955.1260000  -211.2335000  -437.3548333   117.3426667   159.7580000 #> [436]  -639.9481667   236.0460000  -468.0816667 -1700.2693333  -978.4211667 #> [441]   542.7508333   -12.6975000  -182.6245000   616.9690000   358.2396667 #> [446]   969.8216667 -1114.8485000   198.2431667   488.1011667    26.6711667 #> [451]   -98.7973333  -146.5881667 -1435.3618333  -198.6046667  -589.0578333 #> [456]  -252.5588333    -3.2143333   -55.2858333  -177.5743333  -269.9620000 #> [461]  4101.4411667  -108.6270000  1132.5980000  -199.5465000   345.3571667 #> [466]  3021.0275000  2819.3385000  -941.5455000    48.3018333  -350.3733333 #> [471] -1126.1143333 -2534.4991667  -219.7958333  -770.8728333 -1486.9890000 #> [476]  -617.6535000  1637.1648333 -2881.6036667  1658.2551667 -1063.4608333 #> [481]  -104.1293333  -340.0095000 -1745.5748333   -70.1638333  -774.8211667 #> [486]   442.2065238    24.0301667 -2566.2015000  -315.6766667  -570.4331667 #> [491]  -305.0150000   123.7203333  -471.9288333   423.2543333   389.9366667 #> [496]  -254.2003333  -250.5051667 -4239.0138333  -225.9061667  -129.4201667 #>  #> $d_res #>   [1] -0.076273810 -0.285138889 -0.168253968  0.209404762 -0.010000000 #>   [6]  0.097809524 -0.458753968 -0.065964286 -0.001111111 -0.126750000 #>  [11] -0.266448413 -0.105305556  0.244107143 -0.074956349 -0.162595238 #>  [16] -0.105452381 -0.170376984 -0.265805556 -0.192396825 -0.082083333 #>  [21] -0.184301587  0.247452381  0.480182540 -0.017857143  0.060051587 #>  [26] -0.248238095 -0.526250000 -0.087559524  0.107619048 -0.201503968 #>  [31] -0.016079365  0.239543651 -0.115150794 -0.002222222 -0.104535714 #>  [36] -0.034650794 -0.003666667  0.617837302  0.475261905 -0.072607143 #>  [41]  0.938476190 -0.056738095 -0.064789683  0.250984127 -0.023027778 #>  [46] -0.043238095 -0.104615079 -0.078388889  0.000000000 -0.379769841 #>  [51]  0.029146825 -0.062202381  0.050777778  0.603230159  0.228027778 #>  [56] -0.094730159  0.231829365 -0.096523810 -0.151142857  0.145765873 #>  [61]  0.075857143  0.399452381  0.017428571 -0.155972222 -0.080194444 #>  [66] -0.093190476  0.139142857 -0.013416667 -0.186599206 -0.001428571 #>  [71] -0.057678571  0.236900794  0.531230159 -0.132702381 -0.779484127 #>  [76]  0.341718254 -0.720015873  0.295583333 -0.109388889  0.024107143 #>  [81] -0.030392857  0.211293651 -0.121007937  0.222392857 -0.597742063 #>  [86]  0.038134921 -0.111242063 -0.150095238 -0.124706349 -0.198944444 #>  [91]  0.230396825 -0.002000000 -0.968222222 -0.139595238 -0.117448413 #>  [96] -0.055063492  0.301619048  0.030964286  0.239884921  0.052059524 #> [101] -0.247726190 -0.057111111  0.988000000  0.564464286  0.149488095 #> [106] -0.080138889 -0.033500000 -0.801972222 -0.183007937  0.000000000 #> [111]  0.250746032 -0.198083333 -0.006888889 -0.138845238 -0.170063492 #> [116] -0.313841270 -0.790924603 -0.706484127  0.401543651 -0.070793651 #> [121] -0.351785714 -0.031634921 -0.040134921 -0.072150794 -0.127619048 #> [126] -0.008825397 -0.657980159 -0.059511905 -0.055095238 -0.153547619 #> [131] -0.124297619 -0.253047619 -0.005000000  0.294956349  0.280769841 #> [136] -0.100896825  0.219194444  0.116611111 -0.096099206  0.196916667 #> [141]  0.215857143 -0.147626984 -0.144634921  0.386166667 -0.020388889 #> [146] -0.036047619 -0.083607143 -0.218861111 -0.125083333 -0.051527778 #> [151] -0.004857143  0.046611111  0.062337302 -0.045234127  0.052230159 #> [156] -0.083424603 -0.041111111  0.443980159  0.165547619  0.147123016 #> [161]  0.275166667 -0.165404762 -0.033333333  0.056023810  0.050710317 #> [166] -0.112583333  0.000000000 -0.065555556 -0.038095238 -0.210948413 #> [171] -0.122968254  0.951035714  0.347011905 -0.766535714  0.066670635 #> [176]  0.162178571 -0.061611111 -0.025916667  0.224472833 -0.111039683 #> [181] -0.247896825 -0.752428571 -0.094301587  0.251107143 -0.007250000 #> [186]  0.031365079  0.197916667  0.352551587 -0.277126984 -0.165698413 #> [191] -0.127357143 -0.015464286 -0.902063492 -0.390396825  0.570912698 #> [196]  0.348448413  0.245833333  0.000000000  0.036944444  0.448329365 #> [201] -0.028055556 -0.056000000  0.105297619 -0.188757937 -0.160662698 #> [206]  0.322007937  0.261035714 -0.073369048 -0.125805556  0.438793651 #> [211] -0.083603175  0.012666667 -0.964480159 -0.690492063  0.953952381 #> [216] -0.067710317 -0.218726190 -0.134686508 -0.645178571 -0.193384921 #> [221]  0.135944444  0.078833333 -0.082793651  0.297785714 -0.750591270 #> [226] -0.039055556  0.218976190  0.555206349 -0.624289683 -0.152765873 #> [231]  0.269369048 -0.023535714 -0.032579365 -0.016285714  0.200813492 #> [236] -0.043750000  0.807007937 -0.228230159  0.308670635 -0.061555556 #> [241]  0.259638889 -0.093309524  0.130607143 -0.757119048 -0.072611111 #> [246]  0.204714286  0.222738095  0.120730159 -0.027047619  0.585023810 #> [251]  0.000000000  0.133952381  0.139527778  0.658936508  0.349289683 #> [256] -0.126337302  0.506591270 -0.093595238 -0.050924603 -0.141847375 #> [261] -0.010000000  0.116817460  0.543420635 -0.067992063 -0.012202381 #> [266] -0.705551587 -0.137750000  0.012777778 -0.082714286  0.021333333 #> [271]  0.040980159  0.115396825 -0.127357143 -0.155892857 -0.097857143 #> [276] -0.537452381 -0.053801587 -0.732317460 -0.123297619 -0.047555556 #> [281] -0.041166667  0.173547619  0.029869048  0.055722222 -0.063285714 #> [286] -0.041079365  0.269373016 -0.013011905 -0.017730159  0.294412698 #> [291]  0.177285714  0.122369048 -0.012789683  0.422095238 -0.276575397 #> [296] -0.173023810  0.079198413 -0.159988095  0.150257937 -0.037857143 #> [301] -0.140928571 -0.094630952 -0.051587302 -0.151301587  0.079384921 #> [306] -0.057777778 -0.054000000 -0.024027778  0.667805556  0.600916667 #> [311] -0.781484127 -0.063000000  0.614555556 -0.028333333 -0.114230159 #> [316]  0.080555556 -0.773261905  0.233301587 -0.712353175  0.428273810 #> [321]  0.349833333  0.943805556  0.052428571 -0.010000000  0.325912698 #> [326] -0.018000000 -0.207503968  0.174940476  0.258230159 -0.563722222 #> [331]  0.189797619 -0.211349206 -0.217694444  0.347753968  0.427726190 #> [336]  0.339928571  0.083198413  0.271408730 -0.744817460 -0.951865079 #> [341] -0.773186508  0.391130952 -0.868630952 -0.045777778  0.082833333 #> [346] -0.134611111 -0.063968254 -0.062178571 -0.515511905  0.133428571 #> [351]  0.243011905 -0.856765873  0.087083333 -0.158492063  0.259079365 #> [356]  0.189555556 -0.063591270 -0.348142857 -0.067507937 -0.002500000 #> [361]  0.564261905  0.326277778 -0.117630952 -0.014083333 -0.366452381 #> [366] -0.207412698 -0.064011905 -0.091285714  0.641039683 -0.002222222 #> [371] -0.220380952  0.141755800  0.213289683 -0.049642857 -0.027388889 #> [376] -0.025916667 -0.101722222 -0.168547619  0.216396825 -0.024523810 #> [381] -0.056000000  0.408353175 -0.069452381 -0.035873016 -0.929567460 #> [386] -0.055650794 -0.161996032  0.683317460  0.919865079 -0.064079365 #> [391] -0.101503968 -0.012678571  0.549138889 -0.209992063 -0.030714286 #> [396]  0.088539683 -0.180357143  0.120019841 -0.050321429 -0.054210317 #> [401] -0.086523810  0.128500000  0.967067460  0.158611111  0.175396825 #> [406]  0.243206349  0.170309524  0.000000000  0.209900794  0.153662698 #> [411]  0.683261905 -0.946892857  0.123722222  0.022428571 -0.054206349 #> [416]  0.080916667 -0.065980159 -0.076261905 -0.245027778 -0.021011905 #> [421]  0.065948413  0.072817460 -0.076706349 -0.064753968  0.066543651 #> [426] -0.078535714 -0.111083333  0.112210317  0.055900794 -0.015773810 #> [431]  0.324384921 -0.109250000 -0.352119048 -0.094797619  0.938892857 #> [436]  0.436007937 -0.056416667  0.699511905  0.178190476  0.951250000 #> [441] -0.233198413 -0.178519841 -0.123837302  0.378198413  0.621682540 #> [446]  0.358436508 -0.082333333 -0.101888889 -0.076821429 -0.450634921 #> [451] -0.169174603  0.127170635 -0.066432540 -0.125873016 -0.045964286 #> [456] -0.864726190  0.662888889 -0.367408730  0.689329365 -0.181884921 #> [461] -0.066674603 -0.057460317 -0.057682540  0.273301587  0.186059524 #> [466]  0.270547619 -0.017678571 -0.071706349 -0.024507937  0.015523810 #> [471]  0.000000000  0.147765873 -0.073563492 -0.039928571 -0.049000000 #> [476] -0.825206349  0.146718254 -0.051777778 -0.113984127 -0.085710317 #> [481] -0.163261905 -0.042222222  0.377742063  0.376976190 -0.005888889 #> [486]  0.211555556 -0.059130342  0.127178571 -0.963888889 -0.021222222 #> [491]  0.164182540  0.419424603 -0.035845238 -0.121238095 -0.044500000 #> [496] -0.701511905 -0.033503968 -0.070345238 -0.221496032  0.327416667 #>  #> $g_hat #>   [1]  1016.0037  1746.2133  5069.8415  5830.2005  8336.7183   728.5190 #>   [7]  3578.7900  5238.9690  4900.3820 13379.7163 11427.3057 11986.0605 #>  [13]   587.4997  7658.2060  1689.9483   802.8695 16262.6300  2100.2303 #>  [19]   952.0322  2613.4460   658.3620  1692.5418   804.9988  4619.3550 #>  [25]   919.7807 14082.7310  6376.4633 15926.7333  8141.1023  2459.1072 #>  [31]  7373.8285 16611.7497  1443.7613  7404.2538  6483.9067  6824.0275 #>  [37]  3833.7092  2816.6523  2762.1477 16483.3170  1079.2823 13578.8563 #>  [43]  6954.9325   889.3648  1538.2553  1776.8348   592.3785  5648.9062 #>  [49]  4436.2428   560.8235   767.5295  4647.2583   949.2423  6063.6592 #>  [55]   883.6265   675.9427  1084.2133   985.2775   783.7663   654.0104 #>  [61]  1029.6278  7864.9415   818.8313  3331.7232   732.9825   654.1397 #>  [67]  6716.8923  3930.9135  5421.5405  3983.7823 13354.4735  7185.2895 #>  [73]  7395.8752 16270.1692  2274.5330  5455.2282   805.7138  7062.5457 #>  [79]  1721.2620   742.0967 10998.4452   724.8443   687.3932  5969.0095 #>  [85]  4934.7053   937.9768  5531.5502  1431.2163  4454.4185  7121.7432 #>  [91]  9710.5640  5488.5212   826.1923   722.2565   551.6037  3993.3620 #>  [97]  1881.3650  1649.4287   768.7712   844.5322   954.4057  7690.2695 #> [103]  5026.6958  5229.5553   783.3822  4397.0553   644.1393  7567.9182 #> [109]  2698.0555  4682.7903  1823.0847  6163.4567  5466.1463  5440.1932 #> [115]  5617.8530  6546.0177  2617.0852   915.0373 12016.6922  7834.8395 #> [121]  6215.4917  8557.8522  3660.4685 10561.2027   920.2480  3688.1890 #> [127]  4990.3180   566.6650   579.4375  2513.9090  5599.6180  2130.8503 #> [133]   908.1293 13668.6377   535.6420  5438.0520  1857.4012  1899.4543 #> [139]  2740.3530  1597.7240  9743.7305  4536.5425  7111.5828  9838.9310 #> [145] 11346.5393  3973.9538  1809.7627  3301.3750 16958.7460  6162.6792 #> [151]   712.9815   860.5853  5582.5562  4802.8532   920.1430   693.8550 #> [157]   838.7773  7547.7268 14222.2305   789.2048  1025.0338 13899.3492 #> [163]  5786.4878   953.8532  6998.2173  6103.9127  5585.8387  8151.1317 #> [169]  1459.3368  3078.1577  9177.8663   711.4607   901.1480  9621.6692 #> [175]   798.7420   730.8767 15520.4362  4541.3320   761.3182  2514.7188 #> [181]   711.8430  7050.3790  1307.9665 16007.6395  5613.0138   777.0720 #> [187]  5972.8885  1516.6563  2415.6952  1053.1438   585.3242  4395.7412 #> [193]  1653.1860   695.6360  5864.2685   596.8430  2576.5395  4602.7360 #> [199]   724.8493  2367.0257  6716.3137  7113.3165   861.5308   680.0083 #> [205]  3092.0560  1802.5875  1820.1707   766.8175   620.6603  1377.7053 #> [211]  8262.2660  1035.0883  1575.2983  1940.1225  4169.5300  2410.7987 #> [217]  3357.9100 11099.0318  3105.5448  9739.0967   782.8695  6778.3995 #> [223]  5798.9650 15022.7643  2681.4793  1700.5880  6062.6507  3393.7713 #> [229]   605.5142  1832.0235  1818.0362  1654.0323 17014.3343  3764.4380 #> [235]   636.6593 16866.7925   547.5100  3804.9417 13945.3523   622.7555 #> [241]  1784.8463  4938.6172   933.5443  1864.7945   886.6822   900.2225 #> [247]  1914.2978 15279.9448  4308.5533   959.3607   975.0133 13588.6037 #> [253]  7304.3716  3342.8662  6687.8295  5794.1272  1022.4397   730.1923 #> [259] 13260.2260   590.3378  4395.7755  1986.4217  6048.4005  5525.7335 #> [265]   649.6562 15708.3662  3838.1950   703.2155  2232.0725   777.1135 #> [271]   762.0572  7495.6250   590.6540   953.4998   922.5012 17392.0587 #> [277]  4921.3158 11565.1187   626.6292   619.5322   686.1103   742.8280 #> [283]   875.5132   943.1968   698.1787  6999.4413   651.6127   531.0120 #> [289]  3423.1440  1044.1727  1844.9332   716.4070   724.5297   536.7027 #> [295]  5538.6813  2394.1962   775.4193   584.9660   961.8955   721.1250 #> [301]  1011.2247  3779.7490  7472.5877  3622.5482  1251.9253  7168.8023 #> [307] 13194.9787  1635.5763  4220.3257  3101.5483  4764.7523   604.2665 #> [313]  5600.3250  4725.4342  7243.9113   785.1027  1876.1982  1053.0992 #> [319]  2542.7107  1815.8703   783.9467  5279.8110  7197.4245  4981.6645 #> [325]  2507.1568  7268.1092   957.0297   766.9848 10077.2092  3145.6290 #> [331]  1894.3867   947.2618  2419.9215   591.3797   852.1338  1760.8240 #> [337]   786.8195  2365.7920   819.9425  2253.0282  3056.6147  1508.0843 #> [343]   723.4478  4830.3993  1591.5765   636.6992   867.5407 10402.1490 #> [349]  1550.0898   783.9830  1676.8807  5878.2438  7372.6980  4682.9815 #> [355] 13122.6935   826.5363  5476.3798  5258.8945   687.9012   843.7317 #> [361]  2418.3247  1501.5445 13908.2752  4132.6655  2450.8022  5924.2632 #> [367]  3804.4883  3876.5343  2582.9578  5038.9042   789.2287   730.6178 #> [373]  2483.1992  2384.6152  3655.9880   812.1138  2527.3305  4353.5707 #> [379]  8828.2037   801.5070  9394.0377  3075.7240   906.2175  6986.6612 #> [385] 13663.2685 16299.8875  2406.3842  6469.5437  5821.5367  5454.9370 #> [391]  2421.1350  5099.9688   891.2577   551.3803   696.7115   977.6382 #> [397]  3184.3738  1059.3847  2645.2907  4432.9305  9786.4027   731.3480 #> [403] 10813.7963   787.8410   678.7122  5600.6073  1883.3207  5276.5987 #> [409]  6558.7510  1669.0987  3500.1580  1053.5445  1479.2555   810.7808 #> [415]  4883.0135  7736.0078  2503.1865  9761.5165  1615.4090   537.6722 #> [421]  6871.3970   838.2523  5430.7477  5173.8000   902.8407   696.6773 #> [427]  6297.9777   759.8292  7453.3977 16131.3820  1835.8740  5056.2335 #> [433]  5244.3548   607.6573  2604.2420 16491.9482   579.9540  3521.0817 #> [439] 15761.2693 12953.4212  2586.2492  2687.6975  4405.6245 16603.0310 #> [445]  1444.7603  7286.1783  3392.8485   729.7568  6162.8988   556.3288 #> [451]   603.7973   794.5882 15167.3618  1857.6047  2225.0578  1077.5588 #> [457]   538.2143  2355.2858  2670.5743   964.9620  5609.5588  4297.6270 #> [463] 15230.4020  5243.5465  1051.6428 15440.9725  4942.6615  5794.5455 #> [469]   814.6982   964.3733  5244.1143  6311.4992  6751.7958  6668.8728 #> [475] 15351.9890  8166.6535  7992.8352 15946.6037  5573.7448  5567.4608 #> [481]   645.1293  1053.0095  5458.5748  2479.1638  4016.8212 10145.7935 #> [487]   617.9698  7566.2015  1435.6767  4169.4332  1589.0150  1860.2797 #> [493]  3774.9288  1569.7457  1169.0633  1834.2003  2201.5052 11718.0138 #> [499]  3432.9062  3218.4202 #>  #> $m_hat #>   [1] 0.076273810 0.285138889 0.168253968 0.790595238 0.010000000 0.902190476 #>   [7] 0.458753968 0.065964286 0.001111111 0.126750000 0.266448413 0.105305556 #>  [13] 0.755892857 0.074956349 0.162595238 0.105452381 0.170376984 0.265805556 #>  [19] 0.192396825 0.082083333 0.184301587 0.752547619 0.519817460 0.017857143 #>  [25] 0.939948413 0.248238095 0.526250000 0.087559524 0.892380952 0.201503968 #>  [31] 0.016079365 0.760456349 0.115150794 0.002222222 0.104535714 0.034650794 #>  [37] 0.003666667 0.382162698 0.524738095 0.072607143 0.061523810 0.056738095 #>  [43] 0.064789683 0.749015873 0.023027778 0.043238095 0.104615079 0.078388889 #>  [49] 0.000000000 0.379769841 0.970853175 0.062202381 0.949222222 0.396769841 #>  [55] 0.771972222 0.094730159 0.768170635 0.096523810 0.151142857 0.854234127 #>  [61] 0.924142857 0.600547619 0.982571429 0.155972222 0.080194444 0.093190476 #>  [67] 0.860857143 0.013416667 0.186599206 0.001428571 0.057678571 0.763099206 #>  [73] 0.468769841 0.132702381 0.779484127 0.658281746 0.720015873 0.704416667 #>  [79] 0.109388889 0.975892857 0.030392857 0.788706349 0.121007937 0.777607143 #>  [85] 0.597742063 0.961865079 0.111242063 0.150095238 0.124706349 0.198944444 #>  [91] 0.769603175 0.002000000 0.968222222 0.139595238 0.117448413 0.055063492 #>  [97] 0.698380952 0.969035714 0.760115079 0.947940476 0.247726190 0.057111111 #> [103] 0.012000000 0.435535714 0.850511905 0.080138889 0.033500000 0.801972222 #> [109] 0.183007937 0.000000000 0.749253968 0.198083333 0.006888889 0.138845238 #> [115] 0.170063492 0.313841270 0.790924603 0.706484127 0.598456349 0.070793651 #> [121] 0.351785714 0.031634921 0.040134921 0.072150794 0.127619048 0.008825397 #> [127] 0.657980159 0.059511905 0.055095238 0.153547619 0.124297619 0.253047619 #> [133] 0.005000000 0.705043651 0.719230159 0.100896825 0.780805556 0.883388889 #> [139] 0.096099206 0.803083333 0.784142857 0.147626984 0.144634921 0.613833333 #> [145] 0.020388889 0.036047619 0.083607143 0.218861111 0.125083333 0.051527778 #> [151] 0.004857143 0.953388889 0.937662698 0.045234127 0.947769841 0.083424603 #> [157] 0.041111111 0.556019841 0.834452381 0.852876984 0.724833333 0.165404762 #> [163] 0.033333333 0.943976190 0.949289683 0.112583333 0.000000000 0.065555556 #> [169] 0.038095238 0.210948413 0.122968254 0.048964286 0.652988095 0.766535714 #> [175] 0.933329365 0.837821429 0.061611111 0.025916667 0.775527167 0.111039683 #> [181] 0.247896825 0.752428571 0.094301587 0.748892857 0.007250000 0.968634921 #> [187] 0.802083333 0.647448413 0.277126984 0.165698413 0.127357143 0.015464286 #> [193] 0.902063492 0.390396825 0.429087302 0.651551587 0.754166667 0.000000000 #> [199] 0.963055556 0.551670635 0.028055556 0.056000000 0.894702381 0.188757937 #> [205] 0.160662698 0.677992063 0.738964286 0.073369048 0.125805556 0.561206349 #> [211] 0.083603175 0.987333333 0.964480159 0.690492063 0.046047619 0.067710317 #> [217] 0.218726190 0.134686508 0.645178571 0.193384921 0.864055556 0.921166667 #> [223] 0.082793651 0.702214286 0.750591270 0.039055556 0.781023810 0.444793651 #> [229] 0.624289683 0.152765873 0.730630952 0.023535714 0.032579365 0.016285714 #> [235] 0.799186508 0.043750000 0.192992063 0.228230159 0.691329365 0.061555556 #> [241] 0.740361111 0.093309524 0.869392857 0.757119048 0.072611111 0.795285714 #> [247] 0.777261905 0.879269841 0.027047619 0.414976190 0.000000000 0.866047619 #> [253] 0.860472222 0.341063492 0.650710317 0.126337302 0.493408730 0.093595238 #> [259] 0.050924603 0.141847375 0.010000000 0.883182540 0.456579365 0.067992063 #> [265] 0.012202381 0.705551587 0.137750000 0.987222222 0.082714286 0.978666667 #> [271] 0.959019841 0.884603175 0.127357143 0.155892857 0.097857143 0.537452381 #> [277] 0.053801587 0.732317460 0.123297619 0.047555556 0.041166667 0.826452381 #> [283] 0.970130952 0.944277778 0.063285714 0.041079365 0.730626984 0.013011905 #> [289] 0.017730159 0.705587302 0.822714286 0.877630952 0.012789683 0.577904762 #> [295] 0.276575397 0.173023810 0.920801587 0.159988095 0.849742063 0.037857143 #> [301] 0.140928571 0.094630952 0.051587302 0.151301587 0.920615079 0.057777778 #> [307] 0.054000000 0.024027778 0.332194444 0.399083333 0.781484127 0.063000000 #> [313] 0.385444444 0.028333333 0.114230159 0.919444444 0.773261905 0.766698413 #> [319] 0.712353175 0.571726190 0.650166667 0.056194444 0.947571429 0.010000000 #> [325] 0.674087302 0.018000000 0.207503968 0.825059524 0.741769841 0.563722222 #> [331] 0.810202381 0.211349206 0.217694444 0.652246032 0.572273810 0.660071429 #> [337] 0.916801587 0.728591270 0.744817460 0.951865079 0.773186508 0.608869048 #> [343] 0.868630952 0.045777778 0.917166667 0.134611111 0.063968254 0.062178571 #> [349] 0.515511905 0.866571429 0.756988095 0.856765873 0.912916667 0.158492063 #> [355] 0.740920635 0.810444444 0.063591270 0.348142857 0.067507937 0.002500000 #> [361] 0.435738095 0.673722222 0.117630952 0.014083333 0.366452381 0.207412698 #> [367] 0.064011905 0.091285714 0.358960317 0.002222222 0.220380952 0.858244200 #> [373] 0.786710317 0.049642857 0.027388889 0.025916667 0.101722222 0.168547619 #> [379] 0.783603175 0.024523810 0.056000000 0.591646825 0.069452381 0.035873016 #> [385] 0.929567460 0.055650794 0.161996032 0.316682540 0.080134921 0.064079365 #> [391] 0.101503968 0.012678571 0.450861111 0.209992063 0.030714286 0.911460317 #> [397] 0.180357143 0.879980159 0.050321429 0.054210317 0.086523810 0.871500000 #> [403] 0.032932540 0.841388889 0.824603175 0.756793651 0.829690476 0.000000000 #> [409] 0.790099206 0.846337302 0.316738095 0.946892857 0.876277778 0.977571429 #> [415] 0.054206349 0.919083333 0.065980159 0.076261905 0.245027778 0.021011905 #> [421] 0.934051587 0.927182540 0.076706349 0.064753968 0.933456349 0.078535714 #> [427] 0.111083333 0.887789683 0.944099206 0.015773810 0.675615079 0.109250000 #> [433] 0.352119048 0.094797619 0.061107143 0.563992063 0.056416667 0.300488095 #> [439] 0.821809524 0.048750000 0.233198413 0.178519841 0.123837302 0.621801587 #> [445] 0.378317460 0.641563492 0.082333333 0.101888889 0.076821429 0.450634921 #> [451] 0.169174603 0.872829365 0.066432540 0.125873016 0.045964286 0.864726190 #> [457] 0.337111111 0.367408730 0.310670635 0.181884921 0.066674603 0.057460317 #> [463] 0.057682540 0.726698413 0.813940476 0.729452381 0.017678571 0.071706349 #> [469] 0.024507937 0.984476190 0.000000000 0.852234127 0.073563492 0.039928571 #> [475] 0.049000000 0.825206349 0.853281746 0.051777778 0.113984127 0.085710317 #> [481] 0.163261905 0.042222222 0.622257937 0.623023810 0.005888889 0.788444444 #> [487] 0.059130342 0.872821429 0.963888889 0.021222222 0.835817460 0.580575397 #> [493] 0.035845238 0.121238095 0.044500000 0.701511905 0.033503968 0.070345238 #> [499] 0.221496032 0.672583333 #>  #> $folds #> #  5-fold cross-validation using stratification  #> # A tibble: 5 × 2 #>   splits            id    #>   <list>            <chr> #> 1 <split [399/101]> Fold1 #> 2 <split [399/101]> Fold2 #> 3 <split [400/100]> Fold3 #> 4 <split [401/99]>  Fold4 #> 5 <split [401/99]>  Fold5 #>  #> $reps #> [1] 1 #>  #> $m_fits #> NULL #>  #> $g_fits #> NULL #>  #> $lm_fit #>  #> Call: #> stats::lm(formula = y_res ~ 0 + d_res, data = dat) #>  #> Coefficients: #> d_res   #> 203.3   #>  #>  #> $vcov #>          d_res #> d_res 23747.25 #>  #> $vcov_type #> [1] \"HC2\" #>  #> $.y_orig #>   [1]   638  1402  3530  5037 13757   457  2321  5657  4372 13976 13578 10349 #>  [13]   491  5191  1443   579 17019  1309   935  2401   449  1668   608  4065 #>  [25]   847 16479  7978  9850  6750  2230  9942 14388  1791  9471  5488  4324 #>  [37]  4586  3478  2487 16805  1085 11165  5689   759  1068  1918   363  2870 #>  [49]  4106   505   795  4997   708  5564  1056   573  1279  1064   866   826 #>  [61]  1076  6754   706  2043   945   707  5102  3730  5671  2338 17197 10053 #>  [73] 10155 14543  1991  5266   812  5233  1861   918 14268  1041   544  5804 #>  [85]  7098   847  4414  1821  4077  8644 10333  4872   828   828   566  4444 #>  [97]  1221  1656   939   707  1007  4583  5632  4459  1080  4173   802  9023 #> [109]  2395  4865  2112  4935  4179  4928  5286  5110  2271   871 12712  4523 #> [121]  4725  5858  4443  9539   522  4289  4002   724   552 15686  5303  1836 #> [133]   792 11199   500  8820  2357  2189  2753  2639 11917  4751  5035 13771 #> [145]  7109  4969  1872  3557 18018  7555   574   745  9901  7350  1733   730 #> [157]   957  6070 18296   789   963  6315  4588   822 10859  8788  4652  5170 #> [169]  1852  2348 11415   545   756  8637   839   589 16314  3685   895  2531 #> [181]   568  7992  1105 18757  3655   686  4946  1385  3580   755   684  4844 #> [193]  1659   645  6295   675  1664  4737   810  2762  4470  4854   720   844 #> [205]  3428  1649  1419   880   447  1883  5215   905  1250  1775  4403  2150 #> [217]  3082  7385  3267 10098  1163  9645  4250 13263  1922   984 13588  3357 #> [229]   586  1915  1692  1289 18020  3994   863 16564   536  3166 17555   470 #> [241]  1773  6368  1341  1321   792   703  2066 14837  4155   629   895 16316 #> [253] 10342  3456  5670  4498  1158   393 12554   625  3579  1441  8341  5468 #> [265]   605 14620  4006  1033  2500  1174  1033  5412   394   855   869 18255 #> [277]  4340  7341   544   842   816   658   825  1066   949  4913   749   521 #> [289]  3697   877  1789   743   544   362  4633  2239  1080   526  1007   408 #> [301]   919  3375  8139  3260   906  7163 13542  1577  4405  5288  5939   698 #> [313]  4774  5543  4864   530  1770   662  2100  1791   746  4872  7917  3302 #> [325]  3464 10485  1181   842 10851  3152  2029  1580  3109   642   914  1817 #> [337]   936  3172   633  1883  2328  1000   816  4476   782   673  1290 11078 #> [349]  2009   561  1838  6168  6958  3154 15281  1218  3749  5919   557   709 #> [361]  2375  1587  9769  3595  2871  4295  3187  4823  2235  5226   571   589 #> [373]  3265  2401  3604   435  1827  3211  7780   661  7182  2087   726  8795 #> [385] 17005 17666  2137  5055  6871  5219  2843  2695  1179   608   533   899 #> [397]  3603  1115  2525  4791 15404   758  9600   872   680  5491  2318  7528 #> [409]  6970  1629  3210  1007  1359   829  8079  6982  2202  7211  1750   740 #> [421]  5362   463  4706  4843   810   645  8676   884  4846 15931  3791  4845 #> [433]  4807   725  2764 15852   816  3053 14061 11975  3129  2675  4223 17220 #> [445]  1803  8256  2278   928  6651   583   505   648 13732  1659  1636   825 #> [457]   535  2300  2493   695  9711  4189 16363  5044  1397 18462  7762  4853 #> [469]   863   614  4118  3777  6532  5898 13865  7549  9630 13065  7232  4504 #> [481]   541   713  3713  2409  3242 10588   642  5000  1120  3599  1284  1984 #> [493]  3303  1993  1559  1580  1951  7479  3207  3089 #>  #> $.d_orig #>   [1] FALSE FALSE FALSE TRUE  FALSE TRUE  FALSE FALSE FALSE FALSE FALSE FALSE #>  [13] TRUE  FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE  TRUE  FALSE #>  [25] TRUE  FALSE FALSE FALSE TRUE  FALSE FALSE TRUE  FALSE FALSE FALSE FALSE #>  [37] FALSE TRUE  TRUE  FALSE TRUE  FALSE FALSE TRUE  FALSE FALSE FALSE FALSE #>  [49] FALSE FALSE TRUE  FALSE TRUE  TRUE  TRUE  FALSE TRUE  FALSE FALSE TRUE  #>  [61] TRUE  TRUE  TRUE  FALSE FALSE FALSE TRUE  FALSE FALSE FALSE FALSE TRUE  #>  [73] TRUE  FALSE FALSE TRUE  FALSE TRUE  FALSE TRUE  FALSE TRUE  FALSE TRUE  #>  [85] FALSE TRUE  FALSE FALSE FALSE FALSE TRUE  FALSE FALSE FALSE FALSE FALSE #>  [97] TRUE  TRUE  TRUE  TRUE  FALSE FALSE TRUE  TRUE  TRUE  FALSE FALSE FALSE #> [109] FALSE FALSE TRUE  FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE  FALSE #> [121] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [133] FALSE TRUE  TRUE  FALSE TRUE  TRUE  FALSE TRUE  TRUE  FALSE FALSE TRUE  #> [145] FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE  TRUE  FALSE TRUE  FALSE #> [157] FALSE TRUE  TRUE  TRUE  TRUE  FALSE FALSE TRUE  TRUE  FALSE FALSE FALSE #> [169] FALSE FALSE FALSE TRUE  TRUE  FALSE TRUE  TRUE  FALSE FALSE TRUE  FALSE #> [181] FALSE FALSE FALSE TRUE  FALSE TRUE  TRUE  TRUE  FALSE FALSE FALSE FALSE #> [193] FALSE FALSE TRUE  TRUE  TRUE  FALSE TRUE  TRUE  FALSE FALSE TRUE  FALSE #> [205] FALSE TRUE  TRUE  FALSE FALSE TRUE  FALSE TRUE  FALSE FALSE TRUE  FALSE #> [217] FALSE FALSE FALSE FALSE TRUE  TRUE  FALSE TRUE  FALSE FALSE TRUE  TRUE  #> [229] FALSE FALSE TRUE  FALSE FALSE FALSE TRUE  FALSE TRUE  FALSE TRUE  FALSE #> [241] TRUE  FALSE TRUE  FALSE FALSE TRUE  TRUE  TRUE  FALSE TRUE  FALSE TRUE  #> [253] TRUE  TRUE  TRUE  FALSE TRUE  FALSE FALSE FALSE FALSE TRUE  TRUE  FALSE #> [265] FALSE FALSE FALSE TRUE  FALSE TRUE  TRUE  TRUE  FALSE FALSE FALSE FALSE #> [277] FALSE FALSE FALSE FALSE FALSE TRUE  TRUE  TRUE  FALSE FALSE TRUE  FALSE #> [289] FALSE TRUE  TRUE  TRUE  FALSE TRUE  FALSE FALSE TRUE  FALSE TRUE  FALSE #> [301] FALSE FALSE FALSE FALSE TRUE  FALSE FALSE FALSE TRUE  TRUE  FALSE FALSE #> [313] TRUE  FALSE FALSE TRUE  FALSE TRUE  FALSE TRUE  TRUE  TRUE  TRUE  FALSE #> [325] TRUE  FALSE FALSE TRUE  TRUE  FALSE TRUE  FALSE FALSE TRUE  TRUE  TRUE  #> [337] TRUE  TRUE  FALSE FALSE FALSE TRUE  FALSE FALSE TRUE  FALSE FALSE FALSE #> [349] FALSE TRUE  TRUE  FALSE TRUE  FALSE TRUE  TRUE  FALSE FALSE FALSE FALSE #> [361] TRUE  TRUE  FALSE FALSE FALSE FALSE FALSE FALSE TRUE  FALSE FALSE TRUE  #> [373] TRUE  FALSE FALSE FALSE FALSE FALSE TRUE  FALSE FALSE TRUE  FALSE FALSE #> [385] FALSE FALSE FALSE TRUE  TRUE  FALSE FALSE FALSE TRUE  FALSE FALSE TRUE  #> [397] FALSE TRUE  FALSE FALSE FALSE TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  FALSE #> [409] TRUE  TRUE  TRUE  FALSE TRUE  TRUE  FALSE TRUE  FALSE FALSE FALSE FALSE #> [421] TRUE  TRUE  FALSE FALSE TRUE  FALSE FALSE TRUE  TRUE  FALSE TRUE  FALSE #> [433] FALSE FALSE TRUE  TRUE  FALSE TRUE  TRUE  TRUE  FALSE FALSE FALSE TRUE  #> [445] TRUE  TRUE  FALSE FALSE FALSE FALSE FALSE TRUE  FALSE FALSE FALSE FALSE #> [457] TRUE  FALSE TRUE  FALSE FALSE FALSE FALSE TRUE  TRUE  TRUE  FALSE FALSE #> [469] FALSE TRUE  FALSE TRUE  FALSE FALSE FALSE FALSE TRUE  FALSE FALSE FALSE #> [481] FALSE FALSE TRUE  TRUE  FALSE TRUE  FALSE TRUE  FALSE FALSE TRUE  TRUE  #> [493] FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE  #> Levels: FALSE TRUE #>  #> $treatment_type #> [1] \"binary_factor\" #>  #> $m_workflow #> ══ Workflow ════════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: rand_forest() #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #> 2 Recipe Steps #>  #> • step_ns() #> • step_dummy() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> Random Forest Model Specification (classification) #>  #> Main Arguments: #>   trees = 100 #>  #> Computational engine: ranger  #>  #>  #> $g_workflow #> ══ Workflow ════════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: rand_forest() #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #> 3 Recipe Steps #>  #> • step_log() #> • step_impute_knn() #> • step_dummy() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> Random Forest Model Specification (regression) #>  #> Main Arguments: #>   trees = 100 #>  #> Computational engine: ranger  #>  #>  #> $call #> dml_core_wf(data = data, m_wf = m_wf, g_wf = g_wf, folds_outer = folds_outer,  #>     n_folds = n_folds, n_rep = n_rep, vcov_type = vcov_type,  #>     store_models = store_models) #>  #> attr(,\"class\") #> [1] \"dml_plr\" #> attr(,\"y_name\") #> [1] \"price\" #> attr(,\"d_name\") #> [1] \"is_rated_ideal\""},{"path":"https://jberesford-fe.github.io/tiDML/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Justin Beresford. Author, maintainer.","code":""},{"path":"https://jberesford-fe.github.io/tiDML/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Beresford J (2025). tiDML: Double Machine Learning Tidymodels. R package version 0.1.0, https://github.com/justinberesford/tiDML.","code":"@Manual{,   title = {tiDML: Double Machine Learning with Tidymodels},   author = {Justin Beresford},   year = {2025},   note = {R package version 0.1.0},   url = {https://github.com/justinberesford/tiDML}, }"},{"path":"https://jberesford-fe.github.io/tiDML/index.html","id":"tidml","dir":"","previous_headings":"","what":"Double Machine Learning with Tidymodels","title":"Double Machine Learning with Tidymodels","text":"goal tiDML twofold: Simple first pass: provide straightforward way run Double Machine Learning (DML) R. Users need pick model, specify data formula. Defaults set sensible values, ’s quick first pass ask: “OLS results change materially DML?” Run DML tidymodels way: flexible framework lets define inspect stages DML process explicitly. Specify first- second-stage models, chosing thousands parsnip models, specify preprocessing steps recipes. backend, combined workflows, used first- second-stage models DML partially linear regression. short, tiDML simplifies default models, ’s main contribution letting define examine stages DML process explicitly, way tidymodels user expect.","code":""},{"path":"https://jberesford-fe.github.io/tiDML/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Double Machine Learning with Tidymodels","text":"can install development version tiDML GitHub via pak remotes:","code":"# Using pak (recommended) pak::pak(\"jberesford-fe/tiDML\")  # Using remotes remotes::install_github(\"jberesford-fe/tiDML\")"},{"path":"https://jberesford-fe.github.io/tiDML/index.html","id":"default-model-example","dir":"","previous_headings":"","what":"Default model example","title":"Double Machine Learning with Tidymodels","text":"basic example shows run DML PLR model random forests nuisance models, taking parameters default.","code":"library(tiDML)  random_forest <- dml_rf(   data = df,   y = \"y_var\",   d = \"d_var\",   x = c(\"x1\", \"x2\", \"x3\"), )  print(random_forest)"},{"path":"https://jberesford-fe.github.io/tiDML/index.html","id":"user-defined-model-example","dir":"","previous_headings":"","what":"User defined model example","title":"Double Machine Learning with Tidymodels","text":"users requiring control (.e. moving past testing phase implementation), can Define first- second-stage models using parsnip. exmample, using random forests stages: Handle pre-processing steps, stages, using recipes. example, imputing missing values numeric predictors treatment model: Pass parsnip model specs recipes recipe run_dml() function get DML estimate. Noting data must passed run_dml() used define recipes. See getting started vignette detailed examples.","code":"outcome_model <- parsnip::rand_forest(trees = 500) |>   parsnip::set_engine(\"ranger\") |>   parsnip::set_mode(\"regression\")  treatment_model <- parsnip::rand_forest(trees = 500) |>   parsnip::set_engine(\"ranger\") |>   parsnip::set_mode(\"classification\") treatment_recipe <- recipes::recipe(d_var ~ x1 + x2 + x3, data = df) |>   recipes::step_impute_knn(recipes::all_numeric_predictors())   outcome_recipe <- recipes::recipe(y_var ~ x1 + x2 + x3, data = df) run_dml(   data = df,   outcome_model = outcome_model,   treatment_model = treatment_model,   outcome_recipe = outcome_recipe,   treatment_recipe = treatment_recipe,   n_folds = 5,   n_rep = 2, )"},{"path":"https://jberesford-fe.github.io/tiDML/reference/diamonds_sample.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample ggplot2::diamonds with a treatment column — diamonds_sample","title":"Sample ggplot2::diamonds with a treatment column — diamonds_sample","text":"Sample ggplot2::diamonds treatment column","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/diamonds_sample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample ggplot2::diamonds with a treatment column — diamonds_sample","text":"","code":"diamonds_sample(n = 10000, seed = 1)"},{"path":"https://jberesford-fe.github.io/tiDML/reference/diamonds_sample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample ggplot2::diamonds with a treatment column — diamonds_sample","text":"n Number rows sample (default 10,000). seed RNG seed reproducibility.","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/diamonds_sample.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample ggplot2::diamonds with a treatment column — diamonds_sample","text":"tibble columns ggplot2::diamonds plus D (factor 0,1).","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_core_wf.html","id":null,"dir":"Reference","previous_headings":"","what":"Core DML-PLR using workflows — dml_core_wf","title":"Core DML-PLR using workflows — dml_core_wf","text":"Core DML-PLR using workflows","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_core_wf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Core DML-PLR using workflows — dml_core_wf","text":"","code":"dml_core_wf(   data,   m_wf,   g_wf,   folds_outer = NULL,   n_folds = 5,   n_rep = 1,   vcov_type = \"HC2\",   store_models = FALSE )"},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_enet.html","id":null,"dir":"Reference","previous_headings":"","what":"DML-PLR with LASSO (glmnet) — dml_enet","title":"DML-PLR with LASSO (glmnet) — dml_enet","text":"DML-PLR LASSO (glmnet)","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_enet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"DML-PLR with LASSO (glmnet) — dml_enet","text":"","code":"dml_enet(   data,   y,   d,   x,   folds_outer = NULL,   n_folds = 5,   n_rep = 1,   vcov_type = \"HC2\",   penalty_m = 0.01,   penalty_g = 0.01,   mixture = 0.5,   penalties_grid = NULL,   store_models = FALSE )"},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_enet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"DML-PLR with LASSO (glmnet) — dml_enet","text":"data Data frame y Outcome column d Treatment column x Covariate columns folds_outer Optional rsample rset. NULL, folds made internally (stratified D). n_folds Number outer folds folds_outer NULL. n_rep Number repetitions folds_outer NULL. vcov_type Sandwich variance type (e.g., \"HC2\" \"HC3\"). penalty_m Optional single penalty (lambda) m-model (treatment). penalty_g Optional single penalty (lambda) g-model (outcome). mixture Elastic net mixing parameter (0 = ridge, 1 = lasso). store_models TRUE, keep fitted nuisance models inside result.","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_nnet.html","id":null,"dir":"Reference","previous_headings":"","what":"DML-PLR with single-hidden-layer MLP (nnet engine) — dml_nnet","title":"DML-PLR with single-hidden-layer MLP (nnet engine) — dml_nnet","text":"Uses small MLP nuisances. Adds dummy encoding nominal X normalizes numeric predictors (recommended NNs).","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_nnet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"DML-PLR with single-hidden-layer MLP (nnet engine) — dml_nnet","text":"","code":"dml_nnet(   data,   y,   d,   x,   folds_outer = NULL,   n_folds = 5,   n_rep = 1,   vcov_type = \"HC2\",   hidden_units_m = NULL,   hidden_units_g = NULL,   penalty = 0.001,   epochs = 200,   max_weights = 5000,   trace = FALSE,   store_models = FALSE )"},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_nnet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"DML-PLR with single-hidden-layer MLP (nnet engine) — dml_nnet","text":"data, y, d, x dml_rf() folds_outer Optional rsample rset. NULL, folds made internally (stratified D). n_folds Number outer folds folds_outer NULL. n_rep Number repetitions folds_outer NULL. vcov_type Sandwich variance type (e.g., \"HC2\" \"HC3\"). hidden_units_m, hidden_units_g Hidden units m- g-models (NULL = heuristic). penalty L2 penalty (.k.. weight decay). epochs Max iterations (passed nnet::nnet() via parsnip). max_weights Max allowable weights nnet engine (MaxNWts) avoid overflow. trace Logical; print nnet training trace.","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_rf.html","id":null,"dir":"Reference","previous_headings":"","what":"DML-PLR with Random Forest — dml_rf","title":"DML-PLR with Random Forest — dml_rf","text":"DML-PLR Random Forest","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_rf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"DML-PLR with Random Forest — dml_rf","text":"","code":"dml_rf(   data,   y,   d,   x,   folds_outer = NULL,   n_folds = 5,   n_rep = 1,   mtry_m = NULL,   mtry_g = NULL,   vcov_type = \"HC2\",   trees_grid = NULL,   store_models = FALSE )"},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_rf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"DML-PLR with Random Forest — dml_rf","text":"data Data frame y Outcome column d Treatment column x Covariate columns folds_outer Optional rsample rset. NULL, folds made internally (stratified D). n_folds Number outer folds folds_outer NULL. n_rep Number repetitions folds_outer NULL. vcov_type Sandwich variance type (e.g., \"HC2\" \"HC3\"). trees_grid Optional grid number trees try (m- g-models).","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/get_feature_coefs.html","id":null,"dir":"Reference","previous_headings":"","what":"Get feature coefficients from nuisance models — get_feature_coefs","title":"Get feature coefficients from nuisance models — get_feature_coefs","text":"Get feature coefficients nuisance models","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/get_feature_coefs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get feature coefficients from nuisance models — get_feature_coefs","text":"","code":"get_feature_coefs(dml_result, model = c(\"treatment\", \"outcome\"))"},{"path":"https://jberesford-fe.github.io/tiDML/reference/get_feature_coefs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get feature coefficients from nuisance models — get_feature_coefs","text":"dml_result DML result object stored nuisance models. nuisance model coefficients extract, either \"treatment\" \"outcome\".","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/get_feature_importance.html","id":null,"dir":"Reference","previous_headings":"","what":"Get feature importance from nuisance models — get_feature_importance","title":"Get feature importance from nuisance models — get_feature_importance","text":"Get feature importance nuisance models","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/get_feature_importance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get feature importance from nuisance models — get_feature_importance","text":"","code":"get_feature_importance(dml_result, model = c(\"treatment\", \"outcome\"))"},{"path":"https://jberesford-fe.github.io/tiDML/reference/get_feature_importance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get feature importance from nuisance models — get_feature_importance","text":"dml_result DML result object stored nuisance models. nuisance model coefficients extract, either \"treatment\" \"outcome\".","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/make_folds.html","id":null,"dir":"Reference","previous_headings":"","what":"Make v-fold outer folds — make_folds","title":"Make v-fold outer folds — make_folds","text":"Make v-fold outer folds","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/make_folds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make v-fold outer folds — make_folds","text":"","code":"make_folds(data, n_folds = 5)"},{"path":"https://jberesford-fe.github.io/tiDML/reference/make_folds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make v-fold outer folds — make_folds","text":"data Data frame n_folds Number folds","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/make_folds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make v-fold outer folds — make_folds","text":"rsample rset","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/make_folds_stratified.html","id":null,"dir":"Reference","previous_headings":"","what":"Make stratified v-fold outer folds (recommended for binary D) — make_folds_stratified","title":"Make stratified v-fold outer folds (recommended for binary D) — make_folds_stratified","text":"Make stratified v-fold outer folds (recommended binary D)","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/make_folds_stratified.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make stratified v-fold outer folds (recommended for binary D) — make_folds_stratified","text":"","code":"make_folds_stratified(data, d, n_folds = 5, n_rep = 1)"},{"path":"https://jberesford-fe.github.io/tiDML/reference/make_folds_stratified.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make stratified v-fold outer folds (recommended for binary D) — make_folds_stratified","text":"data Data frame d Treatment column name (string) n_folds Number folds n_rep Number repeats","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/make_folds_stratified.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make stratified v-fold outer folds (recommended for binary D) — make_folds_stratified","text":"rsample rset","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/oob_error.html","id":null,"dir":"Reference","previous_headings":"","what":"Get out of bad error — oob_error","title":"Get out of bad error — oob_error","text":"Get bad error","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/oob_error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get out of bad error — oob_error","text":"","code":"oob_error(fitted_wf)"},{"path":"https://jberesford-fe.github.io/tiDML/reference/oob_error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get out of bad error — oob_error","text":"d_vec Treatment vector","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/oob_error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get out of bad error — oob_error","text":"Treatment type string","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/oof_crossfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Out-of-fold cross-fitting for DML — oof_crossfit","title":"Out-of-fold cross-fitting for DML — oof_crossfit","text":"--fold cross-fitting DML","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/oof_crossfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Out-of-fold cross-fitting for DML — oof_crossfit","text":"","code":"oof_crossfit(   data,   folds,   m_fit_fun,   g_fit_fun,   y_name,   d_name,   store_models = FALSE )"},{"path":"https://jberesford-fe.github.io/tiDML/reference/run_dml.html","id":null,"dir":"Reference","previous_headings":"","what":"Run DML-PLR with user-supplied recipes and parsnip models — run_dml","title":"Run DML-PLR with user-supplied recipes and parsnip models — run_dml","text":"Run DML-PLR user-supplied recipes parsnip models","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/run_dml.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run DML-PLR with user-supplied recipes and parsnip models — run_dml","text":"","code":"run_dml(   data,   outcome_recipe,   treatment_recipe,   outcome_model,   treatment_model,   folds_outer = NULL,   n_folds = 5,   n_rep = 1,   vcov_type = \"HC2\",   store_models = FALSE )"},{"path":"https://jberesford-fe.github.io/tiDML/reference/treated_level.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the ","title":"Get the ","text":"Get \"treated\" level binary factor","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/treated_level.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the ","text":"","code":"treated_level(d_vec)"},{"path":"https://jberesford-fe.github.io/tiDML/reference/treated_level.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the ","text":"d_vec Binary factor vector","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/treated_level.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the ","text":"\"treated\" level (second level)","code":""}]
