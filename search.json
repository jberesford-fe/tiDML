[{"path":"https://jberesford-fe.github.io/tiDML/articles/elastic-net.html","id":"regularised-regression","dir":"Articles","previous_headings":"","what":"Regularised Regression","title":"Elastic Net (ridge/lasso)","text":"function dml_enet() defaults elastic net regression mixture = 0.5. Setting mixture = 1 gives lasso regression mixture = 0 gives ridge regression. penalty parameter (lambda) also required input parameter, can vary two nuisance models (yet chosen via cross-validation, #FIXME). Elastic Net linear model, can use get_feature_coefs(fit_lasso, model=\"treatment\") get_feature_coefs(fit_lasso, model=\"outcome\") inspect coefficients selected features.","code":"library(tiDML)  df <- diamonds_sample()  fit_lasso <- dml_enet(   data = df,   y = \"price\",   d = \"is_rated_ideal\",   x = c(\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"),   store_models = TRUE,   mixture = 1,   penalty_g = 0.1,   penalty_m = 0.1 )"},{"path":[]},{"path":"https://jberesford-fe.github.io/tiDML/articles/examine-outputs.html","id":"tidy-glance-and-augment","dir":"Articles","previous_headings":"Describing the model output","what":"tidy(), glance() and augment()","title":"Examine model outputs","text":"functions generics return coefficients, models settings, fold predictions (hat) residuals (res). outcome model (g) treatment model (m). tidy() returns coefficients standard errors glance() returns model settings augment() returns original data, predicted values, residuals","code":"library(tiDML) library(generics)  df <- diamonds_sample(n=500, seed=123)  fit_rf <- dml_rf(   data = df,   y = \"price\",   d = \"is_rated_ideal\",   x = c(\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"), ) tidy(fit_rf) #> # A tibble: 1 × 6 #>   term               estimate std.error conf.low conf.high vcov_type #>   <chr>                 <dbl>     <dbl>    <dbl>     <dbl> <chr>     #> 1 is_rated_idealTRUE     207.      209.    -203.      616. HC2 glance(fit_rf) #> # A tibble: 1 × 8 #>   n_obs n_folds vcov_type treatment_type estimate std_error conf_low conf_high #>   <int>   <int> <chr>     <chr>             <dbl>     <dbl>    <dbl>     <dbl> #> 1   500       5 HC2       binary_factor      207.      209.    -203.      616. augment(fit_rf) #> # A tibble: 500 × 7 #>     .row     y d     g_hat  m_hat   y_res   d_res #>    <int> <int> <fct> <dbl>  <dbl>   <dbl>   <dbl> #>  1     1  2397 TRUE  2958. 0.917   -561.   0.0827 #>  2     2  3300 TRUE  2323. 0.921    977.   0.0791 #>  3     3   713 TRUE   700. 0.972     12.9  0.0275 #>  4     4   707 TRUE   798. 0.836    -91.2  0.164  #>  5     5   987 TRUE   711. 0.982    276.   0.0180 #>  6     6  3250 FALSE 2950. 0        300.   0      #>  7     7  1668 FALSE 1634. 0.317     33.7 -0.317  #>  8     8  1771 FALSE 2441. 0.0753  -670.  -0.0753 #>  9     9  1053 TRUE  1021. 0.988     31.7  0.0120 #> 10    10  4640 FALSE 6643. 0.072  -2003.  -0.072  #> # ℹ 490 more rows"},{"path":"https://jberesford-fe.github.io/tiDML/articles/examine-outputs.html","id":"inspecting-the-workflow","dir":"Articles","previous_headings":"","what":"Inspecting the workflow","title":"Examine model outputs","text":"workflow defined using workflows package. combines pre-processing (recipes) model fitting (parsnip).","code":""},{"path":"https://jberesford-fe.github.io/tiDML/articles/examine-outputs.html","id":"get-the-recipepreprocessor","dir":"Articles","previous_headings":"Inspecting the workflow","what":"Get the recipe/preprocessor","title":"Examine model outputs","text":"Extract preprocessor outcome (g) model: See recipe See summary steps See variables involved want see recipe data:","code":"recipe_g <- workflows::extract_preprocessor(fit_rf$g_workflow) print(recipe_g) #>  #> ── Recipe ────────────────────────────────────────────────────────────────────── #>  #> ── Inputs #> Number of variables by role #> outcome:   1 #> predictor: 6 summary(recipe_g) #> # A tibble: 7 × 4 #>   variable type      role      source   #>   <chr>    <list>    <chr>     <chr>    #> 1 carat    <chr [2]> predictor original #> 2 depth    <chr [2]> predictor original #> 3 table    <chr [2]> predictor original #> 4 x        <chr [2]> predictor original #> 5 y        <chr [2]> predictor original #> 6 z        <chr [2]> predictor original #> 7 price    <chr [2]> outcome   original recipe_g$var_info #> # A tibble: 7 × 4 #>   variable type      role      source   #>   <chr>    <list>    <chr>     <chr>    #> 1 carat    <chr [2]> predictor original #> 2 depth    <chr [2]> predictor original #> 3 table    <chr [2]> predictor original #> 4 x        <chr [2]> predictor original #> 5 y        <chr [2]> predictor original #> 6 z        <chr [2]> predictor original #> 7 price    <chr [2]> outcome   original prepped <- recipes::prep(recipe_g, df) processed <- recipes::bake(prepped, df) processed |> head()  #> # A tibble: 6 × 7 #>   carat depth table     x     y     z price #>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <int> #> 1  0.73  60.7    56  5.85  5.81  3.54  2397 #> 2  0.7   60.8    56  5.73  5.8   3.51  3300 #> 3  0.31  61.6    55  4.3   4.33  2.66   713 #> 4  0.31  62.2    56  4.34  4.37  2.71   707 #> 5  0.31  60.9    55  4.39  4.41  2.68   987 #> 6  0.83  63.7    59  5.95  5.89  3.77  3250"},{"path":"https://jberesford-fe.github.io/tiDML/articles/examine-outputs.html","id":"get-the-model-specifications","dir":"Articles","previous_headings":"Inspecting the workflow","what":"Get the model specifications","title":"Examine model outputs","text":"see key properties","code":"model_spec_g <- workflows::extract_spec_parsnip(fit_rf$g_workflow) model_spec_m <- workflows::extract_spec_parsnip(fit_rf$m_workflow) print(model_spec_g) #> Random Forest Model Specification (regression) #>  #> Main Arguments: #>   mtry = mtry_g #>   trees = 500 #>  #> Engine-Specific Arguments: #>   respect.unordered.factors = order #>   num.threads = 1 #>   importance = if (store_models) \"impurity\" else \"none\" #>  #> Computational engine: ranger model_spec_g$engine    # \"ranger\" is used in the default random forest #> [1] \"ranger\" model_spec_g$mode      # \"regression\" for the outcome model #> [1] \"regression\" model_spec_m$mode      # \"classification\" for the treatment model, since it's binary   #> [1] \"classification\""},{"path":"https://jberesford-fe.github.io/tiDML/articles/examine-outputs.html","id":"what-are-the-hyperparameters","dir":"Articles","previous_headings":"Inspecting the workflow > Get the model specifications","what":"What are the hyperparameters?","title":"Examine model outputs","text":"","code":"model_spec_g$args #> $mtry #> <quosure> #> expr: ^mtry_g #> env:  0x560f71912670 #>  #> $trees #> <quosure> #> expr: ^500 #> env:  empty #>  #> $min_n #> <quosure> #> expr: ^NULL #> env:  empty"},{"path":"https://jberesford-fe.github.io/tiDML/articles/examine-outputs.html","id":"evaluation-metrics","dir":"Articles","previous_headings":"","what":"Evaluation metrics","title":"Examine model outputs","text":"done fold predictions. Running augment() fitted model give : actual values Y D predicted (hat) values Y D residuals Y D (.e. actual - predicted) consider plotting following: scatter plot actual vs predicted Y D histogram residuals Y D QQ plot residuals Y D consider calculating following metrics: Mean Squared Error (MSE) Y D R-squared Y D Correlation actual predicted Y D Correlation residuals Y D can use yardstick package calculate metrics. example:","code":"library(yardstick) # Mean Squared Error mse_y <- mse(data, truth = Y, estimate = .pred_Y) mse_d <- mse(data, truth = D, estimate = .pred_D) # R-squared rsq_y <- rsq(data, truth = Y, estimate = .pred_Y) rsq_d <- rsq(data, truth = D, estimate = .pred_D) # Correlation cor_y <- cor(data$Y, data$.pred_Y) cor_d <- cor(data$D, data$.pred_D)"},{"path":"https://jberesford-fe.github.io/tiDML/articles/feature-importance.html","id":"storing-fitted-models","dir":"Articles","previous_headings":"","what":"Storing fitted models","title":"Extract feature importance","text":"either default dml_XX() functions, running custom run_dml(), option store fitted models (across folds reps) setting store_models = TRUE. allows extract feature importance measures underlying models. Warning: can use lot memory, especially using large number folds reps.","code":""},{"path":"https://jberesford-fe.github.io/tiDML/articles/feature-importance.html","id":"saving-with-store_models-true","dir":"Articles","previous_headings":"Storing fitted models","what":"Saving with store_models = TRUE","title":"Extract feature importance","text":"","code":"library(tiDML)  df <- diamonds_sample(n=500, seed=123)  fit_rf <- dml_rf(   data = df,   y = \"price\",   d = \"is_rated_ideal\",   x = c(\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"),   store_models = TRUE )"},{"path":"https://jberesford-fe.github.io/tiDML/articles/feature-importance.html","id":"extracting-coefficients-linear-models","dir":"Articles","previous_headings":"","what":"Extracting coefficients (linear models)","title":"Extract feature importance","text":"linear models (e.g. Lasso), can extract regression coefficients directly. default settings (5 cross folds, 1 rep) 10 sets regression coefficients: five treatment five outcome. access treatment model , say, third crossfold, save lasso regression fit <- dml_XX(...) use generics package extract coefficients: generics::tidy(fit$m_fit[[3]]). tiDML’s get_feature_coefs() function wrapper around maps across cross folds give single tibble coefficients folds reps.","code":"fit_lasso <- dml_enet(   data = df,   y = \"price\",   d = \"is_rated_ideal\",   x = c(\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"),   store_models = TRUE,   mixture = 1 )  get_feature_coefs(fit_lasso) #> # A tibble: 35 × 5 #>     fold model     term        estimate penalty #>    <int> <chr>     <chr>          <dbl>   <dbl> #>  1     1 treatment (Intercept)  88.6       0.01 #>  2     1 treatment carat        -0.409     0.01 #>  3     1 treatment depth        -0.587     0.01 #>  4     1 treatment table        -0.918     0.01 #>  5     1 treatment x             0         0.01 #>  6     1 treatment y             0         0.01 #>  7     1 treatment z            -0.0137    0.01 #>  8     2 treatment (Intercept)  98.3       0.01 #>  9     2 treatment carat        -0.677     0.01 #> 10     2 treatment depth        -0.699     0.01 #> # ℹ 25 more rows"},{"path":"https://jberesford-fe.github.io/tiDML/articles/feature-importance.html","id":"extracting-feature-importance-tree-based-models","dir":"Articles","previous_headings":"","what":"Extracting feature importance (tree based models)","title":"Extract feature importance","text":"Feature importance can extracted tree based models (decision trees, random forests, gradient boosted trees). function get_feature_importance() extracts feature importance measures fitted models returns tidy data frame. can average importance across folds reps, plot feature importance distribution.","code":"feature_importance <- get_feature_importance(fit_rf, model = \"outcome\") #> Warning: Unknown or uninitialised column: `id2`. #> Unknown or uninitialised column: `id2`. #> Unknown or uninitialised column: `id2`. #> Unknown or uninitialised column: `id2`. #> Unknown or uninitialised column: `id2`.  print(feature_importance) #> # A tibble: 30 × 3 #>    rep   variable  importance #>    <chr> <chr>          <dbl> #>  1 Fold1 carat    1734464833. #>  2 Fold1 depth     127880049. #>  3 Fold1 table      89751947. #>  4 Fold1 x        1316805359. #>  5 Fold1 y        1776542407. #>  6 Fold1 z        1183376993. #>  7 Fold2 carat    1284648350. #>  8 Fold2 depth     114125800. #>  9 Fold2 table      79570451. #> 10 Fold2 x        1231529000. #> # ℹ 20 more rows library(ggplot2)  feature_importance |>   ggplot(aes(importance, reorder(variable, importance))) +   geom_violin(fill=\"#425a7f\", colour=\"#425a7f\") +   labs(x=\"Distribution of importance across folds\", y=\"Feature\")"},{"path":[]},{"path":"https://jberesford-fe.github.io/tiDML/articles/neural-network.html","id":"import-data-and-libraries","dir":"Articles","previous_headings":"Run a neural network with default settings","what":"Import data and libraries","title":"Neural Network","text":"","code":"library(tiDML) library(dplyr) library(recipes) library(parsnip)  # Import first 10k rows of diamonds data df <- diamonds_sample(n=500)"},{"path":"https://jberesford-fe.github.io/tiDML/articles/neural-network.html","id":"neural-network-with-default-settings","dir":"Articles","previous_headings":"","what":"Neural network with default settings","title":"Neural Network","text":"","code":"fit_nnet <- dml_nnet(   data = df,   y = \"price\",   d = \"is_rated_ideal\",   x = c(\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"), )  tidy(fit_nnet) #> # A tibble: 1 × 6 #>   term               estimate std.error conf.low conf.high vcov_type #>   <chr>                 <dbl>     <dbl>    <dbl>     <dbl> <chr>     #> 1 is_rated_idealTRUE     373.      259.    -135.      881. HC2"},{"path":"https://jberesford-fe.github.io/tiDML/articles/neural-network.html","id":"run-a-neural-network-with-custom-settings","dir":"Articles","previous_headings":"","what":"Run a neural network with custom settings","title":"Neural Network","text":"’s possible customise default dml_nnet() degree. set custom penalty rate, number epochs, maximum number weights. also choose number layers (yet true, currently ’s single layer) hidden units (nodes per layer) . Setting hidden units NULL let function choose number hidden units automatically.","code":"fit_nnet <- dml_nnet(   data = df,   y = \"price\",   d = \"is_rated_ideal\",   x = c(\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"),   n_folds = 5,   n_rep = 3,   vcov_type = \"HC2\",   hidden_units_m = 6,   hidden_units_g = 7,   penalty = 0.001,   epochs = 200,   max_weights = 5000,   trace = FALSE   )  fit_nnet |> tidy() #> # A tibble: 1 × 6 #>   term               estimate std.error conf.low conf.high vcov_type #>   <chr>                 <dbl>     <dbl>    <dbl>     <dbl> <chr>     #> 1 is_rated_idealTRUE     249.      179.    -102.      600. HC2"},{"path":"https://jberesford-fe.github.io/tiDML/articles/package-rep.html","id":"replication-of-doubleml-results-with-tidml","dir":"Articles","previous_headings":"","what":"Replication of DoubleML results with tiDML","title":"DoubleML Replication","text":"use 401k data replicate results Chernozhukov et al. (2018). Note example given package documentation. goal show - 100 iterations - tiDML produces identical results, less code interpretable output. code takes several hours run. ease, saved results 100 iterations (5 cross folds, 2 reps) inst/extdata folder. regenerate , clone repo set run_long true params.","code":""},{"path":"https://jberesford-fe.github.io/tiDML/articles/package-rep.html","id":"get-data-and-import-packages","dir":"Articles","previous_headings":"","what":"Get data and import packages","title":"DoubleML Replication","text":"import 401k data, load DoubleML (required packages). Define outcome, treatment, control variables following Chernozhukov et al. (2018) exactly.","code":"library(tiDML) library(dplyr) library(purrr) library(tibble) library(ggplot2) library(DoubleML) library(mlr3) library(mlr3learners) df401k <- DoubleML::fetch_401k(return_type = \"data.frame\", instrument = FALSE) y_col  <- \"net_tfa\" d_col  <- \"e401\" x_cols <- c(\"age\",\"inc\",\"educ\",\"fsize\",\"marr\",\"twoearn\",\"db\",\"pira\",\"hown\")"},{"path":"https://jberesford-fe.github.io/tiDML/articles/package-rep.html","id":"tidml-approach","dir":"Articles","previous_headings":"","what":"tiDML approach","title":"DoubleML Replication","text":"following Chernozhukov, use random forest stages. Since e401 dummy variable, first stage classification second regression.","code":"run_tidml <- function(seed, df, y, d, x, trees_grid, n_folds, n_rep) {   set.seed(seed)      df <- df |> mutate(!!d := as.factor(!!rlang::sym(d)))    fit_tidml <- dml_rf(     data = df,     y = !!rlang::sym(y),     d = !!rlang::sym(d),     x = x,     trees_grid = trees_grid,     n_folds = n_folds,     n_rep = n_rep,   )    return(tibble(     method = \"tiDML\",     seed = seed,     theta = unname(fit_tidml$estimate),     se    = unname(fit_tidml$se)   ) |>     mutate(       lwr = theta - stats::qnorm(0.975) * se,       upr = theta + stats::qnorm(0.975) * se     )) }"},{"path":"https://jberesford-fe.github.io/tiDML/articles/package-rep.html","id":"doubleml-approach","dir":"Articles","previous_headings":"","what":"DoubleML approach","title":"DoubleML Replication","text":"Next use DoubleML package run model.","code":"run_dml <- function(seed, df, y, d, x, trees_grid, n_folds, n_rep) {   set.seed(seed)   ## DoubleML :: PLR with ranger   ml_l <- lrn(\"regr.ranger\",               num.trees = trees_grid,                num.threads = 1,               respect.unordered.factors = \"order\")      ml_m <- lrn(     \"classif.ranger\",     num.trees = trees_grid,     num.threads = 1,     predict_type=\"prob\"   )    dml_data <- DoubleMLData$new(     data = df,      y_col = y,      d_cols = d,      x_cols = x   )    dml <- DoubleMLPLR$new(     dml_data,      ml_l = ml_l,      ml_m = ml_m,     n_folds = n_folds,     n_rep = n_rep,     score = \"partialling out\"   )    dml$fit()    ci <- dml$confint(level = 0.95)   return(tibble(     method = \"DoubleML\",     seed = seed,     theta = as.numeric(dml$coef),     se    = as.numeric(dml$se),     lwr   = as.numeric(ci[1]),     upr   = as.numeric(ci[2])   )   ) }"},{"path":"https://jberesford-fe.github.io/tiDML/articles/package-rep.html","id":"run-both-methods-across-many-replications","dir":"Articles","previous_headings":"","what":"Run both methods across many replications","title":"DoubleML Replication","text":"wrapper function runs methods returns combined data frame. want run long code , can load saved results :","code":"replications <- 100L  run_both <- function(seed, df, y, d, x, trees_grid = 1200, n_folds = 2L, n_rep = 2L) {   tidml_row <- run_tidml(seed, df, y, d, x, trees_grid, n_folds, n_rep)   dml_row   <- run_dml(seed, df, y, d, x, trees_grid, n_folds, n_rep)   bind_rows(tidml_row, dml_row) }  seeds <- 401 + 0:(replications-1L)   res <- map_dfr(   seeds,   ~ run_both(.x, df = df401k, y = y_col, d = d_col, x = x_cols) ) res <- tiDML::replication_results()"},{"path":"https://jberesford-fe.github.io/tiDML/articles/package-rep.html","id":"method-by-method-densities","dir":"Articles","previous_headings":"","what":"Method-by-method densities","title":"DoubleML Replication","text":"randomness methods estimates vary across seeds. plot densities estimates across replications show overlap similar means.","code":"ggplot(res, aes(theta, fill = method)) +   geom_density(alpha = 0.35) +   geom_vline(     data = res %>% group_by(method) %>% summarize(mean_theta = mean(theta)),     aes(xintercept = mean_theta, color = method),     linetype = \"dashed\", size = 1, show.legend = FALSE   ) +   labs(     title = \"DML-PLR estimates across seeds\",     x = \"Theta\", y = \"Density\", fill = \"Method\", colour= \"Method\"   ) +   theme_minimal(base_size = 12)"},{"path":"https://jberesford-fe.github.io/tiDML/articles/package-rep.html","id":"t-test-shows-no-differences-between-packages","dir":"Articles","previous_headings":"","what":"T-Test shows no differences between packages","title":"DoubleML Replication","text":"statistically significant difference mean, standard error, confidence intervals. Theta’s equal: Standard error’s equal: Upper lower bound confidence interval’s equal:","code":"is_not_significant <- function(x, group, data, alpha = 0.05) {   pval <- stats::t.test(stats::reformulate(group, x), data = data)$p.value   pval >= alpha }  same_theta <- is_not_significant(\"theta\", \"method\", res) same_se    <- is_not_significant(\"se\",    \"method\", res) same_lwr    <- is_not_significant(\"lwr\", \"method\", res) same_upr    <- is_not_significant(\"upr\", \"method\", res) same_theta #> [1] TRUE same_se #> [1] TRUE same_lwr #> [1] TRUE same_upr #> [1] TRUE"},{"path":"https://jberesford-fe.github.io/tiDML/articles/random-forest.html","id":"load-packages-and-data","dir":"Articles","previous_headings":"","what":"Load packages and data","title":"Random Forest","text":"","code":"library(tiDML) library(tiDML) library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(recipes) #>  #> Attaching package: 'recipes' #> The following object is masked from 'package:stats': #>  #>     step library(parsnip)"},{"path":"https://jberesford-fe.github.io/tiDML/articles/random-forest.html","id":"random-forest-with-default-settings","dir":"Articles","previous_headings":"","what":"Random forest with default settings","title":"Random Forest","text":"Import small sample data ggplot2’s diamonds dataset (500 rows). basic setup Random Forest :","code":"df <- diamonds_sample(n=500, seed=123) fit_rf <- dml_rf(   data = df,   y = \"price\",   d = \"is_rated_ideal\",   x = c(\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"), )"},{"path":"https://jberesford-fe.github.io/tiDML/articles/random-forest.html","id":"random-forest-with-custom-settings","dir":"Articles","previous_headings":"","what":"Random Forest with custom settings","title":"Random Forest","text":"can also customise default dml_rf() degree. set custom grid number trees try hyperparameter tuning (NB tests 100 200, rather everything ). can also set number folds cross-fitting type robust standard errors use (choice “HC0”, “HC1”, “HC2”, “HC3”, “HC4”).","code":"fit_rf <- dml_rf(   data = df,   y = \"price\",   d = \"is_rated_ideal\",   x = c(\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"),   n_folds = 5,   n_rep = 3,   vcov_type = \"HC2\",   trees_grid = c(100, 200))  tidy(fit_rf) #> # A tibble: 1 × 6 #>   term               estimate std.error conf.low conf.high vcov_type #>   <chr>                 <dbl>     <dbl>    <dbl>     <dbl> <chr>     #> 1 is_rated_idealTRUE     175.      211.    -239.      588. HC2"},{"path":"https://jberesford-fe.github.io/tiDML/articles/tiDML.html","id":"first-pass-with-tidml","dir":"Articles","previous_headings":"","what":"First pass with tiDML","title":"Intro to tiDML","text":"simplest case, can use package complete default settings. Pick model, specify data, outcome variable, treatment variable, covariates, hit go. Currently, default models available : dml_rf() random forest, dml_nnet() neural network. use diamonds data ggplot2 estimate effect rated “ideal” diamonds’ price, controlled caret, depth, size.","code":"library(tiDML)  df <- diamonds_sample(n=500)  fit_rf <- dml_rf(   data = df,   y = \"price\",   d = \"is_rated_ideal\",   x = c(\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"), )  fit_rf$estimate #> [1] 148.6011"},{"path":"https://jberesford-fe.github.io/tiDML/articles/tiDML.html","id":"checking-model-outputs","dir":"Articles","previous_headings":"","what":"Checking model outputs","title":"Intro to tiDML","text":"benefit using tiDML (tidymodels ecosystem generally) can rely packages like generics workflows examine inputs outputs model.","code":""},{"path":"https://jberesford-fe.github.io/tiDML/articles/tiDML.html","id":"tidy","dir":"Articles","previous_headings":"Checking model outputs","what":"tidy()","title":"Intro to tiDML","text":"Tidy returns tibble point estimate, standard error, t-value, p-value, confidence interval.","code":"# Coefficients and standard errors generics::tidy(fit_rf) #> # A tibble: 1 × 6 #>   term               estimate std.error conf.low conf.high vcov_type #>   <chr>                 <dbl>     <dbl>    <dbl>     <dbl> <chr>     #> 1 is_rated_idealTRUE     149.      165.    -174.      472. HC2"},{"path":"https://jberesford-fe.github.io/tiDML/articles/tiDML.html","id":"glance","dir":"Articles","previous_headings":"Checking model outputs","what":"glance()","title":"Intro to tiDML","text":"Glance returns tibble inputs settings used DML estimation.","code":"generics::glance(fit_rf) #> # A tibble: 1 × 8 #>   n_obs n_folds vcov_type treatment_type estimate std_error conf_low conf_high #>   <int>   <int> <chr>     <chr>             <dbl>     <dbl>    <dbl>     <dbl> #> 1   500       5 HC2       binary_factor      149.      165.    -174.      472."},{"path":"https://jberesford-fe.github.io/tiDML/articles/tiDML.html","id":"augment","dir":"Articles","previous_headings":"Checking model outputs","what":"augment()","title":"Intro to tiDML","text":"Augment returns tibble original data, predicted values, residuals outcome treatment variables. --fold predictions residuals, handy diagnostics.","code":"generics::augment(fit_rf) |> head() #> # A tibble: 6 × 7 #>    .row     y d     g_hat m_hat  y_res  d_res #>   <int> <int> <fct> <dbl> <dbl>  <dbl>  <dbl> #> 1     1   638 FALSE  994. 0.139  -356. -0.139 #> 2     2  1402 FALSE 1579. 0.225  -177. -0.225 #> 3     3  3530 FALSE 5390. 0.092 -1860. -0.092 #> 4     4  5037 TRUE  5872. 0.871  -835.  0.129 #> 5     5 13757 FALSE 7996. 0.01   5761. -0.01  #> 6     6   457 TRUE   727. 0.859  -270.  0.141"},{"path":"https://jberesford-fe.github.io/tiDML/articles/tiDML.html","id":"examine-the-workflow-recipe-and-model-specs","dir":"Articles","previous_headings":"Checking model outputs","what":"Examine the workflow (recipe and model specs)","title":"Intro to tiDML","text":"workflows package used manage preprocessing model fitting steps. can extract (unfitted) workflow object examine . Note fitted workflow can extracted, isn’t useful since DML uses cross-fitting. Much detail given Articles section. See vignette(\"examine-outputs\").","code":"# Examine the treatment model workflow print(\"Treatment model workflow:\") #> [1] \"Treatment model workflow:\" fit_rf$m_workflow #> ══ Workflow ════════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: rand_forest() #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #> 0 Recipe Steps #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> Random Forest Model Specification (classification) #>  #> Main Arguments: #>   mtry = mtry_m #>   trees = 500 #>   min_n = min_n_val #>  #> Engine-Specific Arguments: #>   num.threads = 1 #>   probability = (treatment_type == \"binary_factor\") #>   importance = if (store_models) \"impurity\" else \"none\" #>  #> Computational engine: ranger  print(\"Outcome model workflow:\") #> [1] \"Outcome model workflow:\" fit_rf$g_workflow #> ══ Workflow ════════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: rand_forest() #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #> 0 Recipe Steps #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> Random Forest Model Specification (regression) #>  #> Main Arguments: #>   mtry = mtry_g #>   trees = 500 #>  #> Engine-Specific Arguments: #>   respect.unordered.factors = order #>   num.threads = 1 #>   importance = if (store_models) \"impurity\" else \"none\" #>  #> Computational engine: ranger"},{"path":"https://jberesford-fe.github.io/tiDML/articles/tiDML.html","id":"setting-your-own-models","dir":"Articles","previous_headings":"","what":"Setting your own models","title":"Intro to tiDML","text":"can also set models using parsnip recipes. gives control model specifications preprocessing steps. See vignette(\"user-defined-recipies\") instructions.","code":""},{"path":"https://jberesford-fe.github.io/tiDML/articles/user-defined.html","id":"three-steps-to-your-own-model","dir":"Articles","previous_headings":"","what":"Three steps to your own model","title":"User Defined","text":"define DML procedure, need three things: Define model specifications (using parsnip) Define recipes (using recipes) Run DML procedure (using run_dml())","code":""},{"path":"https://jberesford-fe.github.io/tiDML/articles/user-defined.html","id":"define-your-model-specs","dir":"Articles","previous_headings":"Three steps to your own model","what":"1. Define your model specs","title":"User Defined","text":"define using parsnip package. literally thousands available models, see parsnip documentation comprehensive list examples.","code":"library(tiDML)  # Test dml_rf df = diamonds_sample(n=500, seed=123)  # parsnip model spec  g_spec = parsnip::rand_forest(trees = 100) |>   parsnip::set_engine(\"ranger\") |>   parsnip::set_mode(\"regression\")  m_spec = parsnip::rand_forest(trees = 100) |>   parsnip::set_engine(\"ranger\") |>   parsnip::set_mode(\"classification\")"},{"path":"https://jberesford-fe.github.io/tiDML/articles/user-defined.html","id":"define-your-own-recipes","dir":"Articles","previous_headings":"Three steps to your own model","what":"2. Define your own recipes","title":"User Defined","text":"","code":"g_rec <- recipes::recipe(price ~ carat + depth + table + x + y + z, data = df) |>   recipes::step_log('carat') |> # Take log for a given column name   recipes::step_impute_knn(recipes::all_numeric_predictors()) |> # Impute missing values for all numeric columns   recipes::step_dummy(recipes::all_nominal(), -recipes::all_outcomes()) # Note the exclusion of outcome variables with -  m_rec <- recipes::recipe(is_rated_ideal ~ carat + depth + table + x + y + z, data = df) |>   recipes::step_ns(carat, deg_free = 3) |>   recipes::step_dummy(recipes::all_nominal(), -recipes::all_outcomes())"},{"path":"https://jberesford-fe.github.io/tiDML/articles/user-defined.html","id":"finally-run-the-dml-procedure","dir":"Articles","previous_headings":"Three steps to your own model","what":"Finally, run the DML procedure","title":"User Defined","text":"Use model specs recipes defined inputs run_dml(). dataframe going run_dml() must one used define recipes.","code":"fit <- run_dml(   data = df,   outcome_recipe = g_rec,   treatment_recipe = m_rec,   outcome_model = g_spec,   treatment_model = m_spec, )"},{"path":"https://jberesford-fe.github.io/tiDML/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Justin Beresford. Author, maintainer.","code":""},{"path":"https://jberesford-fe.github.io/tiDML/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Beresford J (2025). tiDML: Double Machine Learning Tidymodels. R package version 0.1.0, https://github.com/justinberesford/tiDML.","code":"@Manual{,   title = {tiDML: Double Machine Learning with Tidymodels},   author = {Justin Beresford},   year = {2025},   note = {R package version 0.1.0},   url = {https://github.com/justinberesford/tiDML}, }"},{"path":"https://jberesford-fe.github.io/tiDML/index.html","id":"tidml","dir":"","previous_headings":"","what":"Double Machine Learning with Tidymodels","title":"Double Machine Learning with Tidymodels","text":"goal tiDML twofold: Simple first pass: provide straightforward way run Double Machine Learning (DML) R. Users need pick model, specify data formula. Defaults set sensible values, ’s quick first pass ask: “OLS results change materially DML?” Run DML tidymodels way: flexible framework lets define inspect stages DML process explicitly. Specify first- second-stage models, chosing thousands parsnip models, specify preprocessing steps recipes. backend, combined workflows, used first- second-stage models DML partially linear regression. short, tiDML simplifies default models, ’s main contribution letting define examine stages DML process explicitly, way tidymodels user expect.","code":""},{"path":"https://jberesford-fe.github.io/tiDML/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Double Machine Learning with Tidymodels","text":"can install development version tiDML GitHub via pak remotes:","code":"# Using pak (recommended) pak::pak(\"jberesford-fe/tiDML\")  # Using remotes remotes::install_github(\"jberesford-fe/tiDML\")"},{"path":"https://jberesford-fe.github.io/tiDML/index.html","id":"default-model-example","dir":"","previous_headings":"","what":"Default model example","title":"Double Machine Learning with Tidymodels","text":"basic example shows run DML PLR model random forests nuisance models, taking parameters default.","code":"library(tiDML)  random_forest <- dml_rf(   data = df,   y = \"y_var\",   d = \"d_var\",   x = c(\"x1\", \"x2\", \"x3\"), )  print(random_forest)"},{"path":"https://jberesford-fe.github.io/tiDML/index.html","id":"user-defined-model-example","dir":"","previous_headings":"","what":"User defined model example","title":"Double Machine Learning with Tidymodels","text":"users requiring control (.e. moving past testing phase implementation), can Define first- second-stage models using parsnip. exmample, using random forests stages: Handle pre-processing steps, stages, using recipes. example, imputing missing values numeric predictors treatment model: Pass parsnip model specs recipes recipe run_dml() function get DML estimate. Noting data must passed run_dml() used define recipes. See getting started vignette detailed examples.","code":"outcome_model <- parsnip::rand_forest(trees = 500) |>   parsnip::set_engine(\"ranger\") |>   parsnip::set_mode(\"regression\")  treatment_model <- parsnip::rand_forest(trees = 500) |>   parsnip::set_engine(\"ranger\") |>   parsnip::set_mode(\"classification\") treatment_recipe <- recipes::recipe(d_var ~ x1 + x2 + x3, data = df) |>   recipes::step_impute_knn(recipes::all_numeric_predictors())   outcome_recipe <- recipes::recipe(y_var ~ x1 + x2 + x3, data = df) run_dml(   data = df,   outcome_model = outcome_model,   treatment_model = treatment_model,   outcome_recipe = outcome_recipe,   treatment_recipe = treatment_recipe,   n_folds = 5,   n_rep = 2, )"},{"path":"https://jberesford-fe.github.io/tiDML/reference/diamonds_sample.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample ggplot2::diamonds with a treatment column — diamonds_sample","title":"Sample ggplot2::diamonds with a treatment column — diamonds_sample","text":"Sample ggplot2::diamonds treatment column","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/diamonds_sample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample ggplot2::diamonds with a treatment column — diamonds_sample","text":"","code":"diamonds_sample(n = 10000, seed = 1)"},{"path":"https://jberesford-fe.github.io/tiDML/reference/diamonds_sample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample ggplot2::diamonds with a treatment column — diamonds_sample","text":"n Number rows sample (default 10,000). seed RNG seed reproducibility.","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/diamonds_sample.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample ggplot2::diamonds with a treatment column — diamonds_sample","text":"tibble columns ggplot2::diamonds plus D (factor {0,1}).","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_core_wf.html","id":null,"dir":"Reference","previous_headings":"","what":"Core DML-PLR using workflows — dml_core_wf","title":"Core DML-PLR using workflows — dml_core_wf","text":"Core DML-PLR using workflows","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_core_wf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Core DML-PLR using workflows — dml_core_wf","text":"","code":"dml_core_wf(   data,   m_wf,   g_wf,   folds_outer = NULL,   n_folds = 5,   n_rep = 1,   vcov_type = \"HC2\",   store_models = FALSE )"},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_enet.html","id":null,"dir":"Reference","previous_headings":"","what":"DML-PLR with LASSO (glmnet) — dml_enet","title":"DML-PLR with LASSO (glmnet) — dml_enet","text":"DML-PLR LASSO (glmnet)","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_enet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"DML-PLR with LASSO (glmnet) — dml_enet","text":"","code":"dml_enet(   data,   y,   d,   x,   folds_outer = NULL,   n_folds = 5,   n_rep = 1,   vcov_type = \"HC2\",   penalty_m = 0.01,   penalty_g = 0.01,   mixture = 0.5,   penalties_grid = NULL,   store_models = FALSE )"},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_enet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"DML-PLR with LASSO (glmnet) — dml_enet","text":"data Data frame y Outcome column d Treatment column x Covariate columns folds_outer Optional rsample rset. NULL, folds made internally (stratified D). n_folds Number outer folds folds_outer NULL. n_rep Number repetitions folds_outer NULL. vcov_type Sandwich variance type (e.g., \"HC2\" \"HC3\"). penalty_m Optional single penalty (lambda) m-model (treatment). penalty_g Optional single penalty (lambda) g-model (outcome). mixture Elastic net mixing parameter (0 = ridge, 1 = lasso). penalties_grid Optional list penalty grids hyperparameter tuning (W..P.) store_models TRUE, keep fitted nuisance models inside result.","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_nnet.html","id":null,"dir":"Reference","previous_headings":"","what":"DML-PLR with single-hidden-layer MLP (nnet engine) — dml_nnet","title":"DML-PLR with single-hidden-layer MLP (nnet engine) — dml_nnet","text":"Uses small MLP nuisances. Adds dummy encoding nominal X normalizes numeric predictors (recommended NNs).","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_nnet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"DML-PLR with single-hidden-layer MLP (nnet engine) — dml_nnet","text":"","code":"dml_nnet(   data,   y,   d,   x,   folds_outer = NULL,   n_folds = 5,   n_rep = 1,   vcov_type = \"HC2\",   hidden_units_m = NULL,   hidden_units_g = NULL,   penalty = 0.001,   epochs = 200,   max_weights = 5000,   trace = FALSE,   store_models = FALSE )"},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_nnet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"DML-PLR with single-hidden-layer MLP (nnet engine) — dml_nnet","text":"data, y, d, x dml_rf() folds_outer Optional rsample rset. NULL, folds made internally (stratified D). n_folds Number outer folds folds_outer NULL. n_rep Number repetitions folds_outer NULL. vcov_type Sandwich variance type (e.g., \"HC2\" \"HC3\"). hidden_units_m, hidden_units_g Hidden units m- g-models (NULL = heuristic). penalty L2 penalty (.k.. weight decay). epochs Max iterations (passed nnet::nnet() via parsnip). max_weights Max allowable weights nnet engine (MaxNWts) avoid overflow. trace Logical; print nnet training trace. store_models TRUE, keep fitted nuisance models inside result.","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_rf.html","id":null,"dir":"Reference","previous_headings":"","what":"DML-PLR with Random Forest — dml_rf","title":"DML-PLR with Random Forest — dml_rf","text":"DML-PLR Random Forest","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_rf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"DML-PLR with Random Forest — dml_rf","text":"","code":"dml_rf(   data,   y,   d,   x,   folds_outer = NULL,   n_folds = 5,   n_rep = 1,   mtry_m = NULL,   mtry_g = NULL,   vcov_type = \"HC2\",   trees_grid = NULL,   store_models = FALSE )"},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_rf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"DML-PLR with Random Forest — dml_rf","text":"data Data frame y Outcome column d Treatment column x Covariate columns folds_outer Optional rsample rset. NULL, folds made internally (stratified D). n_folds Number outer folds folds_outer NULL. n_rep Number repetitions folds_outer NULL. mtry_m Number variables randomly sampled candidates split m-model (treatment). Default: floor(p/3). mtry_g Number variables randomly sampled candidates split g-model (outcome). Default: floor(p/3). vcov_type Sandwich variance type (e.g., \"HC2\" \"HC3\"). trees_grid Optional grid number trees try (m- g-models). store_models TRUE, keep fitted nuisance models inside result.","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/get_feature_coefs.html","id":null,"dir":"Reference","previous_headings":"","what":"Get feature coefficients from nuisance models — get_feature_coefs","title":"Get feature coefficients from nuisance models — get_feature_coefs","text":"Get feature coefficients nuisance models","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/get_feature_coefs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get feature coefficients from nuisance models — get_feature_coefs","text":"","code":"get_feature_coefs(dml_result, model = c(\"treatment\", \"outcome\"))"},{"path":"https://jberesford-fe.github.io/tiDML/reference/get_feature_coefs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get feature coefficients from nuisance models — get_feature_coefs","text":"dml_result DML result object stored nuisance models. model nuisance model coefficients extract, either \"treatment\" \"outcome\".","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/get_feature_importance.html","id":null,"dir":"Reference","previous_headings":"","what":"Get feature importance from nuisance models — get_feature_importance","title":"Get feature importance from nuisance models — get_feature_importance","text":"Get feature importance nuisance models","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/get_feature_importance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get feature importance from nuisance models — get_feature_importance","text":"","code":"get_feature_importance(dml_result, model = c(\"treatment\", \"outcome\"))"},{"path":"https://jberesford-fe.github.io/tiDML/reference/get_feature_importance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get feature importance from nuisance models — get_feature_importance","text":"dml_result DML result object stored nuisance models. model nuisance model coefficients extract, either \"treatment\" \"outcome\".","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/make_folds.html","id":null,"dir":"Reference","previous_headings":"","what":"Make v-fold outer folds — make_folds","title":"Make v-fold outer folds — make_folds","text":"Make v-fold outer folds","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/make_folds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make v-fold outer folds — make_folds","text":"","code":"make_folds(data, n_folds = 5)"},{"path":"https://jberesford-fe.github.io/tiDML/reference/make_folds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make v-fold outer folds — make_folds","text":"data Data frame n_folds Number folds","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/make_folds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make v-fold outer folds — make_folds","text":"rsample rset","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/make_folds_stratified.html","id":null,"dir":"Reference","previous_headings":"","what":"Make stratified v-fold outer folds (recommended for binary D) — make_folds_stratified","title":"Make stratified v-fold outer folds (recommended for binary D) — make_folds_stratified","text":"Make stratified v-fold outer folds (recommended binary D)","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/make_folds_stratified.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make stratified v-fold outer folds (recommended for binary D) — make_folds_stratified","text":"","code":"make_folds_stratified(data, d, n_folds = 5, n_rep = 1)"},{"path":"https://jberesford-fe.github.io/tiDML/reference/make_folds_stratified.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make stratified v-fold outer folds (recommended for binary D) — make_folds_stratified","text":"data Data frame d Treatment column name (string) n_folds Number folds n_rep Number repeats","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/make_folds_stratified.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make stratified v-fold outer folds (recommended for binary D) — make_folds_stratified","text":"rsample rset","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/oob_error.html","id":null,"dir":"Reference","previous_headings":"","what":"Get out of bag error — oob_error","title":"Get out of bag error — oob_error","text":"Get bag error","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/oob_error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get out of bag error — oob_error","text":"","code":"oob_error(fitted_wf)"},{"path":"https://jberesford-fe.github.io/tiDML/reference/oob_error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get out of bag error — oob_error","text":"Treatment type string","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/oof_crossfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Out-of-fold cross-fitting for DML — oof_crossfit","title":"Out-of-fold cross-fitting for DML — oof_crossfit","text":"--fold cross-fitting DML","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/oof_crossfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Out-of-fold cross-fitting for DML — oof_crossfit","text":"","code":"oof_crossfit(   data,   folds,   m_fit_fun,   g_fit_fun,   y_name,   d_name,   store_models = FALSE )"},{"path":"https://jberesford-fe.github.io/tiDML/reference/replication_results.html","id":null,"dir":"Reference","previous_headings":"","what":"Precomputed DoubleML replication results (internal) — replication_results","title":"Precomputed DoubleML replication results (internal) — replication_results","text":"Precomputed DoubleML replication results (internal)","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/replication_results.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Precomputed DoubleML replication results (internal) — replication_results","text":"","code":"replication_results()"},{"path":"https://jberesford-fe.github.io/tiDML/reference/replication_results.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Precomputed DoubleML replication results (internal) — replication_results","text":"tibble/data.frame columns: method, seed, theta, se, lwr, upr","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/run_dml.html","id":null,"dir":"Reference","previous_headings":"","what":"Run DML-PLR with user-supplied recipes and parsnip models — run_dml","title":"Run DML-PLR with user-supplied recipes and parsnip models — run_dml","text":"Run DML-PLR user-supplied recipes parsnip models","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/run_dml.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run DML-PLR with user-supplied recipes and parsnip models — run_dml","text":"","code":"run_dml(   data,   outcome_recipe,   treatment_recipe,   outcome_model,   treatment_model,   folds_outer = NULL,   n_folds = 5,   n_rep = 1,   vcov_type = \"HC2\",   store_models = FALSE )"},{"path":"https://jberesford-fe.github.io/tiDML/reference/run_dml.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run DML-PLR with user-supplied recipes and parsnip models — run_dml","text":"data Data frame outcome_recipe Recipe outcome (g) model treatment_recipe Recipe treatment (m) model outcome_model parsnip model spec outcome (g) model treatment_model parsnip model spec treatment (m) model folds_outer Optional rsample rset. n_folds Number outer folds folds_outer NULL. n_rep Number repetitions folds_outer NULL. vcov_type Sandwich variance type (e.g., \"HC2\" \"HC3\"). store_models TRUE, keep fitted nuisance models inside result","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/treated_level.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the ","title":"Get the ","text":"Get \"treated\" level binary factor","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/treated_level.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the ","text":"","code":"treated_level(d_vec)"},{"path":"https://jberesford-fe.github.io/tiDML/reference/treated_level.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the ","text":"d_vec Binary factor vector","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/treated_level.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the ","text":"\"treated\" level (second level)","code":""}]
