[{"path":"https://jberesford-fe.github.io/tiDML/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 Justin Beresford Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"https://jberesford-fe.github.io/tiDML/articles/examine-outputs.html","id":"learners","dir":"Articles","previous_headings":"Describing the model setup","what":"Learners","title":"Examine model outputs","text":"models? hyperparameters? pre-processing done?","code":""},{"path":"https://jberesford-fe.github.io/tiDML/articles/examine-outputs.html","id":"folds","dir":"Articles","previous_headings":"Describing the model setup","what":"Folds","title":"Examine model outputs","text":"stratified? many?","code":""},{"path":"https://jberesford-fe.github.io/tiDML/articles/examine-outputs.html","id":"evaluation-metrics","dir":"Articles","previous_headings":"","what":"Evaluation metrics","title":"Examine model outputs","text":"done fold predictions. Running augment() fitted model give : + actual values Y D + predicted (hat) values Y D + residuals Y D (.e. actual - predicted) consider plotting following: + scatter plot actual vs predicted Y D + histogram residuals Y D + QQ plot residuals Y D consider calculating following metrics: + Mean Squared Error (MSE) Y D + R-squared Y D + Correlation actual predicted Y D + Correlation residuals Y D can use yardstick package calculate metrics. example:","code":"library(yardstick) # Mean Squared Error mse_y <- mse(data, truth = Y, estimate = .pred_Y) mse_d <- mse(data, truth = D, estimate = .pred_D) # R-squared rsq_y <- rsq(data, truth = Y, estimate = .pred_Y) rsq_d <- rsq(data, truth = D, estimate = .pred_D) # Correlation cor_y <- cor(data$Y, data$.pred_Y) cor_d <- cor(data$D, data$.pred_D)"},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"https://jberesford-fe.github.io/tiDML/articles/neural-network.html","id":"import-data-and-libraries","dir":"Articles","previous_headings":"Run a neural network with default settings","what":"Import data and libraries","title":"Neural Network","text":"","code":"library(tiDML) library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(recipes) #>  #> Attaching package: 'recipes' #> The following object is masked from 'package:stats': #>  #>     step library(parsnip)   df <- diamonds_sample()"},{"path":"https://jberesford-fe.github.io/tiDML/articles/neural-network.html","id":"neural-network-with-default-settings","dir":"Articles","previous_headings":"","what":"Neural network with default settings","title":"Neural Network","text":"","code":"fit_nnet <- dml_nnet(   data = df,   y = \"price\",   d = \"is_rated_ideal\",   x = c(\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"), )  tidy(fit_nnet) #> # A tibble: 1 × 6 #>   term  estimate std.error conf.low conf.high vcov_type #>   <chr>    <dbl>     <dbl>    <dbl>     <dbl> <chr>     #> 1 d_res     377.      49.0     281.      474. HC2"},{"path":"https://jberesford-fe.github.io/tiDML/articles/neural-network.html","id":"run-a-neural-network-with-custom-settings","dir":"Articles","previous_headings":"","what":"Run a neural network with custom settings","title":"Neural Network","text":"’s possible customise default dml_nnet() degree. set custom penalty rate, number epochs, maximum number weights. also choose number layers (yet true, currently ’s single layer) hidden units (nodes per layer) . Setting hidden units NULL let function choose number hidden units automatically.","code":"fit_nnet <- dml_nnet(   data = df,   y = \"price\",   d = \"is_rated_ideal\",   x = c(\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"),   n_folds = 5,   vcov_type = \"HC2\",   hidden_units_m = 6,   hidden_units_g = 7,   penalty = 0.001,   epochs = 200,   max_weights = 5000,   trace = FALSE   )  fit_nnet |> tidy() #> # A tibble: 1 × 6 #>   term  estimate std.error conf.low conf.high vcov_type #>   <chr>    <dbl>     <dbl>    <dbl>     <dbl> <chr>     #> 1 d_res     281.      42.3     198.      364. HC2"},{"path":"https://jberesford-fe.github.io/tiDML/articles/package-replication.html","id":"replication-of-doubleml-results-with-tidml","dir":"Articles","previous_headings":"","what":"Replication of DoubleML results with tiDML","title":"DoubleML Package","text":"use 401k data Chernozhukov et al. (2018) replicate results package different specifications. goal show tiDML::dml_plr() can produce comparable results much less code.","code":""},{"path":"https://jberesford-fe.github.io/tiDML/articles/package-replication.html","id":"get-data-and-import-packages","dir":"Articles","previous_headings":"","what":"Get data and import packages","title":"DoubleML Package","text":"Note use data (401k) variables across specifications.","code":"library(tiDML) library(dplyr) library(purrr) library(tibble) library(ggplot2) library(DoubleML) library(mlr3) library(mlr3learners)  df401k <- DoubleML::fetch_401k(return_type = \"data.frame\", instrument = FALSE)  y_col  <- \"net_tfa\"   # or \"tw\" depending on the example d_col  <- \"e401\" x_cols <- c(\"age\",\"inc\",\"educ\",\"fsize\",\"marr\",\"twoearn\",\"db\",\"pira\",\"hown\")"},{"path":"https://jberesford-fe.github.io/tiDML/articles/package-replication.html","id":"tidml-approach-as-a-function","dir":"Articles","previous_headings":"","what":"tiDML approach as a function","title":"DoubleML Package","text":"Following Chernozhukov, use random forest stages first classification second regression.","code":"run_tidml <- function(seed, df, y, d, x, trees_grid = 1200L, n_folds = 5L) {   set.seed(seed)       df <- df |> mutate(!!d := as.factor(!!rlang::sym(d)))    fit_tidml <- dml_rf(     data = df,     y = !!rlang::sym(y),     d = !!rlang::sym(d),     x = x,   )    return(tibble(     method = \"tiDML\",     seed = seed,     theta = unname(fit_tidml$estimate),     se    = unname(fit_tidml$se)   ) |>     mutate(       lwr = theta - stats::qnorm(0.975) * se,       upr = theta + stats::qnorm(0.975) * se     )) }"},{"path":"https://jberesford-fe.github.io/tiDML/articles/package-replication.html","id":"doubleml-approach-as-a-function","dir":"Articles","previous_headings":"","what":"DoubleML approach as a function","title":"DoubleML Package","text":"Next use DoubleML package run model.","code":"run_dml <- function(seed, df, y, d, x, trees_grid = 1200L, n_folds = 5L) {   ## DoubleML :: PLR with ranger   ml_l <- lrn(\"regr.ranger\",               num.trees = trees_grid,                num.threads = 1,               respect.unordered.factors = \"order\")      ml_m <- lrn(     \"classif.ranger\",     num.trees = trees_grid,     num.threads = 1,     predict_type=\"prob\"   )    dml_data <- DoubleMLData$new(     data = df,      y_col = y,      d_cols = d,      x_cols = x   )    dml <- DoubleMLPLR$new(     dml_data,      ml_l = ml_l,      ml_m = ml_m,     n_folds = n_folds,     score = \"partialling out\"   )    dml$fit()    ci <- dml$confint(level = 0.95)   return(tibble(     method = \"DoubleML\",     seed = seed,     theta = as.numeric(dml$coef),     se    = as.numeric(dml$se),     lwr   = as.numeric(ci[1]),     upr   = as.numeric(ci[2])   )   ) }"},{"path":"https://jberesford-fe.github.io/tiDML/articles/package-replication.html","id":"run-both-methods-across-many-replications","dir":"Articles","previous_headings":"","what":"Run both methods across many replications","title":"DoubleML Package","text":"wrapper function runs methods returns combined data frame.","code":"replications <- 2L  run_both <- function(seed, df, y, d, x, trees_grid = 1200L, n_folds = 5L) {   tidml_row <- run_tidml(seed, df, y, d, x, trees_grid, n_folds)   dml_row   <- run_dml(seed, df, y, d, x, trees_grid, n_folds)   bind_rows(tidml_row, dml_row) }  seeds <- 401 + 0:replications-1   res <- map_dfr(   seeds,   ~ run_both(.x, df = df401k, y = y_col, d = d_col, x = x_cols) )"},{"path":"https://jberesford-fe.github.io/tiDML/articles/package-replication.html","id":"method-by-method-densities","dir":"Articles","previous_headings":"","what":"Method-by-method densities","title":"DoubleML Package","text":"randomness methods estimates vary across seeds. plot densities estimates across replications show overlap similar means.","code":"ggplot(res, aes(theta, fill = method)) +   geom_density(alpha = 0.35) +   geom_vline(     data = res %>% group_by(method) %>% summarize(mean_theta = mean(theta)),     aes(xintercept = mean_theta, color = method),     linetype = \"dashed\", size = 1   ) +   labs(     title = \"DML-PLR estimates across seeds\",     x = expression(hat(theta)), y = \"Density\", fill = \"Method\"   ) +   theme_minimal(base_size = 12)"},{"path":"https://jberesford-fe.github.io/tiDML/articles/random-forest.html","id":"load-packages-and-data","dir":"Articles","previous_headings":"","what":"Load packages and data","title":"Random Forest","text":"","code":"library(tiDML) library(tiDML) library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(recipes) #>  #> Attaching package: 'recipes' #> The following object is masked from 'package:stats': #>  #>     step library(parsnip)"},{"path":"https://jberesford-fe.github.io/tiDML/articles/random-forest.html","id":"random-forest-with-default-settings","dir":"Articles","previous_headings":"","what":"Random forest with default settings","title":"Random Forest","text":"","code":"df <- diamonds_sample()  fit_rf <- dml_rf(   data = df,   y = \"price\",   d = \"is_rated_ideal\",   x = c(\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"), )  tidy(fit_rf) #> # A tibble: 1 × 6 #>   term  estimate std.error conf.low conf.high vcov_type #>   <chr>    <dbl>     <dbl>    <dbl>     <dbl> <chr>     #> 1 d_res     234.      46.0     143.      324. HC2"},{"path":"https://jberesford-fe.github.io/tiDML/articles/random-forest.html","id":"random-forest-with-custom-settings","dir":"Articles","previous_headings":"","what":"Random Forest with custom settings","title":"Random Forest","text":"can also customise default dml_rf() degree. set custom grid number trees try hyperparameter tuning (NB tests 100 200, rather everything ). can also set number folds cross-fitting type robust standard errors use (choice “HC0”, “HC1”, “HC2”, “HC3”, “HC4”).","code":"fit_rf <- dml_rf(   data = df,   y = \"price\",   d = \"is_rated_ideal\",   x = c(\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"),   n_folds = 5,   vcov_type = \"HC2\",   trees_grid = c(100, 200))  tidy(fit_rf) #> # A tibble: 1 × 6 #>   term  estimate std.error conf.low conf.high vcov_type #>   <chr>    <dbl>     <dbl>    <dbl>     <dbl> <chr>     #> 1 d_res     210.      45.7     120.      299. HC2"},{"path":"https://jberesford-fe.github.io/tiDML/articles/tiDML.html","id":"first-pass-with-tidml","dir":"Articles","previous_headings":"","what":"First pass with tiDML","title":"Introduction to tiDML","text":"simplest case, can use package complete default settings. Pick model, specify data, outcome variable, treatment variable, covariates, hit go. Currently, default models available : + dml_rf() random forest, + dml_nnet() neural network. use diamonds data ggplot2 estimate effect rated “ideal” diamonds price, controlled caret, depth, etc. function dml_rf shortcut using ranger package fit random forest models. full list options : + dml_rf() random forest model using ranger(), + dml_nnet() neural network model using mlp(). Printing recipe steps DML estimate shows preprocessing steps automatically applied data fitting nuisance models. case dml_nn(), see: + zero variance filtering, + Median imputation missing values, + Dummy encoding categorical variables, + Centering scaling numeric variables.","code":"library(tiDML) library(generics) #>  #> Attaching package: 'generics' #> The following objects are masked from 'package:base': #>  #>     as.difftime, as.factor, as.ordered, intersect, is.element, setdiff, #>     setequal, union  df <- diamonds_sample()  fit_rf <- dml_rf(   data = df,   y = \"price\",   d = \"is_rated_ideal\",   x = c(\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"), )  tidy(fit_rf) #> # A tibble: 1 × 6 #>   term  estimate std.error conf.low conf.high vcov_type #>   <chr>    <dbl>     <dbl>    <dbl>     <dbl> <chr>     #> 1 d_res     234.      46.0     143.      324. HC2 print(\"hello\") #> [1] \"hello\""},{"path":"https://jberesford-fe.github.io/tiDML/articles/tiDML.html","id":"examining-the-output","dir":"Articles","previous_headings":"","what":"Examining the output","title":"Introduction to tiDML","text":"Much detail giving Articles section documentation (see vignette(\"examine-outputs\")). get quick overview results, can use tidy() `augment() functions return, respectively: + tibble point estimate, standard error, t-value, p-value, confidence interval. + tibble original data, predicted values, residuals outcome treatment variables.","code":""},{"path":[]},{"path":"https://jberesford-fe.github.io/tiDML/articles/user-defined-recipies.html","id":"start-by-defining-your-learners","dir":"Articles","previous_headings":"How to set your own model","what":"Start by defining your “learners”","title":"Set your own model","text":"define using parsnip package. literally thousands available models, see parsnip documentation comprehensive list examples.","code":"library(tiDML)"},{"path":"https://jberesford-fe.github.io/tiDML/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Justin Beresford. Author, maintainer.","code":""},{"path":"https://jberesford-fe.github.io/tiDML/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Beresford J (2025). tiDML: Double Machine Learning Tidymodels. R package version 0.0.0.9000.","code":"@Manual{,   title = {tiDML: Double Machine Learning with Tidymodels},   author = {Justin Beresford},   year = {2025},   note = {R package version 0.0.0.9000}, }"},{"path":"https://jberesford-fe.github.io/tiDML/index.html","id":"tidml","dir":"","previous_headings":"","what":"Double Machine Learning with Tidymodels","title":"Double Machine Learning with Tidymodels","text":"goal tiDML twofold: Simple first pass: provide straightforward way run Double Machine Learning (DML) R. Users need pick model, specify data formula. Defaults set sensible values, ’s quick first pass ask: “OLS results change materially DML?” Run DML tidymodels way: flexible framework lets define inspect stages DML process explicitly. Specify first- second-stage models, chosing thousands parsnip models, specify preprocessing steps recipes. backend, combined workflows, used first- second-stage models DML partially linear regression. short, tiDML can simplify things, ’s main contribution letting define examine stages DML process explicitly, way tidymodels user expect.","code":""},{"path":"https://jberesford-fe.github.io/tiDML/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Double Machine Learning with Tidymodels","text":"can install development version tiDML GitHub via pak, pacman remotes:","code":"# Using pak pak::pak(\"jberesford-fe/tiDML\")  # using remotes remotes::install_github(\"jberesford-fe/tiDML\")  # not currently working: pacman::p_load_gh(\"jberesford-fe/tiDML\")"},{"path":"https://jberesford-fe.github.io/tiDML/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Double Machine Learning with Tidymodels","text":"basic example shows run DML PLR model random forests nuisance models, taking parameters default. users requiring control (.e. moving past testing phase implementation), can () define first- second-stage models using parsnip, (ii) handle pre-processing steps, stages, using recipes, (iii) pass parsnip model specs recipes recipe run_dml() function get DML estimate. ``` r See vignette detailed examples.","code":"library(tiDML)  random_forest <- dml_rf(   data = df,   y = \"y_var\",   d = \"d_var\",   x = c(\"x1\", \"x2\", \"x3\"), )  print(fit)"},{"path":"https://jberesford-fe.github.io/tiDML/reference/diamonds_sample.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample ggplot2::diamonds with a treatment column — diamonds_sample","title":"Sample ggplot2::diamonds with a treatment column — diamonds_sample","text":"Sample ggplot2::diamonds treatment column","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/diamonds_sample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample ggplot2::diamonds with a treatment column — diamonds_sample","text":"","code":"diamonds_sample(n = 10000, seed = 1)"},{"path":"https://jberesford-fe.github.io/tiDML/reference/diamonds_sample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample ggplot2::diamonds with a treatment column — diamonds_sample","text":"n Number rows sample (default 10,000). seed RNG seed reproducibility.","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/diamonds_sample.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample ggplot2::diamonds with a treatment column — diamonds_sample","text":"tibble columns ggplot2::diamonds plus D (factor 0,1).","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_core_wf.html","id":null,"dir":"Reference","previous_headings":"","what":"Core DML-PLR using workflows — dml_core_wf","title":"Core DML-PLR using workflows — dml_core_wf","text":"Core DML-PLR using workflows","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_core_wf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Core DML-PLR using workflows — dml_core_wf","text":"","code":"dml_core_wf(   data,   m_wf,   g_wf,   folds_outer = NULL,   n_folds = 5,   vcov_type = \"HC2\" )"},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_nnet.html","id":null,"dir":"Reference","previous_headings":"","what":"DML-PLR with single-hidden-layer MLP (nnet engine) — dml_nnet","title":"DML-PLR with single-hidden-layer MLP (nnet engine) — dml_nnet","text":"Uses small MLP nuisances. Adds dummy encoding nominal X normalizes numeric predictors (recommended NNs).","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_nnet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"DML-PLR with single-hidden-layer MLP (nnet engine) — dml_nnet","text":"","code":"dml_nnet(   data,   y,   d,   x,   folds_outer = NULL,   n_folds = 5,   vcov_type = \"HC2\",   hidden_units_m = NULL,   hidden_units_g = NULL,   penalty = 0.001,   epochs = 200,   max_weights = 5000,   trace = FALSE )"},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_nnet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"DML-PLR with single-hidden-layer MLP (nnet engine) — dml_nnet","text":"data, y, d, x dml_rf() folds_outer Optional rsample rset. NULL, folds made internally (stratified D). n_folds Number outer folds folds_outer NULL. vcov_type Sandwich variance type (e.g., \"HC2\" \"HC3\"). hidden_units_m, hidden_units_g Hidden units m- g-models (NULL = heuristic). penalty L2 penalty (.k.. weight decay). epochs Max iterations (passed nnet::nnet() via parsnip). max_weights Max allowable weights nnet engine (MaxNWts) avoid overflow. trace Logical; print nnet training trace.","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_rf.html","id":null,"dir":"Reference","previous_headings":"","what":"DML-PLR with Random Forest — dml_rf","title":"DML-PLR with Random Forest — dml_rf","text":"DML-PLR Random Forest","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/dml_rf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"DML-PLR with Random Forest — dml_rf","text":"","code":"dml_rf(   data,   y,   d,   x,   folds_outer = NULL,   n_folds = 5,   vcov_type = \"HC2\",   trees_grid = NULL )"},{"path":"https://jberesford-fe.github.io/tiDML/reference/make_folds.html","id":null,"dir":"Reference","previous_headings":"","what":"Make v-fold outer folds — make_folds","title":"Make v-fold outer folds — make_folds","text":"Make v-fold outer folds","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/make_folds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make v-fold outer folds — make_folds","text":"","code":"make_folds(data, n_folds = 5)"},{"path":"https://jberesford-fe.github.io/tiDML/reference/make_folds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make v-fold outer folds — make_folds","text":"data Data frame n_folds Number folds","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/make_folds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make v-fold outer folds — make_folds","text":"rsample rset","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/make_folds_stratified.html","id":null,"dir":"Reference","previous_headings":"","what":"Make stratified v-fold outer folds (recommended for binary D) — make_folds_stratified","title":"Make stratified v-fold outer folds (recommended for binary D) — make_folds_stratified","text":"Make stratified v-fold outer folds (recommended binary D)","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/make_folds_stratified.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make stratified v-fold outer folds (recommended for binary D) — make_folds_stratified","text":"","code":"make_folds_stratified(data, d, n_folds = 5)"},{"path":"https://jberesford-fe.github.io/tiDML/reference/make_folds_stratified.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make stratified v-fold outer folds (recommended for binary D) — make_folds_stratified","text":"data Data frame d Treatment column name (string) n_folds Number folds","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/make_folds_stratified.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make stratified v-fold outer folds (recommended for binary D) — make_folds_stratified","text":"rsample rset","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/oob_error.html","id":null,"dir":"Reference","previous_headings":"","what":"Get treatment type: ","title":"Get treatment type: ","text":"Get treatment type: \"binary_factor\" \"continuous\"","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/oob_error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get treatment type: ","text":"","code":"oob_error(fitted_wf)"},{"path":"https://jberesford-fe.github.io/tiDML/reference/oob_error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get treatment type: ","text":"d_vec Treatment vector","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/oob_error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get treatment type: ","text":"Treatment type string","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/oof_crossfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Out-of-fold cross-fitting for DML — oof_crossfit","title":"Out-of-fold cross-fitting for DML — oof_crossfit","text":"--fold cross-fitting DML","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/oof_crossfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Out-of-fold cross-fitting for DML — oof_crossfit","text":"","code":"oof_crossfit(data, folds, m_fit_fun, g_fit_fun, y_name, d_name)"},{"path":"https://jberesford-fe.github.io/tiDML/reference/run_dml.html","id":null,"dir":"Reference","previous_headings":"","what":"Run DML-PLR with user-supplied recipes and parsnip models — run_dml","title":"Run DML-PLR with user-supplied recipes and parsnip models — run_dml","text":"Run DML-PLR user-supplied recipes parsnip models","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/run_dml.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run DML-PLR with user-supplied recipes and parsnip models — run_dml","text":"","code":"run_dml(   data,   output_recipe,   treatment_recipe,   output_model,   treatment_model,   folds_outer = NULL,   n_folds = 5,   vcov_type = \"HC2\" )"},{"path":"https://jberesford-fe.github.io/tiDML/reference/treated_level.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the ","title":"Get the ","text":"Get \"treated\" level binary factor","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/treated_level.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the ","text":"","code":"treated_level(d_vec)"},{"path":"https://jberesford-fe.github.io/tiDML/reference/treated_level.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the ","text":"d_vec Binary factor vector","code":""},{"path":"https://jberesford-fe.github.io/tiDML/reference/treated_level.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the ","text":"\"treated\" level (second level)","code":""}]
